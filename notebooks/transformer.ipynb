{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, random_split\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# parent_dir = os.path.abspath(\"../papers/attention_is_all_you_need\")\n",
    "# sys.path.append(parent_dir)\n",
    "parent_dir = os.path.abspath(\"../utils/\")\n",
    "sys.path.append(parent_dir)\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "YAML_PATH = Path(\"../\")  / \"papers\" / \"attention_is_all_you_need\" / \"config.yaml\"\n",
    "with open(YAML_PATH, \"r\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Training Data and Encode Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BPE.bpe import BPEEncoder, BPEDecoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"../\")  / \"data\" / \"EnglishGerman\" \n",
    "dataset = pd.read_csv(PATH / \"wmt14_translate_de-en_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "BPE_PATH = Path(\"../\")  / \"papers\" / \"attention_is_all_you_need\" / \"BPE\" \n",
    "with open(BPE_PATH / \"vocab_merges_2500.pkl\", \"rb\") as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[171], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m bpe_encoder \u001b[38;5;241m=\u001b[39m BPEEncoder(vocab\u001b[38;5;241m=\u001b[39mvocab)\n\u001b[0;32m----> 2\u001b[0m english_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mbpe_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m german_encoded \u001b[38;5;241m=\u001b[39m bpe_encoder\u001b[38;5;241m.\u001b[39mencode(dataset\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/Documents - Utkarsh’s MacBook Air/AI grind/dl_from_scratch/dl-from-scratch/papers/Attention Is All You Need/BPE/bpe.py:47\u001b[0m, in \u001b[0;36mBPEEncoder.encode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     45\u001b[0m utf8_encoding \u001b[38;5;241m=\u001b[39m _encode_utf8(text)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     stats \u001b[38;5;241m=\u001b[39m \u001b[43m_sum_bigrams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mutf8_encoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     pair \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(stats, key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m p: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mget(p, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pair \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab:\n",
      "File \u001b[0;32m~/Documents/Documents - Utkarsh’s MacBook Air/AI grind/dl_from_scratch/dl-from-scratch/papers/Attention Is All You Need/BPE/utils.py:36\u001b[0m, in \u001b[0;36m_sum_bigrams\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mSums the bi-grams for all sentences.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m pair_counts \u001b[38;5;241m=\u001b[39m [_get_bigrams(sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences]\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sum_dicts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpair_counts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Documents - Utkarsh’s MacBook Air/AI grind/dl_from_scratch/dl-from-scratch/papers/Attention Is All You Need/BPE/utils.py:29\u001b[0m, in \u001b[0;36m_sum_dicts\u001b[0;34m(dicts)\u001b[0m\n\u001b[1;32m     27\u001b[0m         accumulator[key] \u001b[38;5;241m=\u001b[39m accumulator\u001b[38;5;241m.\u001b[39mget(key, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m value\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreducer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Documents - Utkarsh’s MacBook Air/AI grind/dl_from_scratch/dl-from-scratch/papers/Attention Is All You Need/BPE/utils.py:27\u001b[0m, in \u001b[0;36m_sum_dicts.<locals>.reducer\u001b[0;34m(accumulator, element)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreducer\u001b[39m(accumulator, element):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m element\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 27\u001b[0m         accumulator[key] \u001b[38;5;241m=\u001b[39m \u001b[43maccumulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m value\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bpe_encoder = BPEEncoder(vocab=vocab)\n",
    "english_encoded = bpe_encoder.encode(dataset.iloc[:, 1])\n",
    "german_encoded = bpe_encoder.encode(dataset.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_size = max(vocab.values())\n",
    "special_tokens = {max_vocab_size + 1 : \"<SOS>\",  max_vocab_size + 2 : \"<EOS>\", max_vocab_size + 3 : \"<pad>\"}\n",
    "bpe_decoder = BPEDecoder(vocab=vocab, special_tokens=special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageTranslationDataset(Dataset):\n",
    "    def __init__(self, seq_length, src_encodings, tgt_encodings, sos_token, eos_token, pad_token):\n",
    "        super().__init__()\n",
    "        self.paired_encodings = LanguageTranslationDataset.augment_encodings(src_encodings, tgt_encodings, sos_token, eos_token)\n",
    "        self.seq_len = seq_length\n",
    "        self.pad_token = pad_token\n",
    "\n",
    "    @staticmethod\n",
    "    def augment_encodings(src_encodings, tgt_encodings, sos_token, eos_token):\n",
    "        src_encodings = [[sos_token] + sublist + [eos_token] for sublist in src_encodings]\n",
    "        tgt_encodings = [[sos_token] + sublist for sublist in tgt_encodings]\n",
    "        output_encodings = [sublist + [eos_token] for sublist in tgt_encodings] \n",
    "        full_encoding = list(zip(src_encodings, tgt_encodings, output_encodings))\n",
    "        full_encoding.sort(key=lambda x: len(x[0])) # sort sequence lengths\n",
    "        return full_encoding\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_seq, tgt_seq, output_seq = self.paired_encodings[idx]\n",
    "        src_tensor = torch.tensor(src_seq, dtype=torch.long)\n",
    "        tgt_tensor = torch.tensor(tgt_seq, dtype=torch.long)\n",
    "        output_tensor = torch.tensor(output_seq, dtype=torch.long)\n",
    "\n",
    "        src_tensor = F.pad(src_tensor, (0, self.seq_len - src_tensor.size(0)), value=self.pad_token)\n",
    "        tgt_tensor = F.pad(tgt_tensor, (0, self.seq_len - tgt_tensor.size(0)), value=self.pad_token)\n",
    "        output_tensor = F.pad(output_tensor, (0, self.seq_len - output_tensor.size(0)), value=self.pad_token)\n",
    "        encoder_mask = (src_tensor != self.pad_token).int()\n",
    "\n",
    "        subsequent_mask = torch.tril(torch.ones((self.seq_len, self.seq_len), dtype=torch.int))\n",
    "        padding_mask = (tgt_tensor != self.pad_token).int()\n",
    "        decoder_mask = subsequent_mask & padding_mask.unsqueeze(0)\n",
    "\n",
    "        \n",
    "\n",
    "        return {\n",
    "            \"src\": src_tensor, # Seq_len\n",
    "            \"tgt\": tgt_tensor, # seq_len\n",
    "            \"output\": output_tensor, # seq_len\n",
    "            \"encoder_mask\" : encoder_mask.unsqueeze(0).unsqueeze(0), # 1 x 1 x seq_len\n",
    "            \"decoder_mask\" : decoder_mask.unsqueeze(0), # 1 x seq_len x seq_len\n",
    "        }\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.paired_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'english_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m full_data \u001b[38;5;241m=\u001b[39m LanguageTranslationDataset(seq_length\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEQ_LEN\u001b[39m\u001b[38;5;124m'\u001b[39m], src_encodings\u001b[38;5;241m=\u001b[39m\u001b[43menglish_encoded\u001b[49m, tgt_encodings\u001b[38;5;241m=\u001b[39mgerman_encoded, sos_token\u001b[38;5;241m=\u001b[39mmax_vocab_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, eos_token\u001b[38;5;241m=\u001b[39mmax_vocab_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      2\u001b[0m                                         pad_token\u001b[38;5;241m=\u001b[39mmax_vocab_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      4\u001b[0m train_data, test_data \u001b[38;5;241m=\u001b[39m random_split(full_data, [config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAIN_RATIO\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAIN_RATIO\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'english_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "full_data = LanguageTranslationDataset(seq_length=config['SEQ_LEN'], src_encodings=english_encoded, tgt_encodings=german_encoded, sos_token=max_vocab_size + 1, eos_token=max_vocab_size + 2,\n",
    "                                        pad_token=max_vocab_size + 3)\n",
    "\n",
    "train_data, test_data = random_split(full_data, [config['TRAIN_RATIO'], 1-config['TRAIN_RATIO']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=config['BATCH_SIZE'], shuffle=True, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=config['BATCH_SIZE'], shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TransformerComponents.Encoder import Encoder\n",
    "from TransformerComponents.Decoder import Decoder\n",
    "from TransformerComponents.PE import PositionalEmbedding\n",
    "from TransformerComponents.Transformer import Transformer\n",
    "from TransformerComponents.UtilsLayers import Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_size = len(vocab) + 256 + 3 # 3 special tokens\n",
    "vocab_size = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_transformer = Encoder(config['N_ENCODERS'], config['N_HEADS'], config['D_MODEL'], config['D_MODEL'] // config['N_HEADS'], config['D_MODEL'] // config['N_HEADS'], config['FF_HIDDEN'], config['DROPOUT'])\n",
    "decoder_transformer = Decoder(config['N_DECODERS'], config['N_HEADS'], config['D_MODEL'], config['D_MODEL'] // config['N_HEADS'], config['D_MODEL'] // config['N_HEADS'], config['FF_HIDDEN'], config['DROPOUT'])\n",
    "src_embeddings = PositionalEmbedding(vocab_size, config['D_MODEL'], config['SEQ_LEN'], config['DROPOUT'])\n",
    "tgt_embeddings = PositionalEmbedding(vocab_size, config['D_MODEL'], config['SEQ_LEN'], config['DROPOUT'])\n",
    "projection = Projection(config['D_MODEL'], vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Transformer(encoder_transformer, decoder_transformer, src_embeddings, tgt_embeddings, projection).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.initialise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(model, batch, max_len, device, sos_token, eos_token, pad_token):\n",
    "    encoder_input = batch['src'].to(device) # B x seq_len\n",
    "    encoder_mask = batch['encoder_mask'].to(device) # B  x 1 x 1 x seq_len\n",
    "    encoder_output = model.encode(encoder_input, encoder_mask)\n",
    "    B = encoder_input.size(0)\n",
    "    decoder_input = torch.full((B, max_len), pad_token).to(device)\n",
    "    decoder_input[: , 0] = sos_token\n",
    "    finished = torch.zeros(B, dtype=torch.bool, device=device)\n",
    "\n",
    "    for t in range(max_len - 1):\n",
    "        subsequent_mask = torch.tril(torch.ones((max_len, max_len), dtype=torch.int)).expand(B, -1, -1) # shape: (B, max_len, max_len)\n",
    "        other_mask =(decoder_input != pad_token).int().unsqueeze(1) # (B, 1, max_len)\n",
    "        out = model.decode(decoder_input, encoder_output, encoder_mask, (subsequent_mask & other_mask).unsqueeze(1).to(device))\n",
    "        prediction = model.proj(out) # Expected shape: (B, max_len, vocab_size)\n",
    "        next_tokens = torch.argmax(prediction[:, t, :], dim=-1) # shape: (B, )\n",
    "        next_tokens = torch.where(finished, pad_token, next_tokens)\n",
    "\n",
    "        decoder_input[:, t + 1] = next_tokens\n",
    "        finished |= (next_tokens == eos_token)\n",
    "\n",
    "        if finished.all():\n",
    "          break\n",
    "\n",
    "    return decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('../papers/attention_is_all_you_need/Tensorboard/experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmupAdamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, warmup, optimiser):\n",
    "        self.optimiser = optimiser\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "    \n",
    "    def state_dict(self):\n",
    "        return {key: value for key, value in self.__dict__.items() if key != 'optimiser'}\n",
    "    \n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.__dict__.update(state_dict) \n",
    "        \n",
    "    def step(self):\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimiser.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimiser.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 00:   5%|▌         | 2/38 [00:52<15:51, 26.43s/it, loss=7.820]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m writer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m     30\u001b[0m optimiser\u001b[38;5;241m.\u001b[39moptimiser\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 31\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m optimiser\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     33\u001b[0m global_step_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_examples = 10\n",
    "optimiser = WarmupAdamOpt(config['D_MODEL'], 500,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "# optimiser = torch.optim.Adam(model.parameters(), lr=config['LR'], eps=1e-9)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=max_vocab_size + 3, label_smoothing=0.1).to(device)\n",
    "\n",
    "global_step_train = 0\n",
    "global_step_test = 0\n",
    "losses = []\n",
    "test_losses = []\n",
    "for epoch in range(config['NUM_EPOCHS']):\n",
    "    model.train()\n",
    "    batch_train = tqdm(train_dataloader, desc=f\"Training epoch: {epoch:02d}\")\n",
    "    batch_loss = 0\n",
    "    for data in batch_train:\n",
    "        target_indices = data['output'].to(device) # B x seq_len\n",
    "\n",
    "        encoder_input = data['src'].to(device) # B x seq_len\n",
    "        tgt_input = data['tgt'].to(device) # B x seq_len\n",
    "        encoder_mask = data['encoder_mask'].to(device) # B x 1 x 1 x seq_len\n",
    "        decoder_mask = data['decoder_mask'].to(device) # B x 1 x seq_len x seq_len\n",
    "        logits = model(encoder_input,  tgt_input, encoder_mask=encoder_mask, decoder_mask=decoder_mask)\n",
    "        loss = loss_fn(logits.view(-1, vocab_size), target_indices.view(-1))\n",
    "        batch_train.set_postfix({\"loss\": f\"{loss.item(): 6.3f}\"})\n",
    "        batch_loss += loss.item()\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), global_step_train)\n",
    "        writer.flush()\n",
    "\n",
    "        \n",
    "        optimiser.optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        global_step_train += 1\n",
    "\n",
    "    writer.add_scalar(\"batch_train_loss\", batch_loss / len(batch_train), global_step_train // len(batch_train))\n",
    "    writer.flush()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    batch_test = tqdm(test_dataloader, desc=f\"Test epoch: {epoch:02d}\")\n",
    "    sample_taken = False\n",
    "    for idx, data in enumerate(batch_test):\n",
    "        with torch.no_grad():\n",
    "            target_indices = data['output'].to(device)\n",
    "\n",
    "            if not sample_taken:\n",
    "                pred = model_prediction(model, data, config['SEQ_LEN'], device, max_vocab_size + 1, max_vocab_size + 2, max_vocab_size + 3)\n",
    "                ints = torch.randint(low=0, high=pred.size(0), size=(num_examples,))\n",
    "                pred = pred[ints, :]\n",
    "                decoded = [decoded.replace(\"<pad>\", \"\") for decoded in bpe_decoder.decode(pred.detach().cpu().tolist())]\n",
    "                actual_decoded = [decoded.replace(\"<pad>\", \"\") for decoded in bpe_decoder.decode(target_indices[ints, :].detach().cpu().tolist())]\n",
    "                \n",
    "                comparison_text = f\"| Predicted | Actual |\\n|-----------|--------|\\n|\"\n",
    "                for j in range(len(decoded)):\n",
    "                    comparison_text +=  f\"{decoded[j]} | {actual_decoded[j]} | \\n |\"\n",
    "                writer.add_text(\"Translation Comparison\", comparison_text, global_step_test)\n",
    "                writer.flush()\n",
    "                global_step_test += 1\n",
    "                sample_taken = True\n",
    "\n",
    "            encoder_input = data['src'].to(device) # B x seq_len\n",
    "            tgt_input = data['tgt'].to(device) # B x seq_len\n",
    "            encoder_mask = data['encoder_mask'].to(device) # B x 1 x 1 x seq_len\n",
    "            decoder_mask = data['decoder_mask'].to(device) # B x 1 x seq_len x seq_len\n",
    "            logits = model(encoder_input,  tgt_input, encoder_mask=encoder_mask, decoder_mask=decoder_mask)\n",
    "            loss = loss_fn(logits.view(-1, vocab_size), target_indices.view(-1))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    writer.add_scalar(\"val_loss\", val_loss / len(batch_test), epoch)\n",
    "    writer.flush()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "      model_filename = f\"../papers/attention_is_all_you_need/Models/model_{epoch}\"\n",
    "      torch.save({\n",
    "          'epoch' : epoch,\n",
    "          \"model_state_dict\" : model.state_dict(),\n",
    "          \"optimiser_state_dic\" : optimiser.state_dict(),\n",
    "          \"global_step\": global_step_train, \n",
    "          \"global_step_test\" : global_step_test\n",
    "          }, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing HPC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"../papers/attention_is_all_you_need/experiments\")\n",
    "exp_2 = \"drop_warm\"\n",
    "exp_3 = \"hindi_drop_warm_smoothen\"\n",
    "exp_1 = \"no_drop_no_warm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = {}\n",
    "test_losses = {}\n",
    "sentences = {}\n",
    "\n",
    "for exp in [exp_3]:\n",
    "    with open(base_path / f\"{exp}_sentences.pkl\", \"rb\") as f:\n",
    "        sentences[exp] = pickle.load(f)\n",
    "\n",
    "    with open(base_path / f\"{exp}_train_loss.pkl\", \"rb\") as f:\n",
    "        train_losses[exp] = pickle.load(f)\n",
    "\n",
    "    with open(base_path / f\"{exp}_test_loss.pkl\", \"rb\") as f:\n",
    "        test_losses[exp] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIAAAAIhCAYAAAA2OMErAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC0Y0lEQVR4nOzdd3hU1dbH8d+k90pJgCT0XpUiIAIiICAiRRQbIBZERURFUBRQBEVUrJfrK15Aveq1oSIiqBQVpINIR0NCLwkhpE+S8/4RZiQkhCRMciaT7+d58uicOXNmzezAbNbstZfFMAxDAAAAAAAAcFluZgcAAAAAAACAskUCCAAAAAAAwMWRAAIAAAAAAHBxJIAAAAAAAABcHAkgAAAAAAAAF0cCCAAAAAAAwMWRAAIAAAAAAHBxJIAAAAAAAABcHAkgAAAAAAAAF0cCCE7HYrEU62flypWX9TxTp06VxWIp1WNXrlzpkBgu57k///zzcn/u0nrjjTdksVjUvHlzs0MpM926dbvo72rt2rXNDu+SRowYUSHinDFjhhYtWmR2GADgcspr/iVJaWlpmjp1arGvdeDAAVksFs2ePfuyn7u8fPPNN7JYLAoPD1dmZqbZ4ZSJESNGFPm74uwu598C5emdd97R/PnzzQ4DLsLD7ACAC61duzbf7eeff14rVqzQzz//nO9406ZNL+t57rnnHl1//fWleuwVV1yhtWvXXnYMlcX7778vSdqxY4fWrVunDh06mBxR2ahbt64++uijAse9vb1NiKZknnnmGT3yyCNmh3FJM2bM0JAhQ3TTTTeZHQoAuJTymn9JeQmgadOmScr7AsUVzZs3T5KUmJioRYsW6ZZbbjE5orLh6+tb4HekoricfwuUp3feeUdVqlTRiBEjzA4FLoAEEJzOVVddle921apV5ebmVuD4hdLS0uTn51fs56lVq5Zq1apVqhiDgoIuGQ/ybNy4Udu2bVO/fv303Xffad68eQ5LAFmtVlksFnl4OMdfZb6+vhXu98L256ZevXpmhwIAMFFp518o6NixY1qyZImuvfZarVmzRvPmzXNYAignJ0fZ2dlO8+VSRfwdsc19LuffAkBFRQkYKqRu3bqpefPmWr16tTp16iQ/Pz/dfffdkqRPP/1UvXr1UmRkpHx9fdWkSRNNnDhRqamp+a5R2LLP2rVr64YbbtDSpUt1xRVXyNfXV40bN7avYLEprARsxIgRCggI0P79+9W3b18FBAQoKipKjz32WIGlv4cOHdKQIUMUGBiokJAQ3X777dqwYYMsFovDlnj++eefGjBggEJDQ+Xj46PWrVtrwYIF+c7Jzc3V9OnT1ahRI/n6+iokJEQtW7bU66+/bj/n5MmTuu+++xQVFSVvb29VrVpVnTt31o8//lisOGzfgL344ovq1KmTPvnkE6WlpRU47/Dhw/bn8fLyUo0aNTRkyBAdP35c0j/v+QcffKDHHntMNWvWlLe3t/bv3y8pb5VRq1at5OPjo7CwMA0cOFC7du3K9xx///23br31VtWoUUPe3t6qXr26evTooa1bt9rP+fnnn9WtWzeFh4fL19dX0dHRGjx4cKExl5RhGOrbt6/Cw8MVHx9vP56WlqZmzZqpSZMm9t9T2+/nli1bNGjQIAUFBSk4OFh33HGHTp48WeDan376qTp27Ch/f38FBASod+/e2rJlS75zbL+j27dvV69evRQYGKgePXrY77uwBMxiseihhx7Sf/7zH/vvSNu2bfX777/LMAy9/PLLqlOnjgICAnTttdfax+J8P/74o3r06KGgoCD5+fmpc+fO+umnn/KdY3utO3bs0LBhwxQcHKzq1avr7rvv1pkzZ/LFk5qaqgULFtiXl9u+OU5LS9Pjjz+uOnXq2H8H2rZtq48//rj4AwQAKFJWVpamT5+uxo0b2+cEI0eOLPC5VNRn6YEDB1S1alVJ0rRp0+x/nztidUN8fLzuuOMOVatWTd7e3mrSpIleeeUV5ebm5jvvX//6l1q1aqWAgAAFBgaqcePGeuqpp+z3X+5nyoIFC5Sdna1HH31UgwYN0k8//aS4uLgC5yUlJemxxx5T3bp15e3trWrVqqlv377avXu3pH9K32bNmqXp06erTp068vb21ooVKyTllZl17NhRfn5+CgwMVM+ePQus5CrOPG7Lli264YYb7O9bjRo11K9fPx06dKh4b/wljB49Wj4+Ptq0aZP9WG5urnr06KHq1avr6NGjkqT58+fLYrFo+fLlGjlypMLCwuTv76/+/fvr77//LnDdkswxNm/erCFDhig0NNT+pVdR/xZYvHix2rRpY/+3xOLFi+0xNmnSRP7+/mrfvr02btxYIK6NGzfqxhtvVFhYmHx8fNSmTRv973//y3eO7bWuWLFCDzzwgKpUqaLw8HANGjRIR44cyRfPjh07tGrVqgJbCxRnHg9cyDm+NgdK4ejRo7rjjjs0YcIEzZgxQ25uefnMffv2qW/fvho3bpz8/f21e/duvfTSS1q/fn2xlqhu27ZNjz32mCZOnKjq1avrvffe06hRo1S/fn1dc801RT7WarXqxhtv1KhRo/TYY49p9erVev755xUcHKxnn31WkpSamqru3bsrMTFRL730kurXr6+lS5c6dGnwnj171KlTJ1WrVk1vvPGGwsPD9eGHH2rEiBE6fvy4JkyYIEmaNWuWpk6dqsmTJ+uaa66R1WrV7t27lZSUZL/WnXfeqc2bN+uFF15Qw4YNlZSUpM2bNyshIeGScaSnp+vjjz9Wu3bt1Lx5c919992655579Nlnn2n48OH28w4fPqx27drJarXqqaeeUsuWLZWQkKAffvhBp0+fVvXq1e3nTpo0SR07dtTcuXPl5uamatWqaebMmXrqqac0bNgwzZw5UwkJCZo6dao6duyoDRs2qEGDBpKkvn37KicnR7NmzVJ0dLROnTqlNWvW2F/vgQMH1K9fP3Xp0kXvv/++QkJCdPjwYS1dulRZWVnFWmGWnZ1d4Jibm5vc3NzsCazWrVtr6NCh+uWXX+Tp6akxY8YoNjZW69atk7+/f77HDhw4UEOHDtXo0aO1Y8cOPfPMM9q5c6fWrVsnT09PSXllUZMnT9bIkSM1efJkZWVl6eWXX1aXLl20fv36fMv1s7KydOONN+r+++/XxIkTC433fIsXL9aWLVv04osvymKx6Mknn1S/fv00fPhw/f3333rrrbd05swZjR8/XoMHD9bWrVvtk6kPP/xQd911lwYMGKAFCxbI09NT//73v9W7d2/98MMP9uSTzeDBg3XLLbdo1KhR2r59uyZNmiTpnxLCtWvX6tprr1X37t31zDPPSMpbjSdJ48eP1wcffKDp06erTZs2Sk1N1Z9//lms31MAwKXl5uZqwIAB+uWXXzRhwgR16tRJcXFxmjJlirp166aNGzfK19f3kp+lkZGRWrp0qa6//nqNGjVK99xzjyTZk0KldfLkSXXq1ElZWVl6/vnnVbt2bS1evFiPP/64/vrrL73zzjuSpE8++URjxozRww8/rNmzZ8vNzU379+/Xzp077de63M+U999/X5GRkerTp498fX313//+V/Pnz9eUKVPs55w9e1ZXX321Dhw4oCeffFIdOnRQSkqKVq9eraNHj6px48b2c9944w01bNhQs2fPVlBQkBo0aKD//ve/uv3229WrVy99/PHHyszM1KxZs9StWzf99NNPuvrqqyVdeh6Xmpqqnj17qk6dOnr77bdVvXp1HTt2TCtWrNDZs2eL9XqLmvtI0pw5c7Ru3ToNHTpUmzZtUkhIiKZNm6aVK1dq6dKlioyMzPfYUaNGqWfPnvrvf/+rgwcPavLkyerWrZv++OMPhYSESCr5HGPQoEG69dZbNXr06AJfCl9o27ZtmjRpkp5++mkFBwdr2rRpGjRokCZNmqSffvpJM2bMsM+JbrjhBsXGxsrX11eStGLFCl1//fXq0KGD5s6dq+DgYH3yySe65ZZblJaWViDRec8996hfv3721/rEE0/ojjvusP+b5auvvtKQIUMUHBxs/x22rf4qzjweKMAAnNzw4cMNf3//fMe6du1qSDJ++umnIh+bm5trWK1WY9WqVYYkY9u2bfb7pkyZYlz4RyAmJsbw8fEx4uLi7MfS09ONsLAw4/7777cfW7FihSHJWLFiRb44JRn/+9//8l2zb9++RqNGjey33377bUOS8f333+c77/777zckGf/5z3+KfE225/7ss88ues6tt95qeHt7G/Hx8fmO9+nTx/Dz8zOSkpIMwzCMG264wWjdunWRzxcQEGCMGzeuyHMuZuHChYYkY+7cuYZhGMbZs2eNgIAAo0uXLvnOu/vuuw1PT09j586dF72W7XVfc801+Y6fPn3a8PX1Nfr27ZvveHx8vOHt7W3cdttthmEYxqlTpwxJxpw5cy76HJ9//rkhydi6dWuJXqdh/PM7WdjPqFGj8p3766+/Gh4eHsa4ceOM999/35BkvPfee/nOsf1+Pvroo/mOf/TRR4Yk48MPP7S/Tg8PD+Phhx/Od97Zs2eNiIgIY+jQofZjtt/R999/v0D8w4cPN2JiYvIdk2REREQYKSkp9mOLFi0yJBmtW7c2cnNz7cfnzJljSDL++OMPwzAMIzU11QgLCzP69++f75o5OTlGq1atjPbt2xd4rbNmzcp37pgxYwwfH598z+Pv728MHz68QPzNmzc3brrppgLHAQClc+H86+OPPzYkGV988UW+8zZs2GBIMt555x3DMIr3WXry5ElDkjFlypRixRIbG2tIMl5++eWLnjNx4kRDkrFu3bp8xx944AHDYrEYe/bsMQzDMB566CEjJCSkyOe7nM+U1atXG5KMiRMnGoaRNxetU6eOERMTk+/z7LnnnjMkGcuXL7/otWyvu169ekZWVpb9eE5OjlGjRg2jRYsWRk5Ojv342bNnjWrVqhmdOnWyH7vUPG7jxo2GJGPRokUlfq22eUVhPz169Mh37r59+4ygoCDjpptuMn788UfDzc3NmDx5cr5z/vOf/xiSjIEDB+Y7/ttvvxmSjOnTpxuGUbo5xrPPPlsg/ov9W8DX19c4dOiQ/djWrVsNSUZkZKSRmppqP26bE33zzTf2Y40bNzbatGljWK3WfNe94YYbjMjISPt42V7rmDFj8p03a9YsQ5Jx9OhR+7FmzZoZXbt2LRB/cebxwIUoAUOFFRoaqmuvvbbA8b///lu33XabIiIi5O7uLk9PT3Xt2lWSCpQEFaZ169aKjo623/bx8VHDhg0LXbp7IYvFov79++c71rJly3yPXbVqlQIDAwtsOjds2LBLXr+4fv75Z/Xo0UNRUVH5jo8YMUJpaWn25cHt27fXtm3bNGbMGP3www9KTk4ucK327dtr/vz5mj59un7//XdZrdZixzFv3jz5+vrq1ltvlSQFBATo5ptv1i+//KJ9+/bZz/v+++/VvXt3NWnS5JLXHDx4cL7ba9euVXp6eoFvVKKionTttdfalwKHhYWpXr16evnll/Xqq69qy5YtBZaEt27dWl5eXrrvvvu0YMGCQpcbF6VevXrasGFDgR/bahWbzp0764UXXtCcOXP0wAMP6I477tCoUaMKvebtt9+e7/bQoUPl4eFhX/79ww8/KDs7W3fddZeys7PtPz4+PuratWuhHVYufA+L0r1793yrkmxj1KdPn3zLpm3Hbb/ra9asUWJiooYPH54vrtzcXF1//fXasGFDgW/gbrzxxny3W7ZsqYyMDJ04ceKScbZv317ff/+9Jk6cqJUrVyo9Pb3YrxEAcGmLFy9WSEiI+vfvn+/v9datWysiIsL+eXO5n6Wl9fPPP6tp06Zq3759vuMjRoyQYRj2FRXt27dXUlKShg0bpq+//lqnTp0qcK3L+Uyxlb7btiawlbfFxcXlK0/6/vvv1bBhQ1133XWXvOaNN95oX/Ur5a30PnLkiO688077Khspb541ePBg/f777/bS9UvN4+rXr6/Q0FA9+eSTmjt3br6VUMXh6+tb6NzHtlrl/Of5v//7Py1atEg33HCDunTpoqlTpxZ6zQvnPp06dVJMTIx97lOaOUZJ5j6tW7dWzZo17bdtc5xu3brlWw1+4dxn//792r17tz3+82Pr27evjh49qj179uR7rsLmPudfsyjFmccDFyIBhArrwuWikpSSkqIuXbpo3bp1mj59ulauXKkNGzboyy+/lKRifYCHh4cXOObt7V2sx/r5+cnHx6fAYzMyMuy3ExIS8pU02RR2rLQSEhIKfX9q1Khhv1/KK6eaPXu2fv/9d/Xp00fh4eHq0aNHvnrmTz/9VMOHD9d7772njh07KiwsTHfddZeOHTtWZAz79+/X6tWr1a9fPxmGoaSkJCUlJWnIkCGSlG9fpZMnTxZ7E74LX5fttVzs9drut1gs+umnn9S7d2/NmjVLV1xxhapWraqxY8falzjXq1dPP/74o6pVq6YHH3xQ9erVU7169YpdS+3j46O2bdsW+ImJiSlw7u233y4vLy9lZmbqiSeeuOg1IyIi8t328PBQeHi4/XXZ9khq166dPD098/18+umnBSa2fn5+9rKp4ggLC8t328vLq8jjtt91W1xDhgwpENdLL70kwzCUmJiY7xoX/tmzLXEuzp+9N954Q08++aQWLVqk7t27KywsTDfddFO+RCMAoPSOHz+upKQkeXl5Ffh7/dixY/bPm8v9LC2t4s597rzzTr3//vuKi4vT4MGDVa1aNXXo0EHLly+3P6a0nylnz57VZ599pvbt26tq1ar2uc/AgQNlsVjsySGpbOc+ubm5On36tKRLz+OCg4O1atUqtW7dWk899ZSaNWumGjVqaMqUKcX60s/Nza3QuU/Dhg0LnNuvXz9Vr15dGRkZGj9+vNzd3Qu95oVzH9uxC+c+JZljFPZeXczlzn0ef/zxAnGNGTNGkgrMyy5n7lOceTxwIfYAQoV14aZtUt63P0eOHNHKlSvtq34kOVUtbHh4uNavX1/g+KUSKiV9DtuGeuezbSpXpUoVSXnJhPHjx2v8+PFKSkrSjz/+qKeeekq9e/fWwYMH5efnpypVqmjOnDmaM2eO4uPj9c0332jixIk6ceKEli5detEY3n//fRmGoc8//1yff/55gfsXLFig6dOny93dXVWrVi32RoMXjrvtg/Nir9f2WiUpJibGPvnau3ev/ve//2nq1KnKysrS3LlzJUldunRRly5dlJOTo40bN+rNN9/UuHHjVL16dftKpsuVk5Oj22+/XaGhofL29taoUaP022+/2ScS5zt27Fi+b6Gys7OVkJBgf9221/f5558Xmmi6UGF/bsqCLa4333zzot1BHJn09Pf317Rp0zRt2jQdP37c/s1t//797ZtpAgBKz7ZJ7cU++wMDA+3/Xx6fpRcq7txHkkaOHKmRI0cqNTVVq1ev1pQpU3TDDTdo7969iomJKfVnyscff6y0tDStX79eoaGhBe7/6quvdPr0aYWGhpbp3MfNzc3+/MWZx7Vo0UKffPKJDMPQH3/8ofnz5+u5556Tr6+vJk6cWKwYi2P06NE6e/asmjVrprFjx6pLly6Fvk+FzYmPHTum+vXr21+TVLI5RnnMf2xxTZo0SYMGDSr0nEaNGjns+YozjwcuxAoguBTbX+4Xtsb897//bUY4heratavOnj2r77//Pt/xTz75xGHP0aNHD3sy7HwLFy6Un59foR+WISEhGjJkiB588EElJibqwIEDBc6Jjo7WQw89pJ49e2rz5s0Xff6cnBwtWLBA9erV04oVKwr8PPbYYzp69Kj9PejTp49WrFhRYFlscXTs2FG+vr768MMP8x0/dOiQvRSuMA0bNtTkyZPVokWLQl+Lu7u7OnTooLfffluSiny9JTVlyhT98ssv+uijj/Tpp59q27ZtF10F9NFHH+W7/b///U/Z2dn27le9e/eWh4eH/vrrr0K/gWvbtq3D4i6Jzp07KyQkRDt37rxoXIUlvC6lOKvxqlevrhEjRmjYsGHas2ePQzq4AUBld8MNNyghIUE5OTmF/p1e2D9sL/ZZWpJVDsXVo0cP7dy5s8Dn9cKFC2WxWNS9e/cCj/H391efPn309NNPKysrSzt27ChwTkk+U+bNm6fAwED99NNPBeY+L7/8sjIzM+2f63369NHevXuL1aDkQo0aNVLNmjX13//+V4Zh2I+npqbqiy++sHcGu9Cl5nEWi0WtWrXSa6+9ppCQEIfOfd577z19+OGHeuutt/TNN98oKSlJI0eOLPTcC+c+a9asUVxcnH3uU1ZzjMvVqFEjNWjQQNu2bbtoXOcnSourOHOf4szjAYkVQHAxnTp1UmhoqEaPHq0pU6bI09NTH330kbZt22Z2aHbDhw/Xa6+9pjvuuEPTp09X/fr19f333+uHH36QpHy13EX5/fffCz3etWtXTZkyRYsXL1b37t317LPPKiwsTB999JG+++47zZo1S8HBwZKk/v37q3nz5mrbtq2qVq2quLg4zZkzRzExMWrQoIHOnDmj7t2767bbblPjxo0VGBioDRs2aOnSpRf9ZkPKq2s/cuSIXnrpJfuH9fmaN2+ut956S/PmzdMNN9yg5557Tt9//72uueYaPfXUU2rRooWSkpK0dOlSjR8/Pl8njAuFhITomWee0VNPPaW77rpLw4YNU0JCgqZNmyYfHx97x40//vhDDz30kG6++WY1aNBAXl5e+vnnn/XHH3/Yv92aO3eufv75Z/Xr10/R0dHKyMiwl6oVp0Y/PT39ouNiS7otX75cM2fO1DPPPGNPTs2cOVOPP/64unXrpoEDB+Z73JdffikPDw/17NnT3gWsVatWGjp0qKS89qDPPfecnn76af3999+6/vrrFRoaquPHj2v9+vX2bzHLW0BAgN58800NHz5ciYmJGjJkiKpVq6aTJ09q27ZtOnnypP71r3+V+LotWrTQypUr9e233yoyMlKBgYFq1KiROnTooBtuuEEtW7ZUaGiodu3apQ8++OCik2AAQMnceuut+uijj9S3b1898sgjat++vTw9PXXo0CGtWLFCAwYM0MCBA4v1WRoYGKiYmBh9/fXX6tGjh8LCwlSlShV7e+uL2b59e6Gritu1a6dHH31UCxcuVL9+/fTcc88pJiZG3333nd555x098MAD9pKke++9V76+vurcubMiIyN17NgxzZw5U8HBwWrXrp0kleoz5c8//9T69ev1wAMPFLpHZefOnfXKK69o3rx5euihhzRu3Dh9+umnGjBggCZOnKj27dsrPT1dq1at0g033FBowsrGzc1Ns2bN0u23364bbrhB999/vzIzM/Xyyy8rKSlJL774oiQVax63ePFivfPOO7rppptUt25dGYahL7/8UklJSerZs2eR4yHldYe72NynTZs28vb21vbt2zV27FgNHz7cnvSZN2+ehgwZojlz5mjcuHH5Hrdx40bdc889uvnmm3Xw4EE9/fTTqlmzpr2MqqzmGI7w73//W3369FHv3r01YsQI1axZU4mJidq1a5c2b96szz77rMTXtK3Q+vTTT1W3bl35+PioRYsWl5zHA4Uyb/9poHgu1gWsWbNmhZ6/Zs0ao2PHjoafn59RtWpV45577jE2b95coMPWxXb+79evX4Frdu3aNd/u+xfrAnZhnBd7nvj4eGPQoEFGQECAERgYaAwePNhYsmSJIcn4+uuvL/ZW5Hvui/3YYtq+fbvRv39/Izg42PDy8jJatWpVoMPYK6+8YnTq1MmoUqWK4eXlZURHRxujRo0yDhw4YBiGYWRkZBijR482WrZsaQQFBRm+vr5Go0aNjClTpuTrgnChm266yfDy8jJOnDhx0XNuvfVWw8PDwzh27JhhGIZx8OBB4+677zYiIiIMT09Po0aNGsbQoUON48eP53vdF+t+9t577xktW7Y0vLy8jODgYGPAgAHGjh077PcfP37cGDFihNG4cWPD39/fCAgIMFq2bGm89tprRnZ2tmEYhrF27Vpj4MCBRkxMjOHt7W2Eh4cbXbt2zdfd4WKK6gImybBarcaRI0eMatWqGddee22+rh25ublG//79jZCQECM2NtYwjH9+bzZt2mT079/f/rsybNgw+3tyvkWLFhndu3c3goKCDG9vbyMmJsYYMmSI8eOPP9rPudjvqO2+wrqAPfjgg/mOXawTy8XGZ9WqVUa/fv2MsLAww9PT06hZs6bRr1+/fOfZXuvJkyfzPdbWIcP2nhhGXieOzp07G35+foYk+5/LiRMnGm3btjVCQ0MNb29vo27dusajjz5qnDp1qtDXCwAoWmGfGVar1Zg9e7bRqlUrw8fHxwgICDAaN25s3H///ca+ffsMwyj+Z+mPP/5otGnTxvD29jYkFdrh0cb22XOxH9v8Ji4uzrjtttuM8PBww9PT02jUqJHx8ssv5/vMXbBggdG9e3ejevXqhpeXl32+YetiaRil+0wZN27cJbuf2TqVbdq0yTCMvE6mjzzyiBEdHW14enoa1apVM/r162fs3r073+u+WPezRYsWGR06dDB8fHwMf39/o0ePHsZvv/1mv78487jdu3cbw4YNM+rVq2f4+voawcHBRvv27Y358+df9HXYFNUFTJKxb98+IyUlxWjcuLHRtGnTAnPHBx980PD09LR3brN97i9btsy48847jZCQEHunV9vv1/kuZ45x/n3nu9i/BUoyJ9q2bZsxdOhQo1q1aoanp6cRERFhXHvttfauuOe/1g0bNuR7bGH/xjhw4IDRq1cvIzAw0JBkn69dah4PFMZiGOetGwRgmhkzZmjy5MmKj48v9qaAcF1Tp07VtGnTdPLkyXz7FgAAALii+fPna+TIkdqwYYNpJeyAq6MEDDDBW2+9JUlq3LixrFarfv75Z73xxhu64447SP4AAAAAAByOBBBgAj8/P7322ms6cOCAMjMzFR0drSeffFKTJ082OzQAAAAAgAuiBAwAAAAAAMDF0QYeAAAAAADAxZEAAgAAAAAAcHEkgAAAAAAAAFycy28CnZubqyNHjigwMFAWi8XscAAAwEUYhqGzZ8+qRo0acnPjOyozMX8CAKBiKMn8yeUTQEeOHFFUVJTZYQAAgGI6ePCgatWqZXYYlRrzJwAAKpbizJ9cPgEUGBgoKe/NCAoKcth1rVarli1bpl69esnT09Nh10XpMB7OhfFwHoyFc2E8ipacnKyoqCj7ZzfMw/ypcmA8nAvj4TwYC+fCeBStJPMnl08A2ZYtBwUFOXwC4+fnp6CgIH4JnQDj4VwYD+fBWDgXxqN4KDkyH/OnyoHxcC6Mh/NgLJwL41E8xZk/UWAPAAAAAADg4kgAAQAAAAAAuDgSQAAAAAAAAC7O5fcAAuAaDMNQdna2cnJyzA6lQrFarfLw8FBGRgbvnROo7OPh7u4uDw8P9vgBgHLC/Kl0KvvntbOp7OPhyPkTCSAATi8rK0tHjx5VWlqa2aFUOIZhKCIiQgcPHuQf3U6A8ZD8/PwUGRkpLy8vs0MBAJfG/Kn0+Lx2LoyH4+ZPJIAAOLXc3FzFxsbK3d1dNWrUkJeXV6X9i780cnNzlZKSooCAALm5UfVrtso8HoZhKCsrSydPnlRsbKwaNGhQ6d4DACgvzJ8uT2X+vHZGlXk8HD1/IgEEwKllZWUpNzdXUVFR8vPzMzucCic3N1dZWVny8fGpdB+Yzqiyj4evr688PT0VFxdnfx8AAI7H/OnyVPbPa2dT2cfDkfOnyvfuAaiQKuNf9oAr4s8yAJQf/s4FXIOj/izzNwIAAAAAAICLIwEEAAAAAADg4kgAAUAZ6datm8aNG3fR+y0WixYtWnRZzzF//nyFhITYb0+dOlWtW7cu9fVGjBihm2666bJiQsVwqd9PAADMwPwJzqyiz59IAAGASY4ePao+ffo49JqPP/64fvrpJ4deExXbypUrZbFYlJSUZHYoAABcNuZPKA+uOn+iCxgAmCQiIsLh1wwICFBAQIDDr2uTlZUlLy+vMrt+eXGV1wEAQGXD/Mk8rvI6KjNWAAGocAzDUFpWtik/hmGUKNbc3FxNmDBBYWFhioiI0NSpU+33nb+E+cCBA7JYLPryyy/VvXt3+fn5qVWrVlq7dm2+682fP1/R0dHy8/PTwIEDlZCQkO/+kixhzsnJ0fjx4xUSEqLw8HBNmDChwOvr1q2bHnroIY0fP15VqlRRz549JUmrVq1S+/bt5e3trcjISE2cOFHZ2dkFHvfQQw/Zrz958uRivX9vvvmmWrRoYb+9aNEiWSwWvf322/ZjvXv31qRJkyRJf/31lwYMGKDq1asrICBA7dq1048//pjvmrVr19b06dM1YsQIBQcH695777Uv/168eLEaNWokPz8/DRkyRKmpqVqwYIFq166t0NBQPfzww8rJySnWe/rOO++oQYMG8vHxUfXq1TVkyJB878nYsWM1adIkhYeHq3r16nr33XeVmpqqkSNHKjAwUPXq1dP333+f75qXeq8zMzM1duxYVatWTT4+Prr66qu1YcMGSXm/V927d5ckhYaGymKxaMSIEfbHFvX7KUlnzpzRfffdp2rVqikoKEjXXnuttm3bZr/f9vv2wQcfqHbt2goODtatt96qs2fPFuv9AgCUH7PmTyWdO0nMn5g/MX8qK6wAAlDhpFtz1PTZH0x57p3P9ZafV/H/6lywYIHGjx+vdevWae3atRoxYoQ6d+5snwhc6Omnn9bs2bPVoEEDPf300xo2bJj2798vDw8PrVu3TnfffbdmzJihQYMGaenSpZoyZUqpX8srr7yi999/X/PmzVPTpk31yiuv6KuvvtK1115b4DU88MAD+u2332QYhg4fPqy+fftqxIgRWrhwoXbv3q17771XPj4++T4AFyxYoFGjRmndunXauHGj7rvvPsXExOjee+8tMq5u3brpkUce0alTp1SlShWtWrXK/t8HH3xQ2dnZWrNmjR599FFJUkpKivr27avp06fLx8dHCxYsUP/+/bVnzx5FR0fbr/vyyy/rmWee0eTJkyVJv/76q9LS0vTGG2/ok08+0dmzZzVo0CANGjRIISEhWrJkif7++28NHjxYV199tW655ZYi4964caPGjh2rDz74QJ06dVJiYqJ++eWXfOcsXLhQY8eO1e+//67PPvtMDzzwgBYtWqSBAwfqqaee0muvvaY777xT8fHx8vPzK9Z7PWHCBH3xxRdasGCBYmJiNGvWLPXu3Vv79+9XVFSUvvjiCw0ePFh79uxRUFCQfH19843RxX4/DcNQv379FBYWpiVLlig4OFj//ve/1aNHD+3du1dhYWGS8iaQixYt0uLFi3X69GkNHTpUL774ol544YUi3y8AQPkya/5U0rmTxPyJ+RPzpzJjuLgzZ84YkowzZ8449LpZWVnGokWLjKysLIdeF6XDeDgXR45Henq6sXPnTiM9Pd1+LDXTasQ8udiUn9RMa7Fj79q1q3H11VfnO9auXTvjySefNAzDMCQZX331lWEYhhEbG2tIMt577z37uTt27DAkGbt27TIMwzCGDRtmXH/99fmud8sttxjBwcH221OmTDFatWplv52Tk2OcPn3ayMnJKRBfZGSk8eKLL9pvW61Wo1atWsaAAQPyvYbWrVvne9xTTz1lNGrUyMjNzbUfe/vtt42AgAD783Tt2tVo0qRJvnOefPJJo0mTJgXiuFBubq5RpUoV4/PPPzcMwzBat25tzJw506hWrZphGIaxZs0aw8PDwzh79uxFr9G0aVPjzTfftN+OiYkxbrrppnzn/Oc//zEkGfv377cfu//++w0/P7981+7du7dx//33XzLuL774wggKCjKSk5MLvd/2+2Abj+zsbMPf39+488477eccPXrUkGSsXbvWMIxLv9cpKSmGp6en8dFHH9nvz8rKMmrUqGHMmjXLMAzDWLFihSHJOH36dKHxnO/838+ffvrJCAoKMjIyMvKdU69ePePf//63YRh5v29+fn75XvMTTzxhdOjQ4aLvU2F/pm3K6jMbJcf8qXJgPJyLq86fSjJ3MgzmT8yf8mP+lMdR8ydWAJXS/hMp2nzKooYnUtSkZqjZ4QCViq+nu3Y+19u05y6Jli1b5rsdGRmpEydOFOv8yMhISdKJEyfUuHFj7dq1SwMHDsx3fseOHbV06dISxSTlLU09evSoOnbsaD/m4eGhtm3bFlhm3LZt23y3d+3apY4dO8pisdiPde7cWSkpKTp06JD9W6Orrroq3zkdO3bUK6+8opycHLm7X/x9tFgsuuaaa7Ry5Ur16NFDO3bs0OjRozV79mzt2rVLK1eu1BVXXGGv1U9NTdW0adO0ePFiHTlyRNnZ2UpPT1d8fHyRr0OS/Pz8VK9ePfvt6tWrq3bt2vn2AahevXqRY2bTs2dPxcTEqG7durr++ut1/fXXa+DAgfLz87Ofc/7SbHd3d4WHh+c7Vr16dUmyP9+l3uukpCRZrVZ17tzZfr+np6fat2+vXbt2XTLmon4/N23apJSUFIWHh+c7Jz09XX/99Zf9du3atRUYGFjoNYAL7Tueol+PWdQlI1thnp5mhwNUKmbNn0o6d5KYPzF/Yv5UVkgAldK/VsXqm33uqlr7JAkgoJxZLJYSLyU2i+cF/8CxWCzKzc0t1vm2Dy3b+RdOLMqLv79/vtuGYeT7QLUdk1TgeGl169ZN7777rn755Re1atVKISEhuuaaa7Rq1SqtXLlS3bp1s5/7xBNP6IcfftDs2bNVv359+fr6asiQIcrKyirydUiFj09Jx8wmMDBQmzdv1sqVK7Vs2TI9++yzmjp1qjZs2GBvNXup5ytszIt6ry/2vhf2uMIU9Vpzc3MVGRmplStXFnjc+a1zS/t+oXK6/6MtOnjaXdcfTFKPpr6XfgAAh2H+VL6YPzF/upAzzJ/YBLqUosPyJi0HT6ebHAmAyqJp06b6/fff8x278HZxBQcHKzIyMt/js7OztWnTpmLFsWbNmnwTqjVr1igwMFA1a9a8aGy///67GjRoUOS3VzbdunXTjh079Pnnn9snK127dtWPP/6oNWvWqGvXrvZzf/nlF40YMUIDBw5UixYtFBERoQMHDlzyOcqCh4eHrrvuOs2aNUt//PGHDhw4oJ9//rnU17vUe12/fn15eXnp119/td9vtVq1ceNGNWnSRJLs3TqKuxGjzRVXXKFjx47Jw8ND9evXz/dTpUqVUr8mVG5ta+d9abbhwGmTIwFQWTB/Yv4kMX+yIQFUStFheUvSDiammRwJgMpi7NixWrp0qWbNmqW9e/fqrbfeKtXyZZtHHnlEL774or766ivt3r1bY8aMUVJS0iUfN2bMGB08eFAPP/ywdu/era+//lpTpkzR+PHj5eb2z8fKwYMHNX78eO3Zs0cff/yx3nzzTT3yyCPFiq158+YKDw/XRx99ZJ/AdOvWTYsWLVJ6erquvvpq+7n169fXl19+qa1bt2rbtm267bbbTFmBsnjxYr3xxhvaunWr4uLitHDhQuXm5qpRo0alvual3mt/f3898MADeuKJJ7R06VLt3LlT9957r9LS0jRq1ChJUkxMjCwWixYvXqyTJ08qJSWlWM993XXXqWPHjrrpppv0ww8/6MCBA1qzZo0mT56sjRs3lvo1oXJrF5OXANoYRwIIQPlg/sT8ifnTP0gAlZJtBVA8CSAA5eSqq67Se++9pzfffFOtW7fWsmXL7B0ZSuOxxx7TXXfdpREjRqhjx44KDAwsUCNfmJo1a2rJkiVav369WrVqpdGjR2vUqFEFYrnrrruUnp6u9u3b68EHH9TDDz+s++67r1ixWSwW+7dUXbp0kZRXbx0cHKw2bdooKCjIfu5rr72m0NBQderUSf3791fv3r11xRVXFPdtcJiQkBB9+eWXuvbaa9WkSRPNnTtXH3/8sZo1a1bqaxbnvX7xxRc1ePBg3Xnnnbriiiu0f/9+/fDDDwoNDbVfY9q0aZo4caKqV6+uhx56qFjPbbFYtGTJEl1zzTW6++671bBhQ9166606cOCAvdYeKKl2tUMkSdsOnVGGtWTfqgJAaTB/Yv7E/Om8+AyziiLLSXJysoKDg3XmzJl8v/CX63BiijrPWiU3i7T7+T7y8iCXZiar1aolS5aob9++BeopUf4cOR4ZGRmKjY1VnTp15OPj46AIK4/c3FwlJycrKCgo37dLZa1bt25q3bq15syZU27PWRGYNR7OpKg/02X1mY2SK6uxyMrK0pXPL9NZq0Wf3neVOtQNv/SDUGaYPzkX5k/Og/mTc2H+5Lj5U+V89xygaoCXvNwM5RrSkST2AQIAALgUi8WiekF53z1uOJBocjQAAFQuJIBKyWKxKNw77//jKAMD4IQCAgIUFBSkWrVqKSgoSAEBAfafX375xbS4fvnll3yxXPjjrCpq3ICzqReYlwBaF0sCCIDzYf7kWBU1bldlah/A1atX6+WXX9amTZt09OhRffXVV7rpppvs96ekpGjixIlatGiREhISVLt2bY0dO1YPPPCAeUGfJ9zH0NF0i+ITUiVVNTscAMhn69atys3NVUpKigICAvItmT2/20RZKKz1pU3btm21devWMn3+slBR4wacTd1zK4A2x51Wdk6uPNz5PhKA82D+5FgVNW5XZWoCKDU1Va1atdLIkSM1ePDgAvc/+uijWrFihT788EPVrl1by5Yt05gxY1SjRg0NGDDAhIjzq3Ku9I6NoAE4o/r16ztlzbSvr6/q169vdhglVlHjBpxNDT8p0MdDZzOytevoWbWoFWx2SABgx/zJsSpq3K7K1N/mPn36aPr06Ro0aFCh969du1bDhw9Xt27dVLt2bd13331q1aqVU7RPk6QqPnnfYMUlkAACypqL71cPVBr8WYabRboiOkSStC42wdxgABfH37mAa3DUn2VTVwBdytVXX61vvvlGd999t2rUqKGVK1dq7969ev311y/6mMzMTGVmZtpvJycnS8rbVd9qtTosNqvV+s8eQAmpDr02Ss72/jMOzsHR42EYhlJSUuTt7e2Q61Umtg8LwzCUm5trcjRgPPLKu23vw4V/R/B3eOXRLiZUq/ae0oYDibqnS12zwwFcjq2LWFpamnx9fU2OBsDlSkvLW3RyuR0CnToB9MYbb+jee+9VrVq15OHhITc3N7333nu6+uqrL/qYmTNnatq0aQWOL1u2TH5+fg6Nz1YCFnvyrL77boksFodeHqWwfPlys0PAeRw1HoGBgcrMzFRGRoa8vLxk4Q9biSUk8C27M6mM42EYhrKysnTq1CmdPn1a+/btK3CObXID19eudqgkacOB0zIMg7/XAQdzd3dXSEiITpw4IUny8/Pjz1kJ5ObmKisrSxkZGU5TAlaZVebxMAxDaWlpOnHihEJCQuTu7n5Z13P6BNDvv/+ub775RjExMVq9erXGjBmjyMhIXXfddYU+ZtKkSRo/frz9dnJysqKiotSrVy8FBQU5LDar1arvf1guN4uUlWtRh649VCWA1QlmsVqtWr58uXr27HnZWVFcPkePh2EYOnHihH1FH4rPMAxlZGTIx8eHiZ8TYDykqlWrqlmzZoW+fv6MVx7NawTJ28NNialZ+utkiupXCzQ7JMDlRERESJI9CYTiMwxD6enp8vX1rbSf186E8ZBCQkLsf6Yvh9MmgNLT0/XUU0/pq6++Ur9+/SRJLVu21NatWzV79uyLJoC8vb0LLRPx9PR0eGLAw02KDPbR4aQMHUnOUmQobezMVhbjjNJz5HjUqlVLOTk5lIiUkNVq1erVq3XNNdfwZ8MJVPbx8PT0LPKbq8r4nlRWXh5uahMdot//TtT62NMkgIAyYLFYFBkZqWrVqjF/KqHK/nntbCr7eFxq/lQSTpsAsu3Zc+ESL3d3d6faNyEq1FeHkzIUl5CmK2PCzA4HcGnu7u4O+8uvsnB3d1d2drZ8fHwq5Qems2E8gH+0rx12LgGUoNs6RJsdDuCymD+VHJ/XzoXxcBxTE0ApKSnav3+//XZsbKy2bt2qsLAwRUdHq2vXrnriiSfk6+urmJgYrVq1SgsXLtSrr75qYtT5RYf56ffY07SCBwAAKIH2dcIl7deGA6fNDgUAgErB1ATQxo0b1b17d/tt2949w4cP1/z58/XJJ59o0qRJuv3225WYmKiYmBi98MILGj16tFkhFxAdlrexdDyt4AEAAIqtTXSI3N0sOpyUrkOn01Qr1LHNOgAAQH6mJoC6detWZD/7iIgI/ec//ynHiEouKjSvrWIcK4AAAACKzd/bQ81rBGnboTPacCCRBBAAAGWscvVQKwP2FUAkgAAAAEqkfZ28/RPXx1IGBgBAWSMBdJmiw/JWAJ08m6m0rGyTowEAAKg42tW2JYASTI4EAADXRwLoMgX5eirYN28nclYBAQAAFJ8tAfTXyVQlpGSaHA0AAK6NBJADxISzETQAAEBJhfp7qWH1AEmiGxgAAGWMBJADsA8QAABA6fxTBpZociQAALg2EkAOYEsAxbECCAAAoERsG0FvOEACCACAskQCyAFsJWC0ggcAACgZWwJox5EzOpthNTkaAABcFwkgB4gO85ckHSQBBAAAUCKRwb6qFeqrXEPaHJ9kdjgAALgsEkAOYFsBdOh0mnJyDZOjAQAAqFjsZWDsAwQAQJkhAeQA1YN85OXuJmuOoSNJ6WaHAwAAUKG0ZyNoAADKHAkgB3B3s6hWmK8kysAAAABKyrYCaOuhJGVYc0yOBgAA10QCyEFiwtgIGgAAoDTqVPFXlQAvZWXn6o9DZ8wOBwAAl0QCyEFoBQ8AAFA6FotF7WrTDh4AgLJEAshBosPpBAYAAFBatjIw9gECAKBskABykH9KwFJNjgQAAKDisa0A2hR3mq6qAACUARJADhId/k8JmGEwaQEAACiJJpFBCvT2UEpmtnYdTTY7HAAAXA4JIAex7QF0NiNbZ9KtJkcDAABQsbi7WXRl7VBJlIEBAFAWSAA5iI+nu6oHeUtiI2gAAIDSsJWBkQACAMDxSAA5UDSt4AEAAEqtQ51/OoFRUg8AgGORAHKg6LC8TmDxCWwEDQAAUFItagXLy8NNCalZ+usk8ykAAByJBJADxZzbCDqeFUAAAAAl5u3hrtZRIZLyVgEBAADHIQHkQDHndQIDAABAydnLwNgHCAAAhyIB5EBRYawAAgAAuBy2jaDXkQACAMChSAA5UMy5BNCx5AxlWHNMjgYAAKDiuSImVO5uFh1OStfhpHSzwwEAwGWQAHKgMH8vBXh7yDCkQ6eZsAAAAJRUgLeHmtUIkkQZGAAAjkQCyIEsFst5ZWB0rgAAACgNWxnYejaCBgDAYUgAOZitDCyejaABAABKpT0bQQMA4HAkgBzM3gmMjaABAABKxbYCaN+JFCWmZpkcDQAAroEEkINFsQIIAADgsoT5e6lBtQBJ0gbKwAAAcAgSQA7GCiAAAIDL144yMAAAHIoEkIPFhPlLkg4mpik31zA5GgAAgIqpPRtBAwDgUCSAHKxGiI/c3SzKzM7VibOZZocDAABQIdk2gt5xJFkpmdkmRwMAQMVHAsjBPNzdVDPEV5IUl0AreAAAgNKoEeKrmiG+ysk1tDnutNnhAABQ4ZEAKgO2fYDi2QcIAACg1Ozt4CkDAwDgspEAKgPRYSSAAAAALpctAbSejaABALhsJIDKgC0BFEcreAAAgFJrd24j6C0Hk5SZnWNyNAAAVGwkgMoAJWAAAACXr15Vf4X7eykrO1fbD50xOxwAACo0EkBlIPpcK3gSQAAAAKVnsVjsq4DWUQYGAMBlIQFUBqLPrQBKTM3S2QyrydEAAABUXO3YCBoAAIcgAVQGArw9FO7vJYl9gAAAAC5Hh3MJoE0HTisn1zA5GgAAKi4SQGXEtgroIGVgAAAApdYkMkgB3h46m5mtXUeTzQ4HAIAKiwRQGbF3AiMBBAAAUGrubhZdGRMqiTIwAAAuBwmgMhJDK3gAAACHaM8+QAAAXDYSQGUkOjyvExglYAAAAJfH1glsfWyiDIN9gAAAKA0SQGUkJtxWApZqciQAAAAVW8tawfLycNOplCzFnmJuBQBAaZiaAFq9erX69++vGjVqyGKxaNGiRQXO2bVrl2688UYFBwcrMDBQV111leLj48s/2BKy7QF0JClD1pxck6MBAACouHw83dW6VoikvFVAAACg5ExNAKWmpqpVq1Z66623Cr3/r7/+0tVXX63GjRtr5cqV2rZtm5555hn5+PiUc6QlVy3QWz6ebsrJNXQkKd3scAAAACq0dnXyNoJezz5AAACUiqkJoD59+mj69OkaNGhQofc//fTT6tu3r2bNmqU2bdqobt266tevn6pVq1bOkZacxWL5pxMYG0EDAIBSmDp1qiwWS76fiIiIi56/cuXKAudbLBbt3r27HKMuG+3rhEtiI2gAAErLw+wALiY3N1ffffedJkyYoN69e2vLli2qU6eOJk2apJtuuumij8vMzFRmZqb9dnJysiTJarXKarU6LD7btYq6Zq0QX+09nqK/T55VxzohDntuFFSc8UD5YTycB2PhXBiPovG+FK5Zs2b68ccf7bfd3d0v+Zg9e/YoKCjIfrtq1aplElt5uiI6RG4W6WBiuo6eSVdksK/ZIQEAUKE4bQLoxIkTSklJ0Ysvvqjp06frpZde0tKlSzVo0CCtWLFCXbt2LfRxM2fO1LRp0wocX7Zsmfz8/Bwe5/Llyy96X06ymyQ3rdq4Q6Gntjv8uVFQUeOB8sd4OA/GwrkwHoVLS2PFbGE8PDyKXPVTmGrVqikkJKRsAjJJoI+nmtUI1vbDZ7Q+NlEDWtc0OyQAACoUp00A5ebmbZw8YMAAPfroo5Kk1q1ba82aNZo7d+5FE0CTJk3S+PHj7beTk5MVFRWlXr165fsm7HJZrVYtX75cPXv2lKenZ6HnJPwer1Xf7ZZHSIT69m3tsOdGQcUZD5QfxsN5MBbOhfEomm3VLvLbt2+fatSoIW9vb3Xo0EEzZsxQ3bp1i3xMmzZtlJGRoaZNm2ry5Mnq3r17kec70wrqolwZnZcA+v2vU+rbzPm3BHB2rEp0LoyH82AsnAvjUbSSvC9OmwCqUqWKPDw81LRp03zHmzRpol9//fWij/P29pa3t3eB456enmUy2S7qunWqBkqSDp5OZ6JfTspqnFE6jIfzYCycC+NRON6Tgjp06KCFCxeqYcOGOn78uKZPn65OnTppx44dCg8PL3B+ZGSk3n33XV155ZXKzMzUBx98oB49emjlypW65pprLvo8zrSCuihuCRZJ7lrx50Et8Tjg0JgqM1YlOhfGw3kwFs6F8ShcSVZQO20CyMvLS+3atdOePXvyHd+7d69iYmJMiqpkosPzJkzxiWkyDEMWi8XkiAAAQEXSp08f+/+3aNFCHTt2VL169bRgwYJ8K55tGjVqpEaNGtlvd+zYUQcPHtTs2bOLTAA50wrqonRIzdL7L67UsXSLOna7TqF+Xg6LrTJiVaJzYTycB2PhXBiPopVkBbWpCaCUlBTt37/ffjs2NlZbt25VWFiYoqOj9cQTT+iWW27RNddco+7du2vp0qX69ttvtXLlSvOCLoFaob6yWKS0rBwlpGapSkDBlUkAAADF5e/vrxYtWmjfvn3FfsxVV12lDz/8sMhznGkFdVEiQjxVr6q//jqZqq2HzqpXs5LtjYTCsSrRuTAezoOxcC6MR+FK8p6Y2gZ+48aNatOmjdq0aSNJGj9+vNq0aaNnn31WkjRw4EDNnTtXs2bNUosWLfTee+/piy++0NVXX21m2MXm7eGuGuc6VNAKHgAAXK7MzEzt2rVLkZGRxX7Mli1bSnS+s6MdPAAApWPqCqBu3brJMIwiz7n77rt19913l1NEjhcV5qvDSemKT0zVlTGhZocDAAAqkMcff1z9+/dXdHS0Tpw4oenTpys5OVnDhw+XlFe6dfjwYS1cuFCSNGfOHNWuXVvNmjVTVlaWPvzwQ33xxRf64osvzHwZDtW+Tqg+Xh+v9QdOmx0KAAAVitPuAeQqYsL89fvfiYpPSDc7FAAAUMEcOnRIw4YN06lTp1S1alVdddVV+v333+37IR49elTx8fH287OysvT444/r8OHD8vX1VbNmzfTdd9+pb9++Zr0Eh2tXO0yS9OfhM0rNzJa/N9NZAACKg0/MMmbbCDouMdXkSAAAQEXzySefFHn//Pnz892eMGGCJkyYUIYRma9WqJ9qhuStsN4Sn6SrG1QxOyQAACoEU/cAqgyiw851AmMPIAAAAIdoVzuvrH59bILJkQAAUHGQACpjMee1ggcAAMDla1cnrwxsPRtBAwBQbCSAylhMmL8k6cTZTKVn5ZgcDQAAQMXX4VwCaEt8krKyc02OBgCAioEEUBkL9vNUkE/eVkusAgIAALh89aoGKMzfS5nZudp+OMnscAAAqBBIAJWDmPC8VUBxCWwEDQAAcLksFst5+wDRDh4AgOIgAVQOotkHCAAAwKFs7eDZCBoAgOIhAVQO7J3ASAABAAA4RPtz+wBtjDutnFzD5GgAAHB+JIDKQcy5BFAcreABAAAcomlkkPy93HU2I1t7jp01OxwAAJweCaByYCsBO8gKIAAAAIfwcHfTFTG2fYAoAwMA4FJIAJUD2ybQB0+nsUQZAADAQWzt4DccYCNoAAAuhQRQOYgI8pGnu0XWHENHz6SbHQ4AAIBLsG8EfSBRhsGXbAAAFIUEUDlwd7MoKpSNoAEAABypVVSIvNzddPJspg6w1yIAAEUiAVRO7K3gmZwAAAA4hI+nu1pFBUuSNsQmmhwNAADOjQRQObG1go9jBRAAAIDD2MrA1pEAAgCgSCSAyoktAcQKIAAAAMdpZ98ImgQQAABFIQFUTmydwNgDCAAAwHGujAmVmyVvjnXsTIbZ4QAA4LRIAJUTewlYQqrJkQAAALiOIB9PNYkMkpTXDQwAABSOBFA5sSWAkjOylZSWZXI0AAAArqO9rQyMfYAAALgoEkDlxNfLXdUCvSVRBgYAAOBI7c9tBL2eBBAAABdFAqgcxYTbysBIAAEAADhK23MJoD3Hz7LSGgCAiyABVI6ibJ3AWAEEAADgMFUDvVW3al7DjY0HTpscDQAAzokEUDmKCTvXCYwVQAAAAA5lLwNjI2gAAApFAqgc2UvAEukEBgAA4Ei2jaDZBwgAgMKRACpH9hIwVgABAAA4VLtzK4D+PHxGaVnZJkcDAIDzIQFUjmwrgI4mZygzO8fkaAAAAFxHrVBfRQb7KDvX0Jb4JLPDAQDA6ZAAKkfh/l7y93KXYUiHTqebHQ4AAIDLsFgslIEBAFAEEkDlyGKxUAYGAABQRmxlYCSAAAAoiARQObNvBJ3ARtAAAACOZFsBtOXgaWVl55ocDQAAzoUEUDmLCT/XCj6REjAAAABHql81QKF+nsqw5urPI2fMDgcAAKdCAqic2UvAaAUPAADgUG5uFrWlDAwAgEKRACpnMWG2EjD2AAIAAHC0DufKwDaQAAIAIB8SQOXMtgdQfGKaDMMwORoAAADXYtsIesOBROXmMtcCAMCGBFA5qxHiK3c3izKzc3XibKbZ4QAAALiUZjWC5OflruSMbO05ftbscAAAcBokgMqZp7ubaoT4SKIMDAAAwNE83N10ZUyopLxVQAAAIA8JIBPEhNk6gZEAAgAAcDRbGdg69gECAMCOBJAJom37ACXQCQwAAMDR2p+3ETR7LgIAkIcEkAmibZ3AWAEEAADgcK2jQuTpbtGJs5msuAYA4BwSQCagFTwAAEDZ8fF0V8taIZIoAwMAwIYEkAlsJWAH+UYKAACgTJxfBgYAAEgAmcJWApaQmqWUzGyTowEAAHA97c9tBL2eTmAAAEgiAWSKQB9Phfl7SZLi2AgaAADA4a6sHSqLJa/k/kRyhtnhAABgOhJAJrGtAqIMDAAAwPGCfDzVJCJIEquAAACQSACZJiacjaABAADKkm0foPXsAwQAAAkgs9AKHgAAoGyRAAIA4B+mJoBWr16t/v37q0aNGrJYLFq0aNFFz73//vtlsVg0Z86ccouvLFECBgAAULbandsIes/xszqTZjU5GgAAzGVqAig1NVWtWrXSW2+9VeR5ixYt0rp161SjRo1yiqzsxYT7S6IEDAAAoKxUDfRWnSr+MgxpYxyrgAAAlZuHmU/ep08f9enTp8hzDh8+rIceekg//PCD+vXrV06RlT3bCqDDSemy5uTK051qPAAAAEdrXztMsadStf5Aono0qW52OAAAmMbUBNCl5Obm6s4779QTTzyhZs2aFesxmZmZyszMtN9OTk6WJFmtVlmtjlv6a7tWaa8Z6uMmbw83ZWbnKu7UWcWcSwihdC53POBYjIfzYCycC+NRNN4XlIV2dcL06caD7AMEAKj0nDoB9NJLL8nDw0Njx44t9mNmzpypadOmFTi+bNky+fk5PsmyfPnyUj821NNdx7It+mLpKjUOMRwYVeV1OeMBx2M8nAdj4VwYj8KlpVEWDcfrcG4j6O2Hzig9K0e+Xu4mRwQAgDmcNgG0adMmvf7669q8ebMsFkuxHzdp0iSNHz/efjs5OVlRUVHq1auXgoKCHBaf1WrV8uXL1bNnT3l6epbqGosSN+vYnlOKqN9cfdtHOSy2ysgR4wHHYTycB2PhXBiPotlW7QKOVCvUVxFBPjqWnKEtB0+rU70qZocEAIApnDYB9Msvv+jEiROKjo62H8vJydFjjz2mOXPm6MCBA4U+ztvbW97e3gWOe3p6lslk+3KuW7tKgLTnlA6fyeQfAg5SVuOM0mE8nAdj4VwYj8LxnqAsWCwWtasTpm+3HdH62EQSQACASstpE0B33nmnrrvuunzHevfurTvvvFMjR440KSrHsu37E08nMAAAgDLT/lwCaMMB9gECAFRepiaAUlJStH//fvvt2NhYbd26VWFhYYqOjlZ4eHi+8z09PRUREaFGjRqVd6hlIjo8LwEUl0gCCAAAoKy0r523D9DmuCS6rwIAKi1TP/02btyoNm3aqE2bNpKk8ePHq02bNnr22WfNDKvcRIf5S5LiE1JlGGwCDQAAUBYaVAtQiJ+n0q05+vPwGbPDAQDAFKauAOrWrVuJEh8X2/enoooK85XFIqVm5SgxNUvhAQX3LgIAAMDlcXOzqG1MmH7cdVwbDiSqTXSo2SEBAFDuWP9qIm8Pd0UG+UiiDAwAAKAsta+Tl/RZH8s+QACAyokEkMmi2AgaAACgzLWvk7e35IYDp5WbS+k9AKDyIQFkshjbRtAkgAAAAMpMsxpB8vV015l0q/aeOGt2OAAAlDsSQCaLCT+3ETQlYAAAAGXG091NV8SESJI2UAYGAKiESACZzF4ClphqciQAAACurX3tvDKw9QdOmxwJAADljwSQyWLCKAEDAAAoD+3sG0EnlKgTLQAAroAEkMlsewCdOJup9Kwck6MBAABwXW2iQuXpbtHx5EwdTEw3OxwAAMoVCSCTBft6KtDHQ5J08DSrgAAAAMqKr5e7WtQMliStP8A+QACAyoUEkMksFgudwAAAAMpJuzphkvLKwAAAqExIADmBmDA6gQEAAJSHDucSQBvYCBoAUMmQAHIC9k5gCXQCAwAAKEtXxoTJYpFiT6XqxNkMs8MBAKDckAByAvYSMFYAAQAAlKlgX081jgiSJG2IZRUQAKDyIAHkBGyt4CkBAwAAKHvta+e1g9/ARtAAgEqEBJATiD63AuhQYrpycg2TowEAAHBtto2g18WSAAIAVB4kgJxAZLCvPN0tysrJ1bFkatEBAADKUvvaeQmg3ceSdSbdanI0AACUDxJATsDdzaJaobZW8GwEDQAAUJaqBfmodrifDEPaFMcqIABA5UACyElEn9sH6CD7AAEAAJS5dudWAa1nI2gAQCVBAshJ2BJAcQkkgAAAAMpa+3P7ALERNACgsiAB5CRoBQ8AAFB+bAmgPw4lKcOaY3I0AACUPRJAToISMAAAgPITHean6kHesuYY2hKfZHY4AACUORJATsLWCp4SMAAAgLJnsVjs+wBRBgYAqAxIADkJ2wqgM+lWnUmjHSkAAEBZs5WBrY8lAQQAcH0kgJyEn5eHqgZ6S5LiKQMDAAAoc7YE0Ob407Lm5JocDQAAZYsEkBOJsXUCS0w1ORIAAADX17BaoIJ9PZWWlaMdR5LNDgcAgDJFAsiJ0AoeAACg/Li5WdSudqgkaQNlYAAAF0cCyInYNoKOJwEEAAAkTZ06VRaLJd9PREREkY9ZtWqVrrzySvn4+Khu3bqaO3duOUVbMdk2gl7PRtAAABfnYXYA+EeMLQHEHkAAAOCcZs2a6ccff7Tfdnd3v+i5sbGx6tu3r+699159+OGH+u233zRmzBhVrVpVgwcPLo9wK5x2df7pBJaba8jNzWJyRAAAlA0SQE7EVgJGAggAANh4eHhcctWPzdy5cxUdHa05c+ZIkpo0aaKNGzdq9uzZJIAuonmNYPl6uispzar9J1PUsHqg2SEBAFAmSAA5kegwf0nSkTPpyszOkbfHxb/hAwAAlcO+fftUo0YNeXt7q0OHDpoxY4bq1q1b6Llr165Vr1698h3r3bu35s2bJ6vVKk9Pz0Ifl5mZqczMTPvt5OS8DZGtVqusVquDXons13LkNS+XRVLrqGCt/TtRa/afVJ0wH7NDKjfOOB6VGePhPBgL58J4FK0k7wsJICdSJcBLfl7uSsvK0eHT6apbNcDskAAAgIk6dOighQsXqmHDhjp+/LimT5+uTp06aceOHQoPDy9w/rFjx1S9evV8x6pXr67s7GydOnVKkZGRhT7PzJkzNW3atALHly1bJj8/P8e8mPMsX77c4de8HMFZbpLc9M2aHQo9td3scMqds41HZcd4OA/GwrkwHoVLSyt+BREJICdisVgUHean3cfOKi4xjQQQAACVXJ8+fez/36JFC3Xs2FH16tXTggULNH78+EIfY7Hk38PGMIxCj59v0qRJ+a6XnJysqKgo9erVS0FBQZfzEvKxWq1avny5evbsedHVSGYI/TtBS/+zSYetvurT55oi3ytX4qzjUVkxHs6DsXAujEfRbKt2i4MEkJOxJYDoBAYAAC7k7++vFi1aaN++fYXeHxERoWPHjuU7duLECXl4eBS6YsjG29tb3t7eBY57enqWyWS7rK5bWu3qVJWHm0XHkzN1PCVbUWGOX/XkzJxtPCo7xsN5MBbOhfEoXEneE9rAOxk6gQEAgIvJzMzUrl27LlrK1bFjxwJL5JctW6a2bdsyaS6Cr5e7WtQKliStj6UdPADANZEAcjK2TmBxrAACAKDSe/zxx7Vq1SrFxsZq3bp1GjJkiJKTkzV8+HBJeaVbd911l/380aNHKy4uTuPHj9euXbv0/vvva968eXr88cfNegkVRvva/7SDBwDAFZEAcjLR4XmdwOITU02OBAAAmO3QoUMaNmyYGjVqpEGDBsnLy0u///67YmJiJElHjx5VfHy8/fw6depoyZIlWrlypVq3bq3nn39eb7zxBi3gi6HduQQQK4AAAK6KPYCcTEzYPyVghmFUmk0IAQBAQZ988kmR98+fP7/Asa5du2rz5s1lFJHralc7TBaL9PepVJ08m6mqgQX3RAIAoCJzyAqgpKQkR1wGkmqG+srNImVYc3XybKbZ4QAAAFQKwX6ealQ9UBJlYAAA11TiBNBLL72kTz/91H576NChCg8PV82aNbVt2zaHBlcZebq7qUaIryQpjo2gAQAAyk37OpSBAQBcV4kTQP/+978VFRUlSVq+fLmWL1+u77//Xn369NETTzzh8AArI1snMDaCBgAAKD/t2AgaAODCSrwH0NGjR+0JoMWLF2vo0KHq1auXateurQ4dOjg8wMooOsxfvymBVvAAAADlyLYCaOfRZCVnWBXk42lyRAAAOE6JVwCFhobq4MGDkqSlS5fquuuukyQZhqGcnBzHRldJ2VrBxyfQCQwAAKC8VA/yUUy4nwxD2hR32uxwAABwqBIngAYNGqTbbrtNPXv2VEJCgvr06SNJ2rp1q+rXr+/wACsjewkYK4AAAADKFe3gAQCuqsQJoNdee00PPfSQmjZtquXLlysgIEBSXmnYmDFjHB5gZWRbAXSQBBAAAEC5spWBbSABBABwMSXeA8jT01OPP/54gePjxo1zRDyQFH1uBdCplCylZGYrwLvEwwQAAIBSaH9uBdAfh84ow5ojH093kyMCAMAxSrwCaMGCBfruu+/stydMmKCQkBB16tRJcXFxDg2usgry8VSoX96mg/F0AgMAACg3MeF+qhroraycXG09mGR2OAAAOEyJE0AzZsyQr6+vJGnt2rV66623NGvWLFWpUkWPPvpoia61evVq9e/fXzVq1JDFYtGiRYvs91mtVj355JNq0aKF/P39VaNGDd111106cuRISUOukKLD/SVJ8YlsBA0AAFBeLBYLZWAAAJdU4gTQwYMH7Zs9L1q0SEOGDNF9992nmTNn6pdffinRtVJTU9WqVSu99dZbBe5LS0vT5s2b9cwzz2jz5s368ssvtXfvXt14440lDblCirF1AmMfIAAAgHJlKwNbf4AEEADAdZR4c5mAgAAlJCQoOjpay5Yts6/68fHxUXp6eomu1adPH3sXsQsFBwdr+fLl+Y69+eabat++veLj4xUdHV3S0CsU20bQcZSAAQAAlCtbJ7DNcaeVnZMrD/cSf2cKAIDTKXECqGfPnrrnnnvUpk0b7d27V/369ZMk7dixQ7Vr13Z0fPmcOXNGFotFISEhFz0nMzNTmZmZ9tvJycmS8krKrFarw2KxXcuR1zxfzRBvSdKBU6ll9hyupKzHAyXDeDgPxsK5MB5F432Bs2gUEaggHw8lZ2Rr59FktawVYnZIAABcthIngN5++21NnjxZBw8e1BdffKHw8HBJ0qZNmzRs2DCHB2iTkZGhiRMn6rbbblNQUNBFz5s5c6amTZtW4PiyZcvk5+fn8LguXKXkKEeSJclDew6d0pIlS8rkOVxRWY0HSofxcB6MhXNhPAqXlsaqVzgHdzeL2tYO08+7T2h9bCIJIACASyhxAigkJKTQPXsKS7o4itVq1a233qrc3Fy98847RZ47adIkjR8/3n47OTlZUVFR6tWrV5GJo9LEtHz5cvXs2VOenp4Ou67N0TMZenPHaiVZ3dSrd0+WHl9CWY8HSobxcB6MhXNhPIpmW7XrapKTk/Xzzz+rUaNGatKkidnhoJja1/knAXRPl7pmhwMAwGUrcQJIkpKSkjRv3jzt2rVLFotFTZo00ahRoxQcHOzo+GS1WjV06FDFxsbq559/vmQSx9vbW97e3gWOe3p6lslku6yuWyvMQ14ebsrKztXJ1BxFhxd8TSiorMYDpcN4OA/GwrkwHoVzlfdk6NChuuaaa/TQQw8pPT1dbdu21YEDB2QYhj755BMNHjzY7BBRDLZ9gDYcSJRhGLJYLCZHBADA5SnxspKNGzeqXr16eu2115SYmKhTp07ptddeU7169bR582aHBmdL/uzbt08//vijvdysMnBzs9g3gqYTGAAAFcfq1avVpUsXSdJXX30lwzCUlJSkN954Q9OnTzc5OhRXi5rB8vF00+k0q/afSDE7HAAALluJE0CPPvqobrzxRh04cEBffvmlvvrqK8XGxuqGG27QuHHjSnStlJQUbd26VVu3bpUkxcbGauvWrYqPj1d2draGDBmijRs36qOPPlJOTo6OHTumY8eOKSsrq6RhV0j2TmCJqSZHAgAAiuvMmTMKC8tbPbJ06VINHjxYfn5+6tevn/bt22dydCguLw83tYkKlUQ7eACAayjVCqAnn3xSHh7/VI95eHhowoQJ2rhxY4mv1aZNG7Vp00aSNH78eLVp00bPPvusDh06pG+++UaHDh1S69atFRkZaf9Zs2ZNScOukOwrgGgFDwBAhREVFaW1a9cqNTVVS5cuVa9evSRJp0+flo+Pj8nRoSTa1clL5K2PJQEEAKj4SrwHUFBQkOLj49W4ceN8xw8ePKjAwMASXatbt24yDOOi9xd1X2UQE04JGAAAFc24ceN0++23KyAgQDExMerWrZukvNKwFi1amBscSqTDuQTQBhJAAAAXUOIE0C233KJRo0Zp9uzZ6tSpkywWi3799Vc98cQTZdoGvjKyl4CxAggAgApjzJgxat++vQ4ePKiePXvKzS1vwXXdunXZA6iCaRMdIg83i46cydCh02mqFepndkgAAJRaiRNAs2fPlsVi0V133aXs7GxJeV07HnjgAb344osOD7AyO38FEN0nAACoONq2bau2bdtKknJycrR9+3Z16tRJoaGhJkeGkvDz8lCzmsHadjBJ62MTSQABACq0Eu8B5OXlpddff12nT5/W1q1btWXLFiUmJmrWrFk6fvx4WcRYadUK9ZPFIqVkZisxtXJsfA0AQEU3btw4zZs3T1Je8qdr16664oorFBUVpZUrV5obHErMXgbGRtAAgAquxAkgGz8/P7Vo0UItW7aUn5+fdu7cqTp16jgytkrPx9NdEUF5m0WyDxAAABXD559/rlatWkmSvv32W8XGxmr37t0aN26cnn76aZOjQ0m1q81G0AAA11DqBBDKR1QYG0EDAFCRnDp1ShEREZKkJUuW6Oabb1bDhg01atQobd++3eToUFJtY/LK9v46mapTKZkmRwMAQOmRAHJyMWwEDQBAhVK9enXt3LlTOTk5Wrp0qa677jpJUlpamtzd3U2ODiUV6u+lRtXzOt1upAwMAFCBkQBycrSCBwCgYhk5cqSGDh2q5s2by2KxqGfPnpKkdevWqXHjxiZHh9JoVydvFdA6ysAAABVYsbuA/fHHH0Xev2fPnssOBgXZS8BYAQQAQIUwdepUNW/eXAcPHtTNN98sb29vSZK7u7smTpxocnQojfZ1wvXh7/FsBA0AqNCKnQBq3bq1LBaLDMMocJ/tOG3KHS8m3F+SFJeYanIkAACguIYMGVLg2PDhw02IBI7Q/txG0DuPJOtshlWBPp4mRwQAQMkVOwEUGxtblnHgImx7AB1PzlSGNUc+nuwdAACAs1u1apVmz56tXbt2yWKxqEmTJnriiSfUpUsXs0NDKUQE+ygqzFcHE9O1Ke60ujWqZnZIAACUWLETQDExMWUZBy4ixM9Tgd4eOpuZrYOJaWpwbhNCAADgnD788EONHDlSgwYN0tixY2UYhtasWaMePXpo/vz5uu2228wOEaXQvna4DiYe0oYDiSSAAAAVEptAOzmLxaLocDqBAQBQUbzwwguaNWuWPv30U40dO1aPPPKIPv30U7344ot6/vnnzQ4PpdT+3EbQ69kIGgBQQZEAqgBsncDi6AQGAIDT+/vvv9W/f/8Cx2+88UZK6iuw9nXCJUnbDp5RhjXH5GgAACg5EkAVQHRY3kbQB0kAAQDg9KKiovTTTz8VOP7TTz8pKirKhIjgCLXD/VQlwFtZObn649AZs8MBAKDEir0HEMwTHWYrAaMTGAAAzu6xxx7T2LFjtXXrVnXq1EkWi0W//vqr5s+fr9dff93s8FBKFotF7euEasn2Y1ofm6D2dcLMDgkAgBIhAVQBUAIGAEDF8cADDygiIkKvvPKK/ve//0mSmjRpok8//VQDBgwwOTpcjva1w/ISQAdOmx0KAAAlVuIEUJs2bWSxWAoct1gs8vHxUf369TVixAh1797dIQHinxVAhxLTlZtryM2t4PsPAACcx8CBAzVw4MB8x06fPq2FCxfqrrvuMikqXK5251b9bI47reycXHm4s5sCAKDiKPGn1vXXX6+///5b/v7+6t69u7p166aAgAD99ddfateunY4eParrrrtOX3/9dVnEWylFBvvIw82irJxcHUvOMDscAABQCvHx8Ro5cqTZYeAyNI4IUqC3h1Iys7Xr6FmzwwEAoERKvALo1KlTeuyxx/TMM8/kOz59+nTFxcVp2bJlmjJlip5//nmWOTuIh7ubaoX66kBCmuIS0lQjxNfskAAAACoddzeL2tYO1Yo9J7X+QKJa1Ao2OyQAAIqtxCuA/ve//2nYsGEFjt966632Ovdhw4Zpz549lx8d7KLD6QQGAABgNlsZ2PrYBJMjAQCgZEqcAPLx8dGaNWsKHF+zZo18fHwkSbm5ufL29r786GAXHZa36icukU5gAAAAZulwLgG08cBpGYZhcjQAABRfiUvAHn74YY0ePVqbNm1Su3btZLFYtH79er333nt66qmnJEk//PCD2rRp4/BgK7OYsLwVQHEJrAACAMAZvfHGG0Xef/jw4XKKBGWpRc0Q+Xq6KyE1S99sO6IBrWuaHRIAAMVS4gTQ5MmTVadOHb311lv64IMPJEmNGjXS//3f/+m2226TJI0ePVoPPPCAYyOt5KLPtYKPpwQMAACn9Nprr13ynOjo6HKIBGXJy8NNo7vW02s/7tWUb3aoU70qqhrIyncAgPMrcQJIkm6//XbdfvvtF73f15dNih3N1gqeBBAAAM4pNjbW7BBQTsZ0r6cfdhzTzqPJmrxou+becaUsFovZYQEAUKQS7wFkk5WVpUOHDik+Pj7fD8qGLQGUlGbVmXSrydEAAABUXp7ubnr55pbycLPohx3H9e0fR80OCQCASypxAmjfvn3q0qWLfH19FRMTozp16qhOnTqqXbu26tSpUxYxQpK/t4eqBOQtL45nHyAAAABTNasRrIeurS9JmvL1nzp5NtPkiAAAKFqJS8BGjBghDw8PLV68WJGRkSx3LUcx4X46lZKp+MQ0tagVbHY4AAAAldqYbvX1w47j2nU0Wc8s+lP/uuMK5sYAAKdV4gTQ1q1btWnTJjVu3Lgs4kERosP8tCnuNK3gAQAAnICXh5tm39xSA976TUt3HNPiP46qf6saZocFAEChSlwC1rRpU506daosYsEl2DeCpgQMAADAKTSrEawHu+eVgj379Z86lUIpGADAOZU4AfTSSy9pwoQJWrlypRISEpScnJzvB2UnhlbwAAA4PXd3d504caLA8YSEBLm7u5sQEcrag93rq3FEoE6nWfXs13+aHQ4AAIUqcQnYddddJ0nq0aNHvuOGYchisSgnJ8cxkaEA2wqgOFYAAQDgtAzDKPR4ZmamvLy8yjkalIe8UrBWGvD2b1qy/ZgW/3FEN7SkFAwA4FxKnABasWJFWcSBYog+twLo6Jl0ZWXnysujxAu4AABAGXnjjTckSRaLRe+9954CAgLs9+Xk5Gj16tXsoejCmtcM1oPd6umNn/fr2a936Kq64fYOrgAAOIMSJ4C6du1aFnGgGKoGeMvX013p1hwdTkpXnSr+ZocEAADOee211yTlrQCaO3duvnIvLy8v1a5dW3PnzjUrPJSDh65toGU7j2v3sbOa8vUOvX37FWaHBACAXbESQH/88YeaN28uNzc3/fHHH0We27JlS4cEhoIsFouiw/y05/hZxSWkkgACAMCJxMbGSpK6d++uL7/8UqGhoSZHhPJ2finYd9uPqu8fR9WvZaTZYQEAIKmYCaDWrVvr2LFjqlatmlq3bi2LxVJofTt7AJW96PC8BBAbQQMA4JwuLJfPycnR9u3bFRMTQ1KoEmheM1hjutXTmz/v1zNf/6mr6oYpnFIwAIATKFYCKDY2VlWrVrX/P8wTw0bQAAA4tXHjxqlFixYaNWqUcnJydM0112jt2rXy8/PT4sWL1a1bN7NDRBl76Nr6WrbjuPYcP6tnv9mht2+jFAwAYL5iJYBiYmIK/X+UP1rBAwDg3D777DPdcccdkqRvv/1WBw4c0O7du7Vw4UI9/fTT+u2330yOEGXN28Nds29upZve+U3f/XFU/VocVd8WlIIBAMxV4k2gJWnv3r1auXKlTpw4odzc3Hz3Pfvssw4JDIWLOrcCKJ4VQAAAOKWEhARFRERIkpYsWaKbb75ZDRs21KhRo+ydwuD6WtQK1gNd6+mtFfv1zKI/1aEOpWAAAHOVOAH0f//3f3rggQdUpUoVRUREyGKx2O+zWCwkgMpYTHjexs/xiWkyDCPf+w8AAMxXvXp17dy5U5GRkVq6dKneeecdSVJaWlq+zmBwfQ/3qK/lO/NKwaZ8s0NvUQoGADBRiRNA06dP1wsvvKAnn3yyLOLBJdQM8ZWbRUq35uhkSqaqBfqYHRIAADjPyJEjNXToUEVGRspisahnz56SpHXr1qlx48YmR4fy5O3hrpdvbqmB76zR4nOlYH0oBQMAmMStpA84ffq0br755rKIBcXg5eGmyGBfSZSBAQDgjKZOnar33ntP9913n3777Td5e+eV/bi7u2vixIkmR4fy1rJWiEZ3rStJeubrP5WYmmVyRACAyqrECaCbb75Zy5YtK4tYUEy2jaDpBAYAgHMaMmSIHn30UVWpUsV+bPjw4RowYICJUcEsY3s0UINqATqVkqUp3+wwOxwAQCVV4hKw+vXr65lnntHvv/+uFi1ayNPTM9/9Y8eOdVhwKFxMuJ/W/JVAJzAAAJxQTk6OZsyYoblz5+r48ePau3ev6tatq2eeeUa1a9fWqFGjzA4R5czWFWzQv9bo221H1K9FhK5vTikYAKB8lTgB9O677yogIECrVq3SqlWr8t1nsVhIAJUDeycwEkAAADidF154QQsWLNCsWbN077332o+3aNFCr732GgmgSqpVVIjuv6au3ln5lyYv+lMd6oQr1N/L7LAAAJVIiRNAsbGxZREHSiAmLK8TWFxCqsmRAACACy1cuFDvvvuuevToodGjR9uPt2zZUrt37zYxMpjtkesaaPnO49p3IkVTvtmhN4a1MTskAEAlUuI9gBxp9erV6t+/v2rUqCGLxaJFixblu98wDE2dOlU1atSQr6+vunXrph07qJu27QHECiAAAJzP4cOHVb9+/QLHc3NzZbVaTYgIziKvK1gruVmkb7Yd0dI/j5kdEgCgEinWCqDx48fr+eefl7+/v8aPH1/kua+++mqxnzw1NVWtWrXSyJEjNXjw4AL3z5o1S6+++qrmz5+vhg0bavr06erZs6f27NmjwMDAYj+Pq7GVgJ1KyVJqZrb8vUu8kAsAAJSRZs2a6ZdfflFMTEy+45999pnatGHFR2XXOipE93etp3/ZS8HCKAUDAJSLYmUOtmzZYv/GasuWLRc9z2KxlOjJ+/Tpoz59+hR6n2EYmjNnjp5++mkNGjRIkrRgwQJVr15d//3vf3X//feX6LlcSbCvp0L8PJWUZlV8YpqaRAaZHRIAAJXe3Xffrddff11TpkzRnXfeqcOHDys3N1dffvml9uzZo4ULF2rx4sVmhwkn8EiPvFKw/SdSNO3bHZpzK4lBAEDZK1YCaMWKFYX+f1mKjY3VsWPH1KtXL/sxb29vde3aVWvWrLloAigzM1OZmZn228nJyZIkq9Xq0GXXtmuZtZQ7OtRXSWlW/X0iWfWr+JoSgzMxezyQH+PhPBgL58J4FK2ivy8LFizQiy++qP79++vTTz/VjBkzZLFY9Oyzz+qKK67Qt99+q549e5odJpyAj6e7Xh7SUoP/tUaLth5R3xaR6tUswuywAAAuzmlrh44dy6uJrl69er7j1atXV1xc3EUfN3PmTE2bNq3A8WXLlsnPz8+xQUpavny5w69ZHB4ZbpLctGzNZmUfMEyJwRmZNR4oHOPhPBgL58J4FC4trWLvbWcY/3we9+7dW7179zYxGji7NtGhuveauvr3qr/11Fd/qn2dMIX4UQoGACg7pUoAbdiwQZ999pni4+OVlZWV774vv/zSIYHZXFhWZhhGkaVmkyZNyrdPUXJysqKiotSrVy8FBTmuVMpqtWr58uXq2bOnPD09HXbd4trtuU+bV8fKv3qM+vZtWu7P72zMHg/kx3g4D8bCuTAeRbOt2q3ISloOj8rt0esa6sedx/XXyVRN+3anXrultdkhAQBcWIkTQJ988onuuusu9erVS8uXL1evXr20b98+HTt2TAMHDnRYYBERectgjx07psjISPvxEydOFFgVdD5vb295e3sXOO7p6Vkmk+2yuu6l1Kmatwn2wdMZ/CPiPGaNBwrHeDgPxsK5MB6Fc4X3pGHDhpdMAiUmJpZTNHB2Pp55XcGG/GuNvtpyWH1bRKpn04vPcwEAuBwlTgDNmDFDr732mh588EEFBgbq9ddfV506dXT//ffnS9Rcrjp16igiIkLLly+3d8zIysrSqlWr9NJLLznseSqq6HOt4A/SCh4AAKcxbdo0BQcHmx0GKpArokN1b5e6+vfqv/XUV9vVrnYopWAAgDJR4gTQX3/9pX79+knKW22Tmpoqi8WiRx99VNdee22h++9cTEpKivbv32+/HRsbq61btyosLEzR0dEaN26cZsyYoQYNGqhBgwaaMWOG/Pz8dNttt5U0bJcTfa4V/KHT6crOyZWHu5vJEQEAgFtvvVXVqlUzOwxUMI/2bKgfd+WVgj337U69SikYAKAMlDhrEBYWprNnz0qSatasqT///FOSlJSUVOLNGzdu3Kg2bdrYV/iMHz9ebdq00bPPPitJmjBhgsaNG6cxY8aobdu2Onz4sJYtW6bAwMCShu1yIoJ85OXhpuxcQ0fPZJgdDgAAlR77/6C0bKVgbhbpyy2H9ePO42aHBABwQSVOAHXp0sXevWTo0KF65JFHdO+992rYsGHq0aNHia7VrVs3GYZR4Gf+/PmS8iZSU6dO1dGjR5WRkaFVq1apefPmJQ3ZJbm5WRQVmtf+PS6BMjAAAMx2fhcwoKSuiA7VPV3qSpKe+mq7zqRZTY4IAOBqSlwC9tZbbykjI2/FyaRJk+Tp6alff/1VgwYN0jPPPOPwAHFx0WF++utkquLZBwgAANPl5uaaHQIquPHnSsH+PpmqaYt36NWhrc0OCQDgQkq0Aig7O1vffvut3NzyHubm5qYJEybom2++0auvvqrQ0NAyCRKFiwn3lyTFJaaaHAkAAAAul4+nu14e0koWi/Tl5sP6aRelYAAAxylRAsjDw0MPPPCAMjMzyyoelIBtI+h4SsAAAABcwpUxobrn6jqSpElfUgoGAHCcEu8B1KFDB23ZsqUsYkEJ2RNAlIABAAC4jMd6NVLdKv46cTZTzy3eaXY4AAAXUeI9gMaMGaPHHntMhw4d0pVXXil/f/9897ds2dJhwaFoMeH/rAAyDIPuIwAAAC7Ax9Nds4a01M3/XqsvNh9Sv5YRurZxdbPDAgBUcMVeAXT33XcrOTlZt9xyi2JjYzV27Fh17txZrVu3Vps2bez/RfmJOrcC6Gxmtk6zPBgAAJc3c+ZMWSwWjRs37qLnrFy5UhaLpcDP7t27yy9QXLa2tcM0qvN5pWDpzPUAAJen2CuAFixYoBdffFGxsbFlGQ9KwMfTXRFBPjqWnKH4xDSF+XuZHRIAACgjGzZs0Lvvvlvs1dZ79uxRUFCQ/XbVqlXLKjSUkcd6NdJPu08o9lSqnl+8U7NvbmV2SACACqzYK4AMw5AkxcTEFPmD8mXbBygugU5gAAC4qpSUFN1+++36v//7v2J3Xa1WrZoiIiLsP+7u7mUcJRzN18tdLw9pKYtF+nzTIa3YfcLskAAAFViJ9gBijxnnEx3up/UHEukEBgCAC3vwwQfVr18/XXfddZo+fXqxHtOmTRtlZGSoadOmmjx5srp3737RczMzM/N1eU1OTpYkWa1WWa2OKz2yXcuR13R1rWoGakTHGP1nTZwmfvmHljzUSUG+ng65NuPhXBgP58FYOBfGo2gleV9KlABq2LDhJZNAiYmJJbkkLlMMncAAAHBpn3zyiTZv3qwNGzYU6/zIyEi9++67uvLKK5WZmakPPvhAPXr00MqVK3XNNdcU+piZM2dq2rRpBY4vW7ZMfn5+lxV/YZYvX+7wa7qypjlSFR93HU/O1Jj/+0m31c916PUZD+fCeDgPxsK5MB6FS0srfi6gRAmgadOmKTg4uMQBoexEn+sEFkcCCAAAl3Pw4EE98sgjWrZsmXx8fIr1mEaNGqlRo0b22x07dtTBgwc1e/bsiyaAJk2apPHjx9tvJycnKyoqSr169cq3j9DlslqtWr58uXr27ClPT8esYqksarY4rdvf36B1J9107/VXqmvDy9/TifFwLoyH82AsnAvjUTTbqt3iKFEC6NZbb1W1atVKHBDKjm0PIErAAABwPZs2bdKJEyd05ZVX2o/l5ORo9erVeuutt5SZmVmsvX2uuuoqffjhhxe939vbW97e3gWOe3p6lslku6yu68o6NaimEZ1q6z+/HdDkr3dp2fiqCvJxzHvIeDgXxsN5MBbOhfEoXEnek2JvAs3+P84pJtxfknQsOUMZ1hyTowEAAI7Uo0cPbd++XVu3brX/tG3bVrfffru2bt1a7I2dt2zZosjIyDKOFmVtQu/Gign307HkDL2weJfZ4QAAKphirwCydQGDcwn181SAt4dSMrN16HSa6lcLNDskAADgIIGBgWrevHm+Y/7+/goPD7cfnzRpkg4fPqyFCxdKkubMmaPatWurWbNmysrK0ocffqgvvvhCX3zxRbnHD8fK6wrWSre8u1afbjyoPi0i1K0Rq/MBAMVT7BVAubm5lH85IYvFcl4reMrAAACobI4ePar4+Hj77aysLD3++ONq2bKlunTpol9//VXfffedBg0aZGKUcJT2dcI0vGNtSdKkL7crOYOuOACA4inRHkBwTjHhftp5NJkEEAAAlcDKlSvz3Z4/f36+2xMmTNCECRPKLyCUuwnXN9KKPScUl5CmGd/t0ouDW5odEgCgAij2CiA4L1snMFrBAwAAuD4/Lw/NOpf0+WTDQa3ae9LkiAAAFQEJIBdg7wRGAggAAKBS6FA3XCM61ZYkTfziD0rBAACXRALIBcSE5XUCi0tINTkSAAAAlJcJ1zdSdJifjp7J0MwldAUDABSNBJALiDlXAnbwdLpyc+nWBgAAUBn4eXlo1pC8UrCP1x/UakrBAABFIAHkAiKDfeThZlFWdq6On80wOxwAAACUk6vqhmt4xxhJeaVgZykFAwBcBAkgF+Dh7qaaob6SaAUPAABQ2Uy4vrGiwnx15EyGZizZbXY4AAAnRQLIRdg3giYBBAAAUKn4e3to1uBWkqSP18fr132nTI4IAOCMSAC5CDqBAQAAVF4d64XrrnOlYE9SCgYAKAQJIBdh2wg6jgQQAABApfTk9Y1VK9RXh5PSNfN7SsEAAPmRAHIR0edawcfTCh4AAKBS8vf+pyvYf9dRCgYAyI8EkIugBAwAAACd6lXRnVf9UwqWkpltckQAAGdBAshFRJ8rATudZlUyNd8AAACV1sQ+55WCLdlldjgAACdBAshFBHh7qEqAlyQ6gQEAAFRmeV3B8krBPloXr9/2UwoGACAB5FIoAwMAAIAkdapfRbd3iJYkTficUjAAAAkgl2JLAMWxAggAAKDSm9S3iWqG5JWCvURXMACo9EgAuZDo8HOdwBLpBAYAAFDZBZzXFeyD3+O0hlIwAKjUSAC5kBhWAAEAAOA8netX0W22UrAv/lAqpWAAUGmRAHIhtk5g7AEEAAAAm6fOlYIdOp2ul5ZSCgYAlRUJIBdiWwF0JCldWdm5JkcDAAAAZxDg7aGXznUFW7g2Tmv+ohQMACojEkAupGqgt3w83ZRrSIeT0s0OBwAAAE7i6gZVNKx9XinYk5SCAUClRALIhVgsFlrBAwAAoFBP9W2smiG+OpiYrlmUggFApUMCyMVEh53rBJZAJzAAAAD8I9DHUy8ObiFJWrA2TutiE02OCABQnkgAuZiYcDqBAQAAoHBdGlTVsPZRkqRJX+1QZo7JAQEAyg0JIBcTQycwAAAAFOGpvk1UI9hHB0+n66sDbjIMw+yQAADlgASQi4liDyAAAAAUIa8ULK8r2NoTbnr88z+VYWUpEAC4OhJALibmvAQQ3+YAAACgMNc0rKrnb2wqNxn65o+juuO9dUpIyTQ7LABAGSIB5GJqhfrJYpHSsnJ0kg9xAAAAXMSt7Wrp/ia5CvTx0Ma407rpnd+07/hZs8MCAJQREkAuxsvDTTWCfSVJBykDAwAAQBEahxj6373tFRWW1x5+0L/W6Jd9J80OCwBQBkgAuaDoMDqBAQAAoHjqVwvQojGd1TYmVGczsjXiPxv04e9xZocFAHAwp04AZWdna/LkyapTp458fX1Vt25dPffcc8rNzTU7NKdGK3gAAACURHiAtz66t4MGtqmpnFxDkxf9qee+3amcXPaUBABX4WF2AEV56aWXNHfuXC1YsEDNmjXTxo0bNXLkSAUHB+uRRx4xOzynZesERgkYAAAAisvbw12vDm2lulX89cryvXr/t1jFJaTq9WFtFODt1P9sAAAUg1OvAFq7dq0GDBigfv36qXbt2hoyZIh69eqljRs3mh2aU7OvACIBBAAAgBKwWCx6uEcDvXVbG3l7uOmn3Sd089y1OpKUbnZoAIDL5NSp/Kuvvlpz587V3r171bBhQ23btk2//vqr5syZc9HHZGZmKjPzn+5XycnJkiSr1Sqr1eqw2GzXcuQ1HaVmkLckKS4h1SnjKwvOPB6VEePhPBgL58J4FI33BXAeN7SsoZohvrp34UbtOpqsAW//pvfuaqtWUSFmhwYAKCWnTgA9+eSTOnPmjBo3bix3d3fl5OTohRde0LBhwy76mJkzZ2ratGkFji9btkx+fn4Oj3H58uUOv+blSsuWJA+dSsnSV98ukbe72RGVH2ccj8qM8XAejIVzYTwKl5bGylXAmbSJDtWiBztr1PyN2nP8rG55d61eHdpafVtEmh0aAKAUnDoB9Omnn+rDDz/Uf//7XzVr1kxbt27VuHHjVKNGDQ0fPrzQx0yaNEnjx4+3305OTlZUVJR69eqloKAgh8VmtVq1fPly9ezZU56eng67rqO8+OfPOpOerabtuqhRRKDZ4ZQ5Zx+PyobxcB6MhXNhPIpmW7ULwHnUCvXT5w901MMfb9HKPSc15qPNeqJ3I43pVk8Wi8Xs8AAAJeDUCaAnnnhCEydO1K233ipJatGiheLi4jRz5syLJoC8vb3l7e1d4Linp2eZTLbL6rqXKybcX38cOqPDyVlqHuV88ZUVZx2PyorxcB6MhXNhPArHewI4p0AfT713V1tN/26X5q85oJd/2KO/T6Zq5qAW8vJw6i1FAQDnceq/sdPS0uTmlj9Ed3d32sAXQzSdwAAAAOAgHu5umnpjMz03oJncLNIXmw/pjnnrdDo1y+zQAADF5NQJoP79++uFF17Qd999pwMHDuirr77Sq6++qoEDB5odmtOzJYDiEkgAAQAAwDHu6lhb749op0BvD62PTdTAd37TXydTzA4LAFAMTp0AevPNNzVkyBCNGTNGTZo00eOPP677779fzz//vNmhOT1awQMAAKAsdGtUTV+M6aRaob46kJCmgW//pjV/nTI7LADAJTh1AigwMFBz5sxRXFyc0tPT9ddff2n69Ony8vIyOzSnFx3mL0mKT0g1ORIAAAC4mobVA7Xowc66IjpEyRnZumveen26Id7ssAAARXDqBBBKL/rcCqBDp9OVk2uYHA0AAABcTZUAb/333qt0Y6says419OQX2zVzyS7lMvcEAKdEAshFRQT5yMvdTdm5ho4kpZsdDgAAAFyQj6e7Xr+1tR7p0UCS9O/Vf2v0h5uUlpVtcmQAgAuRAHJR7m4W1QrzlSTFsw8QAAAAyojFYtGjPRvq9Vtby8vdTct2HtfQf6/VsTMZZocGADgPCSAXZusERgIIAAAAZW1A65r6+L4OCvf30p+HkzXg7V/15+EzZocFADiHBJALi6EVPAAAAMrRlTFhWvRgZzWoFqDjyZm6ee5aLdtxzOywAAAiAeTSosPPdQJLpBMYAAAAykdUmJ++GNNJXRpUUbo1R/d/uEnvrv5LhsHm0ABgJhJALiyGEjAAAACYIMjHU/8Z0U53XhUjw5BmLNmtSV9uV1Z2rtmhAUClRQLIhdlawcclpPGNCwAAAMqVh7ubnhvQTFP6N5WbRfpkw0ENf3+9zqRZzQ4NAColEkAuzLYJ9NmMbCXxQQsAAIByZrFYNLJzHb03vK38vdy19u8EDXznNx04xRYFAFDeSAC5MB9Pd1UP8pYkxVEGBgAAAJNc27i6Pn+gk2oE++jvU6m66Z3ftO7vBLPDAoBKhQSQi6MVPAAAAJxBk8ggLXqos1pFhSgpzao75q3T55sOmR0WAFQaJIBcXHTYuU5gCSyzBQAAgLmqBfro0/uuUr8WkbLmGHr8s22atXS3cnPZrxIAyhoJIBcXc95G0AAAAIDZfDzd9eawNnqoe31J0jsr/9JDH29WelaOyZEBgGsjAeTiKAEDAACAs3Fzs+jx3o30ys2t5Olu0ZLtx3Tru2t1IjnD7NAAwGWRAHJxtlbwJIAAAADgbAZfWUsf3XOVQv08te3QGd309m/aeSTZ7LAAwCWRAHJxMedWAB1LzlCGlWW1AAAAcC7t64Rp0YOdVa+qv46cydDNc9fop13HzQ4LAFwOCSAXF+bvJX8vdxmGdOh0utnhAAAAAAXEhPvrywc6q3P9cKVm5ejehRs179dYGQabQwOAo5AAcnEWi0XR4ec6gSXSCQwAAADOKdjPU/NHttew9tHKNaTnF+/U5EV/ypqTa3ZoAOASSABVArYyMDqBAQAAwJl5urtpxsDmmtyviSwW6aN18bp7/gadSbeaHRoAVHgkgCoBWsEDAACgorBYLLqnS129e2db+Xm565d9pzT4X2sUz1wWAC4LCaBKIOrcCqCDdAIDAABABdGzaXX97/6Oigjy0f4TKbrpnd+08UCi2WEBQIVFAqgSsK8AIgEEAACACqR5zWB9/VBntagZrMTULN32f+u0aMths8MCgAqJBFAlEBNm2wQ6Tbm5dFIAAABAxVE9yEef3n+Vrm8WoaycXI37dKteXbaHDmEAUEIkgCqByBAfubtZlJWdqxNnM80OBwAAACgRPy8PvXP7FRrdtZ4k6Y2f9+vhj7cow5pjcmQAUHGQAKoEPN3dVDPEV5IUl0AreAAAAFQ8bm4WTezTWLOGtJSHm0WL/ziqYf/3u07yBScAFAsJoEqCfYAAAADgCoa2jdIHozoo2NdTW+KTdNPbv+nPw2fMDgsAnB4JoEqCTmAAAABwFR3rheurMZ1Up4q/Diel68a3ftWUr//UmTSr2aEBgNMiAVRJxJxLAMUlkAACAABAxVe3aoC+GtNJfVtEKNeQFqyNU/dXVurj9fHKofEJABRAAqiSoAQMAAAAribEz0vv3H6lPrqngxpUC1BiapYmfbldN739mzbHnzY7PABwKiSAKonoc63gKQEDAACAq+lcv4qWPNJFz9zQVIHeHtp++IwGvbNGj/1vm06czTA7PABwCiSAKonocyuAElOzdDaD2mgAAAC4Fk93N426uo5+frybbr6yliTpi82HdO3sVXrvl79lzck1OUIAMBcJoEoiwNtD4f5ektgHCAAAAK6raqC3Xr65lb4a00mtagUrJTNb07/bpT6v/6Jf950yOzwAMA0JoErEtgoonjIwAAAAuLg20aH6akxnvTS4hcL9vbT/RIrumLdOoz/YxLYIAColEkCVSHQYCSAAAABUHm5uFt3SLlo/P95NIzrVlrubRUt3HNN1r67SnB/3KsOaY3aIAFBuSABVIrSCBwAAQGUU7OupqTc205KxXXRV3TBlZudqzo/7dN2rq7T0z2MyDNrGA3B9JIAqkejwvE5g8YmpJkcCAAAAlL9GEYH6+N6r9NZtbRQZ7KNDp9M1+sNNuuv99dp/IsXs8ACgTJEAqkQoAQMAAEBlZ7FYdEPLGvrpsa56qHt9ebm76Zd9p3T9nNV64buddMwF4LJIAFUiMec2gT6SlEEbTAAAAFRqfl4eerx3Iy0ff42ua1JN2bmG/u+XWHWfvUqfbzqk3FzKwgC4FhJAlUi1QG95e7gpJ9fQ4dPpZocDAAAAmC4m3F/vDW+n/4xsp7pV/HUqJVOPf7ZNQ+au0fZDZ8wODwAchgRQJWKxWCgDAwAAAArRvVE1LR13jSb2aSx/L3dtjk/SjW//qklf/qHE1CyzwwOAy0YCqJKxlYHFkQACAKDCmTlzpiwWi8aNG1fkeatWrdKVV14pHx8f1a1bV3Pnzi2fAIEKzsvDTaO71tPPj3fTTa1ryDCkj9cfVLeXV2jBmgPKZhsFABUYCaBKJjrsXCewBDqBAQBQkWzYsEHvvvuuWrZsWeR5sbGx6tu3r7p06aItW7boqaee0tixY/XFF1+UU6RAxVc9yEdzbm2jz0Z3VNPIICVnZGvKNzt0w5u/at3fCWaHBwClQgKokrGvAEpgBRAAABVFSkqKbr/9dv3f//2fQkNDizx37ty5io6O1pw5c9SkSRPdc889uvvuuzV79uxyihZwHe1qh+nbh6/W8zc1V4ifp3YfO6tb3v1dD3+8RUfPsKcmgIrFw+wAUL7YAwgAgIrnwQcfVL9+/XTddddp+vTpRZ67du1a9erVK9+x3r17a968ebJarfL09CzwmMzMTGVmZtpvJycnS5KsVqusVse1xLZdy5HXROkxHsV365U11LtJFb324359svGQvt12RD/tOq4HrqmjkZ1ry9vj8r9XZzycB2PhXBiPopXkfSEBVMlEh/+TADIMQxaLxeSIAABAUT755BNt3rxZGzZsKNb5x44dU/Xq1fMdq169urKzs3Xq1ClFRkYWeMzMmTM1bdq0AseXLVsmPz+/0gVehOXLlzv8mig9xqP4rvKQarWQPo91V+zZHL3y434t+HWfBtXOVbNQx7SNZzycB2PhXBiPwqWlFX9xh9MngA4fPqwnn3xS33//vdLT09WwYUPNmzdPV155pdmhVUi1Qn1lsUhpWTk6lZKlqoHeZocEAAAu4uDBg3rkkUe0bNky+fj4FPtxF37BYxhGocdtJk2apPHjx9tvJycnKyoqSr169VJQUFApIi+c1WrV8uXL1bNnz0JXIqF8MR6ld69h6Js/jmnWD3t14mym3t3trm4Nq2hy38b2LRdKivFwHoyFc2E8imZbtVscTp0AOn36tDp37qzu3bvr+++/V7Vq1fTXX38pJCTE7NAqLG8Pd0UG+ejImQzFJ6aRAAIAwIlt2rRJJ06cyPfFV05OjlavXq233npLmZmZcnd3z/eYiIgIHTt2LN+xEydOyMPDQ+Hh4YU+j7e3t7y9C84JPD09y2SyXVbXRekwHqUzpG20rm9RQ2/+vE/v/xqrlXtPac1fa3RPlzp6sHt9+XuX7p9ajIfzYCycC+NRuJK8J06dAHrppZcUFRWl//znP/ZjtWvXNi8gFxEd7ncuAZSqK2OK3kgSAACYp0ePHtq+fXu+YyNHjlTjxo315JNPFkj+SFLHjh317bff5ju2bNkytW3blokz4GAB3h6a1KeJhraN0nPf7tSqvSf1zsq/9OXmw3qqXxP1bxnJlgsAnIZTJ4C++eYb9e7dWzfffLNWrVqlmjVrasyYMbr33nsv+hg2Mby0qFBf/S4p9kRKhYy/MBV5PFwR4+E8GAvnwngUjfeloMDAQDVv3jzfMX9/f4WHh9uPT5o0SYcPH9bChQslSaNHj9Zbb72l8ePH695779XatWs1b948ffzxx+UeP1BZ1KsaoPkj2+nHXSf03OIdOpiYrrEfb9FHv8dp6o3N1CTScaWUAFBaTp0A+vvvv/Wvf/1L48eP11NPPaX169dr7Nix8vb21l133VXoY9jE8NLSTlgkuWvtn/tUL2OP2eE4VEUcD1fGeDgPxsK5MB6FK8kmhvjH0aNHFR8fb79dp04dLVmyRI8++qjefvtt1ahRQ2+88YYGDx5sYpSA67NYLOrZtLq6NKii/1v9t95euV/rYhPV741fdOdVMRrfs5GC/ViFB8A8Tp0Ays3NVdu2bTVjxgxJUps2bbRjxw7961//umgCiE0ML83YfkzfHfxDub5h6tu3vdnhOERFHg9XxHg4D8bCuTAeRSvJJoaV2cqVK/Pdnj9/foFzunbtqs2bN5dPQADy8fF018M9GmjQlbU047td+m77US1YG6dv/ziqJ3o30tC2UXJ3oywMQPlz6gRQZGSkmjZtmu9YkyZN9MUXX1z0MWxieGl1qwVKkuJPp1e42C+lIo6HK2M8nAdj4VwYj8LxngBwJTVDfPX27Vfo9v2nNPXbHdp7PEWTvtyu/66L17QBzXRFNHtxAihfbmYHUJTOnTtrz578JUp79+5VTEyMSRG5hpgwf0nSybOZSsvKNjkaAPj/9u49Pqr6zv/4+8w1M8lM7ldIuN+SiCAgoGixKILV1V1bty662N3fdm3R1fKztVovtVXpve6vPmQftG7bFS9dtVRXCgIqXhdB7sRwhySEhNwzuc5Mkvn9MZMhkYuAhJnMvJ6PRx6Zc+bMySf5EvLNO98LAACx67LRGVr5b1fokesL5UqwaGdls/7umY/0f/97u2paOiNdHoA4EtUB0He+8x1t2LBBTz75pPbv368XXnhBy5Yt06JFiyJd2qCW7LTKnRAc/FXR0BHhagAAAIDYZjWb9E+zRuid+2brlqlDJUmvbjmiL//iXf3u/YPyd/dEuEIA8SCqA6Bp06ZpxYoVevHFF1VcXKwf//jHeuqpp7RgwYJIlzboDUsPjgIqq2+LcCUAAABAfMhIsutnX71Yf1l0uS4emqxWb5ceX1mq+f/+vj48UB/p8gDEuKheA0iSrr/+el1//fWRLiPmFKQ7tbOyWeUN7LgCAAAAXEiT8lO04tuX65XNR/TT1bu1v6ZVd/xhs4YnmdWRU6kbJ+fLYTNHukwAMSaqRwBh4BSkOSWJAAgAAACIAJPJ0C3T8vX2fbP1jcuHy2IydLjV0PdXlOjSJ9fp0dd2aXc1uyMCOH8IgOLUsFAAVFZPAAQAAABESrLDqkdvKNJ7912p6wu6lZ/qUEtnl/74v2Wa99T7+rtnPtTLn1Sow9cd6VIBDHJRPwUMA6MgnRFAAAAAQLTIdNl1zZCAfjlvljaWN+vFjeVaU3JMW8qbtKW8ST9641P93eQhunV6gcbnuCNdLoBBiAAoTvVOATvS2K7unoDMJiPCFQEAAAAwmQxdMSZTV4zJVE1Lp17ZfEQvbaxQeUO7/vi/Zfrj/5bpkoIU3Xppga6fmMdaQQDOGAFQnMpNdshqNuTvDqiquUNDU52RLgkAAABAH1muBH179mjdeeUofXigjlFBAL4QAqA4ZTYZyk916mBdm8rr2wmAAAAAgCjFqCAA5wOLQMexfHYCAwAAAAaV3lFB6++bref++VJdd1GOLCZDW8qb9N1XdrCDGIBTYgRQHBsWWgi6jAAIAAAAGFQYFQTgbBEAxbHehaDL2QoeAAAAGLRYKwjAmSAAimPD0hMlSWUNbRGuBAAAAMAXxaggAKdDABTHGAEEAAAAxCZGBQH4LAKgONYbAHk6u9TU7lOK0xbhigAAAACcT4wKAtCLXcDimMNmVpbLLkn6n+1H5e/uiXBFAAAAAAYKO4gB8Y0RQHFufK5bNS21evi1Ej39zn79/bQC3XppvnKTHZEuDQAAAMAAYFQQEJ8YARTnfnXLxVp01ShlJNl0zOPV/3trn2b99B3963Of6P19terpCUS6RAAAAAADhFFBQPxgBFCcy0iy67vXjtc9c8ZqdUm1lm8o08ZDDXqz5JjeLDmm4elOLZg+TF+dMlSpiawRBAAAAMQiRgUBsY8ACJIkm8Wkv7k4T39zcZ72HmvR8xvK9OctlTpc364n/lqqn6/Zo+sn5uq2GcM0OT9FhmFEumQAAAAAA4AdxIDYRACEE4zNdumxG4v1vXnj9fr2o1q+oUwlRz3685ZK/XlLpQpz3bptxjDdOClPiXb+CQEAAACxiFFBQGzht3ecUqLdolsvLdDXp+VrW0WTnttQpjd2VOnTKo8eXLFTS/5aqr+7ZIgWzBimsdmuSJcLAAAAYICc6aigr19aoAm5jAoCohEBED6XYRiaXJCqyQWpevgrhXpl8xE9/3GZDtcfT/4vHZGm22YM07yiHNksrC0OAAAAxKIzGRU0KjNR84tzNa84R0V5bpaPAKIEARDOSmqiTf9y5Uj986wR+vBAnZZvKNO60hptPNSgjYcalJFk0y1T83XrpQXKT3NGulwAAAAAA+Szo4Je+Lhc60qP6UBtm55+Z7+efme/hqY6NK8oR/OKc3RJQapMJsIgIFIIgHBO+ib/1c2denFjuV7aVK5jHq+eWX9AS989oKvGZen2GcN05dhMmfmPHgAAAIhJfX838HT69c7uGq3eVa31e2p1pLFDv/vgkH73wSFluuyaW5it+cW5mj4yTVYzMweAC4kACF9YTnKCvnPNWN315dF6q/SYlm8o1wf76/T27hq9vbtGQ1Md+ofpBbplar4ykuyRLhcAAADAAHEnWHXjpCG6cdIQdfi69e7eWr1ZUq11pcdU2+LV8x+X6/mPy5XssOrqCdmaX5yjWWMylGBlAWlgoBEA4byxmk2aV5yrecW5Oljbquc/Ltcrm4/oSGOHfrZ6j369dq/mFwe3kp82PJW5wAAAAEAMc9jMmlccnP7l6+rRRwfq9GZJtdaUHFN9m0+vbjmiV7ccUaLNrNnjszS/OEezx2UpiZ2GgQHBdxYGxMjMJD18faG+e+04/c/2o1r+cbm2VzTp9e1H9fr2oxqbnaTbZgzT304eIleCNdLlAgAAABhANotJs8dlafa4LD1+U0CbDjdo9a5qvVlSrarmTq3cUaWVO6pks5h05ZgMXVuUo2sKs5XitEW6dCBmEABhQCVYzfra1Hx9bWq+dlU2a/mGMr227aj2HmvVI6+V6CerduvGSUN024wCFeUlR7pcAAAAAAPMbDI0Y2S6ZoxM16M3FGrHkWat2lWt1buqdLi+XetKa7SutEZmk6GZI9N1bXGOri3KVpYrIdKlA4MaARAumOIhyfrJzRP1wHUTtGLLES3/uFz7a1r14sZyvbixXJMLUnT7jGG67qJc5gADAAAAccAwDF2cn6KL81N0/7xx2nusVat3VWvVrirtrm7RB/vr9MH+Oj3y2i5NKUjVvOIcXVuUw47DwDkgAMIFl+yw6o7LR2jhZcP18aEGLd9QptW7qrW1vElby5v04zc+1dem5usfLi3Q8IzESJcLAAAA4AIwDEPjclwal+PSPVeP0eG6Nr1ZUq1Vu6q1raJJn5Q16pOyRj2+slTFQ9zh7eVHZ7kiXTowKBAAIWIM4/jQz5qWTv33pgq9uLFClU0dWvbeQS1776CuGJOh22YM05zxWbKwTSQAAAAQN4ZnJOpfvzRK//qlUapq7tCakmNatatKGw81aFelR7sqPfrFmr0anZUUDoOK8txsNgOcAgEQokKWK0F3fXmMvjV7tN7ZXaPlH5fp3b21en9fnd7fV6fc5AR9fVqBvn5pvrLdzP0FAAAA4kluskMLLxuuhZcNV32rV+tKj2n1rmp9sL9O+2ta9XTNfj39zn4NTXWEw6BLClJlMhEGAb0IgBBVzCZDVxdm6+rCbFU0tOv5j8v1359UqKq5U79et1e/eXufrinM1m0zhumyUemk+wAAAECcSU+y6++nFejvpxXI0+nXO7trtHpXtdbvqdWRxg797oND+t0Hh5TpsuvaomzNK8rV9JFpsjKjAHGOAAhRKz/Nqe/PH6/vXDNGq3dVa/mGMm063KhVu4LzgEdmJmrB9GH66iVD5WQneQAAACDuuBOsunHSEN04aYg6fN16d2+t3iyp1rrSY6pt8Wr5hnIt31CuFKdVV0/I1ryiHM0ak8GmM4hLBECIenaLOfyf+u5qj57fUK4/bzmig7Vt+vEbn+rnb+7WVy7KUV6n1ObtUoqVNAgAAACINw6bWfOKg9O/fF09+uhAnd4sqdaakmOqb/Pplc1H9MrmI0q0mXXV+CzNK87R7HFZSrLzazHiA//SMaiMz3HrxzcV6/754/WXrZVavqFMu6tb9OqWo5Iserr0bY3MSFTxkGQV5yWreEiyCvPcSnYQCgEAAADxwmYxafa4LM0el6XHbwpo0+EGrd5VrTdLqlXV3Kk3dlTpjR1VsllMunJMhuYV5+rqCVlKcdoiXTowYAiAMCgl2S26bcYwLZheoC3ljXruo8N6p/Somn2GDtS26UBtm17bdjR8/bB0ZzgQKh7iVlFestIS+c8dAAAAiHVm0/Hdhx+9oVDbjzRr9a5qrd5VpcP17VpXWqN1pTUymwzNHJmuayZkyvBFumrg/CMAwqBmGIamDEvTxDyX/vrXCl165RztqWnXrsrm4NaQR5t1pLFDZfXtKqtv18qdVeHXDklxqCjPrYuGBIOhoiFuZbnYYQwAAACIVYZhaFJ+iiblp+j+eeO091irVu2q0upd1dpd3aIP9tfpg/11kiz6Q9kHmj4yQzNGpmn6iHTlJPO7AgY3AiDElIwku3JTkzR7XFb4XFO7LxwG7apsVslRjw7VtamyqUOVTR1a8+mx8LVZLntolFCyivPcKh6SrNzkBHYbAwAAAGKMYRgal+PSuByX7r16rA7XtWl1SbVW7azSjiNNOljXroN15XpxY7mk4KyC6SPSNGNkuqaPTNeQFEeEPwPg7BAAIealOG2aNSZDs8ZkhM95Ov369KgnHAjtqmzWgdpW1bR49fbuGr29uyZ8bXqiTUV9AqHivGTlpzkIhQAAAIAYMjwjUXd+aZT++bICvfL6X5U6Zqo+KW/Wx4caVHK0OTyr4L8/OSJJGprq0PQR6Zo+Mk0zRqTzOwKiHgEQ4pI7wRqeB9yr3del0ipPcLRQZbN2VjZrX02r6tt8em9vrd7bW9vn9ZbwSKGiUDA0Ij1RJhP/4QMAAACDndMizZmQpXkTh0gK/gF58+FGbThUr48PNmhnZXCpiSONR/TqlmAglJucEBwdNCJN00ema3i6k0AIUYUACAhx2iyaMixNU4alhc91+ru1p7olPH1sV6VHe6pb5Ons0kcH6vXRgfrwtYk2s4rygmsJ9S44PSozURazKRKfDgAAAIDzxJ1g1VXjs3TV+OBSE63eLm0ua9THB+v18aEG7TjSpKrmTq3YWqkVWyslBZeXmB4KhGaMTNOozCQCIUQUARBwGglWsy7OT9HF+Snhc76uHu2raVFJpUc7K5u162izSqs8avN1a+PhBm083NDn9SZNyO0NhIIjhcZkuWSzEAoBAAAAg1WS3aIvjc3Ul8ZmSpI6fN3aUh4MhDYcbNC2iibVtHj1P9uP6n+2B3cnzkiyhaeMTR+RrjFZScwgwAVFAAScJZvFFBzpk5esW6blS5K6unt0sK5NO48EA6GSSo9KjjarzdetreVN2lredPz1ZpPG5bjC29FfNCRZ43JcSrCaI/QZAQAAAPgiHDazLh+doctHB9cd7fQHfw/4ODRlbEt5o+pafVq5syq8M3Gq06pLR6SFQ6EJOW4CIQwoAiDgPLCYTRqb7dLYbJdunjJUktTTE9Ch+rZ+C03vqmyWp7NLO0NrDEkVkiSzydCYrKTQCKEk5ac5lZ/qVH6aQ8kOK0NFAQAAgEEkwWrWzFHpmjkquOaot6tbO440h0cIbS5rVGO7X2+WHNObJcFdid0JFl3au8vYiHQV5rllJhDCeUQABAwQk8nQqMwkjcpM0o2TgovHBQIBVTR0HF9TKBQMNbT5tLu6RburW064j8tu0dA0p/JTHaFgyKGhqc7g4zSHnDa+jQEAAIBoZreYNW14mqYNT9NdXw4uK7Gzsjk8QuiTww3ydHZpXWmN1pUGdyR22S2aOjw1vI5Q8ZBkWVlfFF8AvzkCF5BhGCpId6og3anrLsqVFAyFqpo7w4HQ4bo2VTS2q6KhQ3WtXrV4g7uTlVZ5TnrP9ETbZwIip4aGHg9JcbDeEAAAABBlbBaTpgxL1ZRhqfr27OCSEiVHPdoQWlR606EGtXi79M6eWr2zJ7gbsdNm1tThaeFFpS8akkJfH2eFAAiIMMMwlJfiUF6KQ3OLcvo91+Hr1pHG9nAgVNHQriONHaHjdnk6u1Tf5lN9m0/bK5pOcm8px50QDIXSHKFpZccDohx3AsNKAQAAgAizmE3hzWf+9Uuj1N0TUGnV8UBo46EGNXf49d7eWr23NxgIJViDIdL0EcERQpMKUmS3sK4oTm1QBUBLlizRgw8+qHvuuUdPPfVUpMsBBpzDZtaYbJfGZLtO+nxzhz8UCgUDomBYFAyKKhrb1envUVVzp6qaO7Xx8Imvt5qD4VPvekND+wZEqU5lJNlYfwgAAAC4wMwmQ8VDklU8JFn/54qR6ukJaHd1S3jK2MbDDWpo8+nD/fX6cH+9JMluMWlyQUp4UelLClLZaAb9DJoAaNOmTVq2bJkmTpwY6VKAqJHssCo59IPhswKBgOpafeHRQkcaO8JBUUVjuyobO+TvDqisvl1l9e0nvb/Dag6PFuqdYja0zxSzZId1oD9FAAAAIO6ZTIYK89wqzHPrG5ePUCAQ0L6a1uCi0oca9PHBBtW1erXhYIM2HGyQ3gruPlw0xK2ivODuw4W5bnYfjnODIgBqbW3VggUL9Nvf/laPP/54pMsBBgXDMJTpsivTZdclBaknPN/dE1C1pzM4WqjP1LIjoYCo2tOpDn+39tW0al9N60k/hjvB0m/Hst7H2S6rOruCIRQAAACA88swjPAuxLfPHK5AIKCDdW3BKWMHG/TxoXod83i1tbxJW8ubwq8zmwyNzkxSUShMKspLVmGemz/sxolBEQAtWrRIX/nKV3T11Vd/bgDk9Xrl9XrDxx5PcOFcv98vv99/3mrqvdf5vCfOHe1xbrISLcpKdGtKvvuE57xdPapq7lBFY4eONHaosrEzGBI1BcOihja/PJ1dKjnqUcnRky1QbdGjW99ShsuuzCSbMpLsynSF3ieFzoWeS0+yy84CdgOC743oQnucHl8XAADOjWEc34F4wfRhCgSCI/13VDar5GizPg312RvafNpzrEV7jrXoz1srw6/PT3OoKDc5OFpoiFuFucnKdttZDiLGRH0A9NJLL2nLli3atGnTGV2/ZMkSPfbYYyecX7NmjZxO5/kuT2vXrj3v98S5oz0GRnLordAlySUpX/J2S/VeqaHTUINXqvcaqu+UGrzB445uQ51dPaGpZx2f+zGc5oBcNsltDchlldy9j22S2yq5rAG5bVKiRWLd6rPH90Z0oT1Orr395NNRAQDA2TEMQ8MzEjU8I1F/c3GepODo/GpPp0oqPaE/4jar5KhHlU0doQ1nOrS6pDp8j/REW3iUUHAamVvD0xNlojM+aEV1AFRRUaF77rlHa9asUUJCwhm95oEHHtDixYvDxx6PR/n5+Zo7d67c7hNHOZwrv9+vtWvX6pprrpHVynC5SKM9oovf79fK1Wt18fRZaursUW2rV7UtXtW2+lTX6lVtS+h96NjfHVB7t6H2DulYx+l/oJhNhtITbcpIsikzya4MV+j9Ccd2JdnNcf9XC743ogvtcXq9o3YBAMD5ZxiGcpMdyk126OrC7PD5pnafPq3yhEcJlRxt1v6aVtW3+fT+vjq9v68ufG2izawJuX3WFcpza0x2EruPDRJRHQBt3rxZNTU1mjJlSvhcd3e33nvvPT399NPyer0ym/v/Q7Pb7bLb7Sfcy2q1Dkhne6Dui3NDe0QPm1kakeX+3PYIBAJq7vAHA6IW7/Gw6CTH9W0+dfcEVNPiVU2LV1LLae+dYDUp02VXlishOO3M1eetz3FGkl22GJ+CxvdGdKE9To6vCQAAF16K06bLRmXoslEZ4XOd/m7trm4JjxIqOerR7iqP2nzd+qSsUZ+UNYavtZoNjc5yhUcJFeUla0KuS64Efq5Hm6gOgObMmaOdO3f2O/eNb3xD48eP1/33339C+ANg8DEMQylOm1KctlNud9/L392jhjbfKQOivset3i51+nvCw1k/T4rT2j8kSrIrw2VXmtOmZKdVqU6bUp1WJTutSnHYYj4wAgAAQPxKsJo1KT9Fk/JTwue6unt0sK4tNFLoeDDU3OFXaZVHpVUevbL5+D2GpzvDo4QKQ+FQluvMZvZgYER1AORyuVRcXNzvXGJiotLT0084DyD2Wc0mZbsTlO3+/B8c7b4u1bX4VNvaqRrP6UcWdfUE1NTuV1O7/5Q7nn1Wkt2iZIdVqYnBcCjZ0TckCr5P/Ux45EqwysycaQAAAAxCFrMpvPPYTZOHSAqO5q9s6giHQZ+GgqGq5k4drm/X4fp2rdxZFb5Hpsveb6RQUZ5b+alO1hW6QKI6AAKAc+W0WVSQblFB+ukXf+/pCU1BO0VA1NjuC4VDPjW2++Xp9CsQkFq9XWr1dqmy6fNHF/UyDIWDouB7a2j0U/BcSug4NTTKKMVpVWqiTYk21jICAABA9DEMQ0NTnRqa6tS1RTnh8w1tvs+MFGrWwbo21bZ4tX5PrdbvqQ1f67JbNCH3+CihorxkjclOktXMiPvzbdAFQOvXr490CQBiiMlkKDXRptREm8Z+zhQ0SeruCcjT4Q8GQx2hYKjNf/xxODDy9wuP2nzdCgQUfu5sWM2Gkh2hYKhvSNQ3PHKEziceD48SrEyTBQAAwIWXlmjTrDEZmjXm+LpC7b4ulVa1hEcJlRz1aE91i1q8Xdp4uEEbDzeEr7WZTRqbk6Si3GSNz0lUg0eqb/MpJ4V1hb6IQRcAAUAkmfsERmfD29Wt5o5QMNTWJzwKBUKnCo983T3ydwdU1+pVXav3rD6mw2pWssMic5dZy6s2KdkRnIbmTrDIlWCVK/Te7Th+7E6wyJ0QvC7BamLkEQAAAM4Lp82iKcNSNWVYavicv7tHB2pb+21N/2mVRy2dXdpV6dGuyt4dQi36Tcl6pTqtGp2VpNFZrtD74FtecgL91jNAAAQAF4DdYlaWy3xWC98FAgF1+Ls/M5qo97Ev9DgYHjV19B9x1BOQOvzd6vB3SzJUebjxcz/eZ1lMRjAUcoTCIru1/3EoTHKfIkxyJVjYEhQAAACnZDWbND7HrfE5bt0c2vw7EAiooqEjPH1sV2WTdpbVqsFnqLHdr02HG7XpM33bRJtZo7KSNDozKfg+K0ljspJUkOaUhalkYQRAABClDMOQ02aR02ZRXorjjF/X0xNQi7dLTe0+1Xk6tPbdjzR+4mS1+wNq6fSrpbNLntD7lk6/PJ1d8nQcP27xdikQkLp6AmoMhUznym4x9Rl1dPowydUnTHL3CZH4oQ0AABA/DMNQQbpTBelOzb8oV36/X3/961911dXXqrzJqwO1rdpf06p9x1q1v7ZVh+va1Obr1o4jzdpxpLnfvWxmk4ZnOIMjhTKTNDrbpdGZSRqZmRiXyyUQAAFAjDGZDCU7rEp2WJXntulIakDXXZQjq/XM5kz39ATU5usKBUK9IVFvcBQ67ugKh0m9IdLx4+AC2ZLk7eqR9xymr/XltJnDIVGizaxEuyX4FnqcZA+GZIl2c/Cx3aIku1mJNsvxa0PHThbUBgAAGJQcNrOKhySreEhyv/P+7h6V1bdrf02L9tcEw6H9oZCo09+jvcdatfdY/51+DUPKT3VqTGi00Kg+08ncCbG7zhABEACgH5PJCI3IOfcfft09AbX2GWnUd8RRS++II+8pRiCFru/090iS2n3davd165jn3EOkXoahcBCUFAqH+j5O7BMcBcOk0HO2Po9Dx73Xsm0pAABA5FjNpnB401dPT3CL+v21rToQCob2hd43d/hV3tCu8oZ2vbW7pt/rst324yOG+qw3lJFkG/R/SCQAAgCcd2aToWSnVcnOcw+RfF09avX2GXHk9avN2612X3CEUZu3S23e7uB73/HHrd4utfs+89gXnNYWCEitofM1LV88UJKCi20nhkYdOW2WUEhkDo5EsvUJluwWJVgM7as1ZCo5piSHTU5r8DUOm0kOm0UOq1lOm1l2CwtwAwAAfBEmk6H8NKfy05y6alxW+HwgEFBdqy80Wqil34ihYx5v+O3D/fX97pfssIaDoTHZSeE1h4akOAbNHwQJgAAAUclmMSnNYlPaWe64djI9PcEFtfsGRWcSHIWDJl+f14SOu3sCko4vtl3X+jlFhJn1/P7tp73CMBQOgxJC74MBkSkYGFnNcthC50OPHf2u6//a/vcxK8FiHjQdFQAAgPPJMAxluuzKdNk1c1R6v+c8nf7wNLIDfUYMVTS2q7nDr81ljdpc1n8BaofVrJGZieHpZL1vw9ITZY2ytSwJgAAAMc9kMsLrAcn1xe8XCATk7eoJj0IKBka9I5N6g6b+4VGrt0stHX5VHK1WUkqaOvw96vAFw6P20HtfV0/o/senvg2UvsHRZ8Ok/uGR5Xh41Of5VKdNl4/OGLD6AAAALjR3glWXFKTqkoLUfuc7/d06WNsWHCl0rCU8YuhQXZs6/N2hLew9/V5jMRkanpHYZypZkgrz3BqbfR46o+eIAAgAgLNkGIYSrMGQJD3p86/v1buLxXXXXXrSRbm7unvCI4r6hUOht3Z/tzp9wWlwxx8fv77v4+Bru/rdxxsKmKTjI5fO1cjMRL39f2ef8+sBAAAGiwSrWYV5bhXmufud7+ruUVlD+wmjhg7Utqrd1x0+r5Lg9XPGZ+nZO6ZF4DMIIgACACBKWMwmucymL7QA9+n0ToVr93Wrs8/Io88GRb3PHX/cpQ5fjzr8XeFAKi/FMSA1AgAADBYWs0mjMpM0KjNJ1xYdP9/TE1CVp/P4rmShtYYm5adErFaJAAgAgLjRbyocAAAABoTJZGhIikNDUhz60tjMSJcTFl0rEgEAAAAAAOC8IwACAAAAAACIcQRAAAAAAAAAMY4ACAAAAAAAIMYRAAEAAAAAAMQ4AiAAAAAAAIAYRwAEAAAAAAAQ4wiAAAAAAAAAYhwBEAAAQJRaunSpJk6cKLfbLbfbrZkzZ2rVqlWnvH79+vUyDOOEt927d1/AqgEAQDSyRLoAAAAAnNzQoUP1k5/8RKNHj5Yk/fGPf9SNN96orVu3qqio6JSv27Nnj9xud/g4MzNzwGsFAADRjQAIAAAgSt1www39jp944gktXbpUGzZsOG0AlJWVpZSUlDP+OF6vV16vN3zs8XgkSX6/X36//+yKPo3ee53Pe+Lc0R7RhfaIHrRFdKE9Tu9svi4EQAAAAINAd3e3Xn75ZbW1tWnmzJmnvXby5Mnq7OxUYWGhHnroIV111VWnvX7JkiV67LHHTji/Zs0aOZ3OL1T3yaxdu/a83xPnjvaILrRH9KAtogvtcXLt7e1nfC0BEAAAQBTbuXOnZs6cqc7OTiUlJWnFihUqLCw86bW5ublatmyZpkyZIq/Xq+eee05z5szR+vXrdeWVV57yYzzwwANavHhx+Njj8Sg/P19z587tN5Xsi/L7/Vq7dq2uueYaWa3W83ZfnBvaI7rQHtGDtogutMfp9Y7aPRMEQAAAAFFs3Lhx2rZtm5qamvTqq69q4cKFevfdd08aAo0bN07jxo0LH8+cOVMVFRX6xS9+cdoAyG63y263n3DearUOSGd7oO6Lc0N7RBfaI3rQFtGF9ji5s/masAsYAABAFLPZbBo9erSmTp2qJUuW6OKLL9a///u/n/HrZ8yYoX379g1ghQAAYDAgAAIAABhEAoFAvwWbP8/WrVuVm5s7gBUBAIDBgClgAAAAUerBBx/U/PnzlZ+fr5aWFr300ktav369Vq9eLSm4dk9lZaX+67/+S5L01FNPafjw4SoqKpLP59Py5cv16quv6tVXX43kpwEAAKIAARAAAECUOnbsmG6//XZVVVUpOTlZEydO1OrVq3XNNddIkqqqqlReXh6+3ufz6b777lNlZaUcDoeKioq0cuVKXXfddZH6FAAAQJSI+QAoEAhIOruVsc+E3+9Xe3u7PB4PC1FFAdojutAe0YO2iC60x+n1/qzu/dkN6dlnnz3t83/4wx/6HX/ve9/T9773vS/8cek/xQfaI7rQHtGDtogutMfpnU3/KeYDoJaWFklSfn5+hCsBAABnoqWlRcnJyZEuI67RfwIAYHA5k/6TEYjxP7P19PTo6NGjcrlcMgzjvN3X4/EoPz9fFRUVcrvd5+2+ODe0R3ShPaIHbRFdaI/TCwQCamlpUV5enkwm9qmIJPpP8YH2iC60R/SgLaIL7XF6Z9N/ivkRQCaTSUOHDh2w+7vdbv4RRhHaI7rQHtGDtogutMepMfInOtB/ii+0R3ShPaIHbRFdaI9TO9P+E39eAwAAAAAAiHEEQAAAAAAAADGOAOgc2e12Pfroo7Lb7ZEuBaI9og3tET1oi+hCeyDe8T0QXWiP6EJ7RA/aIrrQHudPzC8CDQAAAAAAEO8YAQQAAAAAABDjCIAAAAAAAABiHAEQAAAAAABAjCMAAgAAAAAAiHEEQOfomWee0YgRI5SQkKApU6bo/fffj3RJcWnJkiWaNm2aXC6XsrKydNNNN2nPnj2RLgsKto1hGLr33nsjXUrcqqys1G233ab09HQ5nU5NmjRJmzdvjnRZcamrq0sPPfSQRowYIYfDoZEjR+pHP/qRenp6Il0acEHRf4o8+k7Rjf5T5NF/ig70nQYGAdA5+NOf/qR7771XP/jBD7R161ZdccUVmj9/vsrLyyNdWtx59913tWjRIm3YsEFr165VV1eX5s6dq7a2tkiXFtc2bdqkZcuWaeLEiZEuJW41Njbq8ssvl9Vq1apVq/Tpp5/ql7/8pVJSUiJdWlz66U9/qv/4j//Q008/rdLSUv3sZz/Tz3/+c/3mN7+JdGnABUP/KTrQd4pe9J8ij/5T9KDvNDDYBv4cTJ8+XZdccomWLl0aPjdhwgTddNNNWrJkSQQrQ21trbKysvTuu+/qyiuvjHQ5cam1tVWXXHKJnnnmGT3++OOaNGmSnnrqqUiXFXe+//3v68MPP+Sv61Hi+uuvV3Z2tp599tnwuZtvvllOp1PPPfdcBCsDLhz6T9GJvlN0oP8UHeg/RQ/6TgODEUBnyefzafPmzZo7d26/83PnztVHH30UoarQq7m5WZKUlpYW4Uri16JFi/SVr3xFV199daRLiWuvv/66pk6dqq997WvKysrS5MmT9dvf/jbSZcWtWbNm6a233tLevXslSdu3b9cHH3yg6667LsKVARcG/afoRd8pOtB/ig70n6IHfaeBYYl0AYNNXV2duru7lZ2d3e98dna2qqurI1QVJCkQCGjx4sWaNWuWiouLI11OXHrppZe0ZcsWbdq0KdKlxL2DBw9q6dKlWrx4sR588EFt3LhR//Zv/ya73a5//Md/jHR5cef+++9Xc3Ozxo8fL7PZrO7ubj3xxBO69dZbI10acEHQf4pO9J2iA/2n6EH/KXrQdxoYBEDnyDCMfseBQOCEc7iw7rrrLu3YsUMffPBBpEuJSxUVFbrnnnu0Zs0aJSQkRLqcuNfT06OpU6fqySeflCRNnjxZJSUlWrp0KR2YCPjTn/6k5cuX64UXXlBRUZG2bdume++9V3l5eVq4cGGkywMuGPpP0YW+U+TRf4ou9J+iB32ngUEAdJYyMjJkNptP+GtVTU3NCX/VwoVz99136/XXX9d7772noUOHRrqcuLR582bV1NRoypQp4XPd3d1677339PTTT8vr9cpsNkewwviSm5urwsLCfucmTJigV199NUIVxbfvfve7+v73v6+vf/3rkqSLLrpIZWVlWrJkCZ0YxAX6T9GHvlN0oP8UXeg/RQ/6TgODNYDOks1m05QpU7R27dp+59euXavLLrssQlXFr0AgoLvuukt//vOf9fbbb2vEiBGRLiluzZkzRzt37tS2bdvCb1OnTtWCBQu0bds2Oi8X2OWXX37Ctr579+7VsGHDIlRRfGtvb5fJ1P9HrtlsZitTxA36T9GDvlN0of8UXeg/RQ/6TgODEUDnYPHixbr99ts1depUzZw5U8uWLVN5ebnuvPPOSJcWdxYtWqQXXnhBr732mlwuV/gvi8nJyXI4HBGuLr64XK4T1g9ITExUeno66wpEwHe+8x1ddtllevLJJ3XLLbdo48aNWrZsmZYtWxbp0uLSDTfcoCeeeEIFBQUqKirS1q1b9atf/Ur/9E//FOnSgAuG/lN0oO8UXeg/RRf6T9GDvtPAYBv4c/TMM8/oZz/7maqqqlRcXKxf//rXbJ0ZAadaN+D3v/+97rjjjgtbDE4we/ZstjGNoDfeeEMPPPCA9u3bpxEjRmjx4sX6l3/5l0iXFZdaWlr08MMPa8WKFaqpqVFeXp5uvfVWPfLII7LZbJEuD7hg6D9FHn2n6Ef/KbLoP0UH+k4DgwAIAAAAAAAgxrEGEAAAAAAAQIwjAAIAAAAAAIhxBEAAAAAAAAAxjgAIAAAAAAAgxhEAAQAAAAAAxDgCIAAAAAAAgBhHAAQAAAAAABDjCIAAAAAAAABiHAEQgJhmGIb+8pe/RLoMAACAQYP+ExCbCIAADJg77rhDhmGc8DZv3rxIlwYAABCV6D8BGCiWSBcAILbNmzdPv//97/uds9vtEaoGAAAg+tF/AjAQGAEEYEDZ7Xbl5OT0e0tNTZUUHF68dOlSzZ8/Xw6HQyNGjNDLL7/c7/U7d+7Ul7/8ZTkcDqWnp+ub3/ymWltb+13zn//5nyoqKpLdbldubq7uuuuufs/X1dXpb//2b+V0OjVmzBi9/vrr4ecaGxu1YMECZWZmyuFwaMyYMSd0uAAAAC4k+k8ABgIBEICIevjhh3XzzTdr+/btuu2223TrrbeqtLRUktTe3q558+YpNTVVmzZt0ssvv6x169b166AsXbpUixYt0je/+U3t3LlTr7/+ukaPHt3vYzz22GO65ZZbtGPHDl133XVasGCBGhoawh//008/1apVq1RaWqqlS5cqIyPjwn0BAAAAzhL9JwDnJAAAA2ThwoUBs9kcSExM7Pf2ox/9KBAIBAKSAnfeeWe/10yfPj3wrW99KxAIBALLli0LpKamBlpbW8PPr1y5MmAymQLV1dWBQCAQyMvLC/zgBz84ZQ2SAg899FD4uLW1NWAYRmDVqlWBQCAQuOGGGwLf+MY3zs8nDAAA8AXRfwIwUFgDCMCAuuqqq7R06dJ+59LS0sKPZ86c2e+5mTNnatu2bZKk0tJSXXzxxUpMTAw/f/nll6unp0d79uyRYRg6evSo5syZc9oaJk6cGH6cmJgol8ulmpoaSdK3vvUt3XzzzdqyZYvmzp2rm266SZdddtk5fa4AAADnA/0nAAOBAAjAgEpMTDxhSPHnMQxDkhQIBMKPT3aNw+E4o/tZrdYTXtvT0yNJmj9/vsrKyrRy5UqtW7dOc+bM0aJFi/SLX/zirGoGAAA4X+g/ARgIrAEEIKI2bNhwwvH48eMlSYWFhdq2bZva2trCz3/44YcymUwaO3asXC6Xhg8frrfeeusL1ZCZmak77rhDy5cv11NPPaVly5Z9ofsBAAAMJPpPAM4FI4AADCiv16vq6up+5ywWS3ihwJdffllTp07VrFmz9Pzzz2vjxo169tlnJUkLFizQo48+qoULF+qHP/yhamtrdffdd+v2229Xdna2JOmHP/yh7rzzTmVlZWn+/PlqaWnRhx9+qLvvvvuM6nvkkUc0ZcoUFRUVyev16o033tCECRPO41cAAADg7NB/AjAQCIAADKjVq1crNze337lx48Zp9+7dkoI7TLz00kv69re/rZycHD3//PMqLCyUJDmdTr355pu65557NG3aNDmdTt1888361a9+Fb7XwoUL1dnZqV//+te67777lJGRoa9+9atnXJ/NZtMDDzygw4cPy+Fw6IorrtBLL710Hj5zAACAc0P/CcBAMAKBQCDSRQCIT4ZhaMWKFbrpppsiXQoAAMCgQP8JwLliDSAAAAAAAIAYRwAEAAAAAAAQ45gCBgAAAAAAEOMYAQQAAAAAABDjCIAAAAAAAABiHAEQAAAAAABAjCMAAgAAAAAAiHEEQAAAAAAAADGOAAgAAAAAACDGEQABAAAAAADEOAIgAAAAAACAGPf/AY3zTYiZfOcqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot training losses\n",
    "for exp_name, losses in train_losses.items():\n",
    "    axes[0].plot(losses, label=exp_name)\n",
    "axes[0].set_title(\"Training Loss Across Experiments\")\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"Training Loss\")\n",
    "axes[0].legend()\n",
    "# axes[0].set_yscale(\"log\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot test losses\n",
    "for exp_name, losses in test_losses.items():\n",
    "    axes[1].plot(losses, label=exp_name)\n",
    "axes[1].set_title(\"Test Loss Across Experiments\")\n",
    "axes[1].set_xlabel(\"Epochs\")\n",
    "axes[1].set_ylabel(\"Test Loss\")\n",
    "axes[1].legend()\n",
    "# axes[1].set_yscale(\"log\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Show the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concatenated(files):\n",
    "    train = [pd.read_csv(file + \"_train_loss.txt\", header=None) for file in files]\n",
    "    test = [pd.read_csv(file + \"_test_loss.txt\", header=None) for file in files]\n",
    "    return pd.concat(train, ignore_index=True), pd.concat(test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total, test_total = get_concatenated([\"../papers/attention_is_all_you_need/experiments/multi_hindi_drop_warm_smoothen_small_2\", \n",
    "                  \"../papers/attention_is_all_you_need/experiments/multi_hindi_drop_warm_smoothen_small_2_continued_0\",\n",
    "                  \"../papers/attention_is_all_you_need/experiments/multi_hindi_drop_warm_smoothen_small_2_continued_2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total, test_total = get_concatenated([\"../papers/attention_is_all_you_need/experiments/multi_hindi_s\", \n",
    "                  \"../papers/attention_is_all_you_need/experiments/multi_hindi_small_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(7.114044513258823</td>\n",
       "      <td>4.945246969232846)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(5.706829388197078</td>\n",
       "      <td>13.623965519296188)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(4.845957502098971</td>\n",
       "      <td>23.319698625609867)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(4.379551090196122</td>\n",
       "      <td>30.366214141250158)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(4.119131488023802</td>\n",
       "      <td>34.56980612817785)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>(3.0211573767107587</td>\n",
       "      <td>52.993911942365266)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>(3.0200702373371566</td>\n",
       "      <td>53.01657236625683)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>(3.0190791701161586</td>\n",
       "      <td>53.02482056742473)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>(3.017767006851906</td>\n",
       "      <td>53.056694835547766)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>(3.0165781908257063</td>\n",
       "      <td>53.062528929056775)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0                     1\n",
       "0     (7.114044513258823    4.945246969232846)\n",
       "1     (5.706829388197078   13.623965519296188)\n",
       "2     (4.845957502098971   23.319698625609867)\n",
       "3     (4.379551090196122   30.366214141250158)\n",
       "4     (4.119131488023802    34.56980612817785)\n",
       "..                   ...                   ...\n",
       "135  (3.0211573767107587   52.993911942365266)\n",
       "136  (3.0200702373371566    53.01657236625683)\n",
       "137  (3.0190791701161586    53.02482056742473)\n",
       "138   (3.017767006851906   53.056694835547766)\n",
       "139  (3.0165781908257063   53.062528929056775)\n",
       "\n",
       "[140 rows x 2 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../data/en-hi/hindi_small_train.txt\n",
      "  input: ../data/en-hi/english_small_train.txt\n",
      "  input_format: \n",
      "  model_prefix: en-hi\n",
      "  model_type: BPE\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 3\n",
      "  unk_piece: <UNK>\n",
      "  bos_piece: <SOS>\n",
      "  eos_piece: <EOS>\n",
      "  pad_piece: <PAD>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: ../data/en-hi/hindi_small_train.txt\n",
      "trainer_interface.cc(380) LOG(WARNING) Found too long line (5144 > 4192).\n",
      "trainer_interface.cc(382) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(383) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: ../data/en-hi/english_small_train.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 999987 sentences\n",
      "trainer_interface.cc(416) LOG(INFO) Skipped 13 too long sentences.\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <UNK>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <SOS>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <EOS>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <PAD>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=95770156\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 99.9528% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=141\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.999528\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 999987 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 999987\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 672047\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1606135 min_freq=8445\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=387488 size=20 all=7448 active=2292 piece=ें\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=272270 size=40 all=9085 active=3929 piece=▁f\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=203853 size=60 all=10300 active=5144 piece=ion\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=161787 size=80 all=11802 active=6646 piece=▁ग\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=120140 size=100 all=13272 active=8116 piece=▁be\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=118646 min_freq=12252\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=98933 size=120 all=14925 active=2619 piece=▁l\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=84249 size=140 all=16835 active=4529 piece=िया\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=72102 size=160 all=19087 active=6781 piece=▁1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64455 size=180 all=20790 active=8484 piece=▁H\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56307 size=200 all=23218 active=10912 piece=ist\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=56077 min_freq=8952\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50789 size=220 all=25048 active=2841 piece=▁with\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46471 size=240 all=27004 active=4797 piece=▁मु\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42318 size=260 all=28873 active=6666 piece=\"\"\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39282 size=280 all=30753 active=8546 piece=ुल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35762 size=300 all=32534 active=10327 piece=ort\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=35421 min_freq=5624\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33342 size=320 all=34247 active=3224 piece=▁था\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30428 size=340 all=36423 active=5400 piece=▁India\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28246 size=360 all=38101 active=7078 piece=▁also\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26813 size=380 all=39632 active=8609 piece=द्\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25180 size=400 all=41693 active=10670 piece=▁भारत\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=25092 min_freq=4129\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23350 size=420 all=43950 active=4326 piece=च्\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22037 size=440 all=45345 active=5721 piece=्रे\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20862 size=460 all=47305 active=7681 piece=▁कु\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19923 size=480 all=49258 active=9634 piece=ome\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18871 size=500 all=50638 active=11014 piece=▁had\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18739 min_freq=3199\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18051 size=520 all=51968 active=3855 piece=li\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17380 size=540 all=53462 active=5349 piece=▁Th\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16766 size=560 all=55114 active=7001 piece=ople\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16052 size=580 all=56437 active=8324 piece=ाना\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15437 size=600 all=58113 active=10000 piece=ence\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15402 min_freq=2631\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14955 size=620 all=59736 active=4460 piece=▁मैं\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14408 size=640 all=61234 active=5958 piece=▁भा\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14079 size=660 all=62636 active=7360 piece=ctor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13611 size=680 all=64035 active=8759 piece=▁under\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13075 size=700 all=65606 active=10330 piece=▁ar\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13068 min_freq=2195\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12618 size=720 all=67159 active=4798 piece=बर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12319 size=740 all=68841 active=6480 piece=ree\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11940 size=760 all=70360 active=7999 piece=ang\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11637 size=780 all=71983 active=9622 piece=red\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11412 size=800 all=73698 active=11337 piece=▁लगा\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11399 min_freq=1878\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11122 size=820 all=74866 active=4831 piece=ens\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10705 size=840 all=75996 active=5961 piece=▁BJP\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10291 size=860 all=76996 active=6961 piece=िज\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10103 size=880 all=78402 active=8367 piece=▁time\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9762 size=900 all=79829 active=9794 piece=म्म\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9758 min_freq=1677\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9492 size=920 all=81198 active=5235 piece=▁first\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9309 size=940 all=82170 active=6207 piece=▁Un\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9064 size=960 all=83364 active=7401 piece=▁फिर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8791 size=980 all=84694 active=8731 piece=reat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8629 size=1000 all=85927 active=9964 piece=पर\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8598 min_freq=1494\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8469 size=1020 all=87226 active=5327 piece=▁पास\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8264 size=1040 all=88735 active=6836 piece=▁add\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8038 size=1060 all=89689 active=7790 piece=▁more\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7866 size=1080 all=90537 active=8638 piece=▁tak\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7752 size=1100 all=91901 active=10002 piece=नाव\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7751 min_freq=1344\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7545 size=1120 all=92882 active=5518 piece=क्ति\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7374 size=1140 all=94257 active=6893 piece=▁राष्ट्र\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7248 size=1160 all=95533 active=8169 piece=▁जर\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7088 size=1180 all=96844 active=9480 piece=▁बन\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6925 size=1200 all=97787 active=10423 piece=▁झ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6921 min_freq=1216\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6750 size=1220 all=98887 active=5923 piece=▁ass\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Ad"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ded: freq=6648 size=1240 all=100406 active=7442 piece=▁गां\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6546 size=1260 all=101261 active=8297 piece=▁बद\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6465 size=1280 all=102399 active=9435 piece=der\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6319 size=1300 all=103752 active=10788 piece=▁दु\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6307 min_freq=1116\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6198 size=1320 all=104762 active=6141 piece=ctions\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6122 size=1340 all=105784 active=7163 piece=ked\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6006 size=1360 all=107029 active=8408 piece=▁15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5909 size=1380 all=107814 active=9193 piece=▁बैठ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5792 size=1400 all=108871 active=10250 piece=▁आधार\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5783 min_freq=1031\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5700 size=1420 all=109994 active=6550 piece=▁आरोप\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5580 size=1440 all=111040 active=7596 piece=धिक\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5485 size=1460 all=112037 active=8593 piece=▁num\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5398 size=1480 all=112966 active=9522 piece=▁पाकिस्तान\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5338 size=1500 all=114332 active=10888 piece=▁ear\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5334 min_freq=957\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5272 size=1520 all=115402 active=6779 piece=▁take\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5178 size=1540 all=116155 active=7532 piece=▁सुरक्षा\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5120 size=1560 all=117389 active=8766 piece=ati\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5028 size=1580 all=118371 active=9748 piece=लिए\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4953 size=1600 all=119330 active=10707 piece=▁loc\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4950 min_freq=896\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4870 size=1620 all=119888 active=6503 piece=▁तैय\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4794 size=1640 all=120575 active=7190 piece=ax\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4717 size=1660 all=121502 active=8117 piece=▁ख़ुदा\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4636 size=1680 all=122647 active=9262 piece=aking\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4577 size=1700 all=123174 active=9789 piece=यह\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4576 min_freq=849\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4520 size=1720 all=124112 active=7047 piece=▁कुमार\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4478 size=1740 all=124675 active=7610 piece=▁hand\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4414 size=1760 all=125870 active=8805 piece=▁योग\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4351 size=1780 all=126606 active=9541 piece=▁13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4304 size=1800 all=127623 active=10558 piece=ेंट\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4303 min_freq=796\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4245 size=1820 all=128470 active=7079 piece=▁incre\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4192 size=1840 all=129227 active=7836 piece=▁col\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4128 size=1860 all=130020 active=8629 piece=▁फ़\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4075 size=1880 all=130745 active=9354 piece=▁स्क\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4022 size=1900 all=131783 active=10392 piece=,\"\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4017 min_freq=755\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3981 size=1920 all=132714 active=7498 piece=▁Sab\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3931 size=1940 all=133505 active=8289 piece=▁ext\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3887 size=1960 all=133875 active=8659 piece=ामी\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3843 size=1980 all=134644 active=9428 piece=▁आत\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3810 size=2000 all=135164 active=9948 piece=इट\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3809 min_freq=722\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3777 size=2020 all=135968 active=7464 piece=ey\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3724 size=2040 all=136779 active=8275 piece=ired\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3681 size=2060 all=137401 active=8897 piece=▁देशों\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3638 size=2080 all=137898 active=9394 piece=▁Ass\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3601 size=2100 all=138410 active=9906 piece=्वी\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3601 min_freq=691\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3580 size=2120 all=138928 active=7391 piece=▁पत्र\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3522 size=2140 all=139423 active=7886 piece=BI\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3495 size=2160 all=140234 active=8697 piece=▁आम\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3453 size=2180 all=140915 active=9378 piece=▁श्र\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3416 size=2200 all=141717 active=10180 piece=▁केवल\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3415 min_freq=659\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3371 size=2220 all=142194 active=7559 piece=▁lakh\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3349 size=2240 all=142769 active=8134 piece=▁लाभ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3317 size=2260 all=143417 active=8782 piece=▁leader\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3280 size=2280 all=144540 active=9905 piece=ंगा\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3261 size=2300 all=145550 active=10915 piece=▁समर्थ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3260 min_freq=629\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3229 size=2320 all=146390 active=8110 piece=gy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3195 size=2340 all=147251 active=8971 piece=▁कर्म\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3169 size=2360 all=147954 active=9674 piece=▁आग\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3139 size=2380 all=148488 active=10208 piece=▁result\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3117 size=2400 all=149082 active=10802 piece=▁Sharma\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3116 min_freq=602\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3085 size=2420 all=149405 active=7777 piece=▁सके\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3062 size=2440 all=150368 active=8740 piece=▁रिपोर्ट\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3022 size=2460 all=151294 active=9666 piece=▁Pat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2967 size=2480 all=151834 active=10206 piece=▁gr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2942 size=2500 all=152602 active=10974 piece=pr\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2941 min_freq=579\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2905 size=2520 all=153211 active=8157 piece=▁महत्वपूर्ण\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2876 size=2540 all=153635 active=8581 piece=▁Bi\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2851 size=2560 all=154057 active=9003 piece=▁पांच\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2826 size=2580 all=154428 active=9374 piece=ination\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2805 size=2600 all=154927 active=9873 piece=व्य\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2805 min_freq=559\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2767 size=2620 all=155517 active=8229 piece=▁seen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2743 size=2640 all=156072 active=8784 piece=▁गति\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2716 size=2660 all=156726 active=9438 piece=▁माध्यम\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2686 size=2680 all=157091 active=9803 piece=orth\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2665 size=2700 all=157599 active=10311 piece=▁मं\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2665 min_freq=538\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2644 size=2720 all=158020 active=8262 piece=▁अच��छा\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2622 size=2740 all=158304 active=8546 piece=ुआ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2601 size=2760 all=158922 active=9164 piece=द्यालय\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2582 size=2780 all=159458 active=9700 piece=▁बेट\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2551 size=2800 all=160343 active=10585 piece=▁दल\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2551 min_freq=521\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2538 size=2820 all=160662 active=8305 piece=▁जरूरत\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2521 size=2840 all=160998 active=8641 piece=self\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2499 size=2860 all=161938 active=9581 piece=नल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2478 size=2880 all=162549 active=10192 piece=अप\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2461 size=2900 all=162979 active=10622 piece=▁persons\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2460 min_freq=504\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2434 size=2920 all=163714 active=8883 piece=कट\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2421 size=2940 all=164193 active=9362 piece=▁asked\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2403 size=2960 all=164644 active=9813 piece=▁city\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2384 size=2980 all=165192 active=10361 piece=▁प्रकाश\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2359 size=3000 all=165977 active=11146 piece=▁sector\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2356 min_freq=485\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2342 size=3020 all=166650 active=8969 piece=बे\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2320 size=3040 all=167289 active=9608 piece=▁video\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2300 size=3060 all=167875 active=10194 piece=▁बाजार\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2283 size=3080 all=168626 active=10945 piece=सत\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2269 size=3100 all=169051 active=11370 piece=▁treat\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2268 min_freq=469\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2251 size=3120 all=169534 active=8927 piece=ium\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2232 size=3140 all=170030 active=9423 piece=▁किसानों\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2209 size=3160 all=170753 active=10146 piece=▁भाषा\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2187 size=3180 all=171369 active=10762 piece=▁hig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2170 size=3200 all=171823 active=11216 piece=icy\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2170 min_freq=454\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2157 size=3220 all=172229 active=8980 piece=▁business\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2137 size=3240 all=172677 active=9428 piece=▁वित्त\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2120 size=3260 all=173352 active=10103 piece=ाज़\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2106 size=3280 all=174081 active=10832 piece=ल्स\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2088 size=3300 all=174941 active=11692 piece=ollywood\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2087 min_freq=439\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2074 size=3320 all=175464 active=9257 piece=ergy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2062 size=3340 all=175824 active=9617 piece=▁issues\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2047 size=3360 all=176371 active=10164 piece=ग्री\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2027 size=3380 all=177005 active=10798 piece=कृतिक\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2014 size=3400 all=177825 active=11618 piece=▁food\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2014 min_freq=425\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1998 size=3420 all=178180 active=9239 piece=▁मजबूत\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1988 size=3440 all=178511 active=9570 piece=line\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1975 size=3460 all=179288 active=10347 piece=▁Med\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1962 size=3480 all=180011 active=11070 piece=\"\".\"\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1951 size=3500 all=180652 active=11711 piece=तमान\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1951 min_freq=412\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1937 size=3520 all=181111 active=9485 piece=resent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1927 size=3540 all=181581 active=9955 piece=ari\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1910 size=3560 all=182062 active=10436 piece=▁कमी\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1899 size=3580 all=182655 active=11029 piece=▁रु\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1889 size=3600 all=183240 active=11614 piece=▁बंगाल\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1889 min_freq=400\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1880 size=3620 all=183940 active=9859 piece=ilities\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1864 size=3640 all=184379 active=10298 piece=ार्ड\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1851 size=3660 all=185169 active=11088 piece=ड्ड\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1836 size=3680 all=185545 active=11464 piece=▁2015\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1823 size=3700 all=186099 active=12018 piece=ps\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1823 min_freq=388\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1813 size=3720 all=186903 active=10020 piece=▁बच्चे\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1806 size=3740 all=187168 active=10285 piece=▁तुल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1793 size=3760 all=187568 active=10685 piece=▁हरियाणा\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1780 size=3780 all=188005 active=11122 piece=▁CM\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1766 size=3800 all=188786 active=11903 piece=ग़\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1766 min_freq=379\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1755 size=3820 all=189554 active=10079 piece=ier\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1745 size=3840 all=190084 active=10609 piece=aff\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1734 size=3860 all=190833 active=11358 piece=ize\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1723 size=3880 all=191498 active=12023 piece=▁वर्ग\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1710 size=3900 all=192244 active=12769 piece=किल\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1710 min_freq=366\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1698 size=3920 all=192835 active=10161 piece=▁cust\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1689 size=3940 all=193324 active=10650 piece=▁young\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1680 size=3960 all=194036 active=11362 piece=▁कोहली\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1669 size=3980 all=194294 active=11620 piece=▁श्रे\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1653 size=4000 all=194756 active=12082 piece=▁राजस्थान\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1651 min_freq=357\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1642 size=4020 all=195414 active=10395 piece=▁निर्धार\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1626 size=4040 all=195836 active=10817 piece=��free\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1614 size=4060 all=196336 active=11317 piece=▁समी\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1605 size=4080 all=196899 active=11880 piece=पट\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1591 size=4100 all=197475 active=12456 piece=▁लेख\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1591 min_freq=347\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1582 size=4120 all=197922 active=10299 piece=▁देव\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1571 size=4140 all=198583 active=10960 piece=▁निकाल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1556 size=4160 all=199156 active=11533 piece=▁प्रत्येक\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1548 size=4180 all=199613 active=11990 piece=▁ड्र\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1537 size=4200 all=200181 active=12558 piece=वधान\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1537 min_freq=339\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1529 size=4220 all=200558 active=10372 piece=▁office\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1519 size=4240 all=200835 active=10649 piece=▁पड़े\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1510 size=4260 all=201192 active=11006 piece=usband\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1503 size=4280 all=201674 active=11488 piece=▁नीचे\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1493 size=4300 all=202259 active=12073 piece=ैक\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1493 min_freq=332\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1486 size=4320 all=202921 active=10663 piece=▁नम\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1480 size=4340 all=203314 active=11056 piece=▁self\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1473 size=4360 all=204100 active=11842 piece=वासी\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1465 size=4380 all=204515 active=12257 piece=▁छो\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1458 size=4400 all=204766 active=12508 piece=engers\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1458 min_freq=323\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1450 size=4420 all=205206 active=10668 piece=ज़र\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1440 size=4440 all=205578 active=11040 piece=▁related\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1436 size=4460 all=205930 active=11392 piece=▁संस्थान\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1432 size=4480 all=206586 active=12048 piece=▁foreign\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1422 size=4500 all=207099 active=12561 piece=▁spec\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1422 min_freq=317\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1415 size=4520 all=207703 active=10947 piece=▁इलाज\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1409 size=4540 all=208088 active=11332 piece=▁प्रचार\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1400 size=4560 all=208638 active=11882 piece=ोम\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1392 size=4580 all=209326 active=12570 piece=stitu\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1385 size=4600 all=209905 active=13149 piece=िटल\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1385 min_freq=308\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1375 size=4620 all=210672 active=11245 piece=▁ty\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1367 size=4640 all=211242 active=11815 piece=ufact\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1358 size=4660 all=211652 active=12225 piece=▁संग्रह\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1351 size=4680 all=211961 active=12534 piece=ex\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1342 size=4700 all=212505 active=13078 piece=▁पर��रदिगार\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1341 min_freq=300\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1334 size=4720 all=212838 active=10959 piece=▁himself\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1325 size=4740 all=213473 active=11594 piece=head\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1318 size=4760 all=214272 active=12393 piece=ication\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1309 size=4780 all=214694 active=12815 piece=त्रियों\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1301 size=4800 all=215012 active=13133 piece=▁जैसा\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1300 min_freq=293\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1294 size=4820 all=215720 active=11458 piece=▁poor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1286 size=4840 all=216111 active=11849 piece=▁Russ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1280 size=4860 all=216450 active=12188 piece=▁बाइबल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1273 size=4880 all=216797 active=12535 piece=▁history\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1267 size=4900 all=217609 active=13347 piece=▁resol\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1266 min_freq=286\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1260 size=4920 all=218012 active=11275 piece=▁parents\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1254 size=4940 all=218420 active=11683 piece=▁quality\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1245 size=4960 all=218881 active=12144 piece=AP\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1239 size=4980 all=219263 active=12526 piece=▁रिज\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1231 size=5000 all=219717 active=12980 piece=▁शब्द\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1231 min_freq=280\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1225 size=5020 all=220072 active=11325 piece=▁Sub\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1218 size=5040 all=220692 active=11945 piece=▁संक्रम\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1212 size=5060 all=221179 active=12432 piece=ंकी\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1207 size=5080 all=221734 active=12987 piece=olk\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1202 size=5100 all=221997 active=13250 piece=स्लिम\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1202 min_freq=273\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1197 size=5120 all=222529 active=11624 piece=onse\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1190 size=5140 all=222913 active=12008 piece=▁personnel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1184 size=5160 all=223471 active=12566 piece=▁अथवा\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1175 size=5180 all=223977 active=13072 piece=▁सत्र\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1167 size=5200 all=224530 active=13625 piece=etro\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1167 min_freq=267\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1161 size=5220 all=224926 active=11586 piece=▁निपट\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1154 size=5240 all=225240 active=11900 piece=aur\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1149 size=5260 all=225818 active=12478 piece=▁विजय\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1144 size=5280 all=226156 active=12816 piece=्रो\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1138 size=5300 all=226565 active=13225 piece=प्त\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1138 min_freq=261\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1134 size=5320 all=226825 active=11544 piece=▁April\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1129 size=5340 all=227181 active=11900 piece=▁रिकॉर्ड\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1123 size=5360 all=227806 active=12525 piece=▁सक्रिय\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1117 size=5380 all=228145 active=12864 piece=ta\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1111 size=5400 all=228562 active=13281 piece=▁शरीर\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1110 min_freq=256\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1105 size=5420 all=228961 active=11819 piece=acy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1102 size=5440 all=229412 active=12270 piece=odies\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1097 size=5460 all=229749 active=12607 piece=▁declared\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1091 size=5480 all=230439 active=13297 piece=▁cities\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1085 size=5500 all=230724 active=13582 piece=ocu\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1085 min_freq=251\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1081 size=5520 all=231292 active=12094 piece=▁कॉलेज\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1076 size=5540 all=231709 active=12511 piece=▁कड़ी\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1071 size=5560 all=232065 active=12867 piece=थि\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1068 size=5580 all=232547 active=13349 piece=▁आठ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1063 size=5600 all=233043 active=13845 piece=▁integr\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1063 min_freq=246\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1058 size=5620 all=233273 active=11869 piece=▁upcoming\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1050 size=5640 all=233559 active=12155 piece=▁Iran\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1045 size=5660 all=233887 active=12483 piece=▁driver\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1040 size=5680 all=234385 active=12981 piece=▁km\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1034 size=5700 all=234771 active=13367 piece=जित\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1034 min_freq=242\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1028 size=5720 all=235112 active=12042 piece=▁hands\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1023 size=5740 all=235440 active=12370 piece=▁living\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1018 size=5760 all=235745 active=12675 piece=वहीं\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1015 size=5780 all=236011 active=12941 piece=▁45\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1011 size=5800 all=236276 active=13206 piece=▁Arun\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1011 min_freq=237\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1007 size=5820 all=236604 active=12123 piece=स्टम\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1004 size=5840 all=237087 active=12606 piece=▁ones\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=999 size=5860 all=237250 active=12769 piece=▁camera\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=994 size=5880 all=237597 active=13116 piece=ovember\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=990 size=5900 all=238175 active=13694 piece=▁एजेंसी\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=989 min_freq=233\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=985 size=5920 all=238417 active=12150 piece=▁बनाई\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=979 size=5940 all=238675 active=12408 piece=▁सजा\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=975 size=5960 all=238962 active=12695 piece=▁pat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=971 size=5980 all=239272 active=13005 piece=▁inaugur\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=963 size=6000 all=239462 active=13195 piece=4,\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=963 min_freq=229\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=959 size=6020 all=239827 active=12257 piece=▁creat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=955 size=6040 all=240079 active=12509 piece=ja\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=953 size=6060 all=240412 active=12842 piece=▁schools\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=948 size=6080 all=240798 active=13228 piece=▁Int\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=943 size=6100 all=241208 active=13638 piece=▁वायरल\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=943 min_freq=225\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=939 size=6120 all=241326 active=12177 piece=▁Road\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=935 size=6140 all=241624 active=12475 piece=▁petition\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=931 size=6160 all=242049 active=12900 piece=▁German\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=927 size=6180 all=242440 active=13291 piece=��operations\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=924 size=6200 all=242856 active=13707 piece=▁rank\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=924 min_freq=221\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=920 size=6220 all=243294 active=12575 piece=▁रूस\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=917 size=6240 all=243668 active=12949 piece=▁गेंदबाज\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=914 size=6260 all=244054 active=13335 piece=▁charges\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=910 size=6280 all=244537 active=13818 piece=ably\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=907 size=6300 all=245200 active=14481 piece=▁कारोबार\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=907 min_freq=217\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=904 size=6320 all=245681 active=12740 piece=▁forg\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=902 size=6340 all=245913 active=12972 piece=▁सुल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=898 size=6360 all=246346 active=13405 piece=दाताओं\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=894 size=6380 all=246855 active=13914 piece=US\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=891 size=6400 all=247198 active=14257 piece=▁आंध्र\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=891 min_freq=214\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=887 size=6420 all=247342 active=12502 piece=कल्प\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=883 size=6440 all=247629 active=12789 piece=▁अय\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=880 size=6460 all=248069 active=13229 piece=▁प्रारंभ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=875 size=6480 all=248358 active=13518 piece=▁34\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=871 size=6500 all=248608 active=13768 piece=▁रणनी\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=870 min_freq=210\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=867 size=6520 all=248985 active=12802 piece=ोषण\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=865 size=6540 all=249293 active=13110 piece=कारात्मक\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=862 size=6560 all=249477 active=13294 piece=▁Cons\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=858 size=6580 all=249919 active=13736 piece=िस्ट\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=855 size=6600 all=250325 active=14142 piece=▁wal\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=855 min_freq=206\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=852 size=6620 all=250728 active=12909 piece=त्तीसगढ़\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=849 size=6640 all=251071 active=13252 piece=▁accom\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=846 size=6660 all=251433 active=13614 piece=▁everything\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=841 size=6680 all=251888 active=14069 piece=5,\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=837 size=6700 all=252225 active=14406 piece=ौन\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=837 min_freq=203\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=833 size=6720 all=252554 active=12891 piece=द्योगिक\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=830 size=6740 all=252908 active=13245 piece=▁श्रेणी\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=826 size=6760 all=253390 active=13727 piece=▁दस्ता\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=822 size=6780 all=253538 active=13875 piece=सच\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=820 size=6800 all=253726 active=14063 piece=िनी\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=820 min_freq=200\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=817 size=6820 all=254033 active=12907 piece=अम\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=815 size=6840 all=254280 active=13154 piece=▁तुम्हारा\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=810 size=6860 all=254752 active=13626 piece=हाद\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=807 size=6880 all=255053 active=13927 piece=▁mobile\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=804 size=6900 all=255221 active=14095 piece=▁smart\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=804 min_freq=197\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=801 size=6920 all=255837 active=13369 piece=▁कर्मचारी\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=798 size=6940 all=256323 active=13855 piece=merce\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=795 size=6960 all=256660 active=14192 piece=▁undert\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=792 size=6980 all=256998 active=14530 piece=▁gas\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=789 size=7000 all=257317 active=14849 piece=▁चित्र\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=789 min_freq=194\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=786 size=7020 all=257674 active=13201 piece=▁site\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=783 size=7040 all=257902 active=13429 piece=hips\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=782 size=7060 all=258218 active=13745 piece=▁status\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=779 size=7080 all=258338 active=13865 piece=▁earn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=776 size=7100 all=258700 active=14227 piece=▁कार्यक्रमों\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=775 min_freq=191\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=772 size=7120 all=258991 active=13226 piece=तुम\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=770 size=7140 all=259351 active=13586 piece=▁punishment\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=767 size=7160 all=259561 active=13796 piece=▁initiative\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=764 size=7180 all=259790 active=14025 piece=▁उन्\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=761 size=7200 all=260040 active=14275 piece=▁plant\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=760 min_freq=188\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=757 size=7220 all=260429 active=13384 piece=everal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=755 size=7240 all=260831 active=13786 piece=▁बहन\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=752 size=7260 all=261237 active=14192 piece=▁...\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=748 size=7280 all=261454 active=14409 piece=What\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=745 size=7300 all=261672 active=14627 piece=▁heard\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=744 min_freq=185\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=741 size=7320 all=262120 active=13531 piece=▁phase\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=738 size=7340 all=262355 active=13766 piece=▁इकाई\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=736 size=7360 all=262616 active=14027 piece=▁भ्रष्ट\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=733 size=7380 all=262788 active=14199 piece=▁nations\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=730 size=7400 all=263298 active=14709 piece=▁मीटर\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=730 min_freq=183\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=728 size=7420 all=263629 active=13494 piece=▁resources\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=725 size=7440 all=263923 active=13788 piece=▁उत्पादों\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=721 size=7460 all=264273 active=14138 piece=खे\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=719 size=7480 all=264535 active=14400 piece=incipal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=717 size=7500 all=264733 active=14598 piece=▁मुसलमान\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=716 min_freq=181\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=714 size=7520 all=265488 active=13989 piece=फारिश\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=711 size=7540 all=265709 active=14210 piece=▁Abd\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=708 size=7560 all=265881 active=14382 piece=डाउन\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=705 size=7580 all=266022 active=14523 piece=▁परन्तु\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=703 size=7600 all=266736 active=15237 piece=▁facing\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=703 min_freq=178\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=700 size=7620 all=266927 active=13528 piece=▁Association\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=697 size=7640 all=267319 active=13920 piece=year\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=694 size=7660 all=267771 active=14372 piece=्रपति\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=692 size=7680 all=268232 active=14833 piece=▁democracy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=689 size=7700 all=268531 active=15132 piece=▁पौ\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=689 min_freq=175\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=687 size=7720 all=268815 active=13673 piece=▁railway\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=685 size=7740 all=269078 active=13936 piece=▁Telangana\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=682 size=7760 all=269223 active=14081 piece=▁गोल\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=679 size=7780 all=269478 active=14336 piece=▁fig\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=677 size=7800 all=269699 active=14557 piece=▁Industry\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=676 min_freq=173\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=674 size=7820 all=270094 active=13879 piece=▁Na\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=672 size=7840 all=270433 active=14218 piece=rim\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: en-hi.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: en-hi.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train(input=['../data/en-hi/hindi_small_train.txt', '../data/en-hi/english_small_train.txt'], model_prefix=\"en-hi\", model_type='bpe', vocab_size=8000, pad_id=3, bos_piece=\"<SOS>\", eos_piece=\"<EOS>\", unk_piece=\"<UNK>\", pad_piece=\"<PAD>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[196], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_total\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(test_total)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/matplotlib/pyplot.py:3794\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3786\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3788\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3793\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3795\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3798\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3799\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3800\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1779\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1778\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1779\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/matplotlib/axes/_base.py:296\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    295\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/matplotlib/axes/_base.py:483\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    481\u001b[0m     axes\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mupdate_units(x)\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axes\u001b[38;5;241m.\u001b[39myaxis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 483\u001b[0m     \u001b[43maxes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myaxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/matplotlib/axis.py:1756\u001b[0m, in \u001b[0;36mAxis.update_units\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1754\u001b[0m neednew \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverter \u001b[38;5;241m!=\u001b[39m converter\n\u001b[1;32m   1755\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverter \u001b[38;5;241m=\u001b[39m converter\n\u001b[0;32m-> 1756\u001b[0m default \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_units(default)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/matplotlib/category.py:105\u001b[0m, in \u001b[0;36mStrCategoryConverter.default_units\u001b[0;34m(data, axis)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# the conversion call stack is default_units -> axis_info -> convert\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis\u001b[38;5;241m.\u001b[39munits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     axis\u001b[38;5;241m.\u001b[39mset_units(\u001b[43mUnitData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     axis\u001b[38;5;241m.\u001b[39munits\u001b[38;5;241m.\u001b[39mupdate(data)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/matplotlib/category.py:181\u001b[0m, in \u001b[0;36mUnitData.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_counter \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mcount()\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/matplotlib/category.py:214\u001b[0m, in \u001b[0;36mUnitData.update\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# check if convertible to number:\u001b[39;00m\n\u001b[1;32m    213\u001b[0m convertible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m \u001b[43mOrderedDict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# OrderedDict just iterates over unique values in data.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     _api\u001b[38;5;241m.\u001b[39mcheck_isinstance((\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m), value\u001b[38;5;241m=\u001b[39mval)\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convertible:\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;66;03m# this will only be called so long as convertible is True.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_total)\n",
    "plt.plot(test_total)\n",
    "plt.legend(['train', 'test'])\n",
    "# plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing hindi Translation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageTranslationDataset(Dataset):\n",
    "    def __init__(self, seq_length, src_encodings, tgt_encodings, sos_token, eos_token, pad_token):\n",
    "        super().__init__()\n",
    "        self.paired_encodings = LanguageTranslationDataset.augment_encodings(src_encodings, tgt_encodings, sos_token, eos_token)\n",
    "        self.seq_len = seq_length\n",
    "        self.pad_token = pad_token\n",
    "\n",
    "    @staticmethod\n",
    "    def augment_encodings(src_encodings, tgt_encodings, sos_token, eos_token):\n",
    "        src_encodings_app = [[sos_token] + sublist + [eos_token] for sublist in src_encodings]\n",
    "        tgt_encodings_app = [[sos_token] + sublist for sublist in tgt_encodings]\n",
    "        output_encodings = [sublist + [eos_token] for sublist in tgt_encodings] \n",
    "        full_encoding = list(zip(src_encodings_app, tgt_encodings_app, output_encodings))\n",
    "        full_encoding.sort(key=lambda x: len(x[0])) # sort sequence lengths\n",
    "        return full_encoding\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "            src_seq, tgt_seq, output_seq = self.paired_encodings[idx]\n",
    "            \n",
    "            # Convert to tensors\n",
    "            src_tensor = torch.tensor(src_seq, dtype=torch.long)\n",
    "            tgt_tensor = torch.tensor(tgt_seq, dtype=torch.long)\n",
    "            output_tensor = torch.tensor(output_seq, dtype=torch.long)\n",
    "\n",
    "            # **Ensure the sequence length does not exceed `seq_len`**\n",
    "            if src_tensor.size(0) > self.seq_len:\n",
    "                src_tensor = src_tensor[:self.seq_len]  # Crop excess tokens\n",
    "            if tgt_tensor.size(0) > self.seq_len:\n",
    "                tgt_tensor = tgt_tensor[:self.seq_len]  # Crop excess tokens\n",
    "            if output_tensor.size(0) > self.seq_len:\n",
    "                output_tensor = output_tensor[:self.seq_len]  # Crop excess tokens\n",
    "\n",
    "            # **Pad sequences to `seq_len` if they are shorter**\n",
    "            src_tensor = F.pad(src_tensor, (0, max(0, self.seq_len - src_tensor.size(0))), value=self.pad_token)\n",
    "            tgt_tensor = F.pad(tgt_tensor, (0, max(0, self.seq_len - tgt_tensor.size(0))), value=self.pad_token)\n",
    "            output_tensor = F.pad(output_tensor, (0, max(0, self.seq_len - output_tensor.size(0))), value=self.pad_token)\n",
    "            encoder_mask = (src_tensor != self.pad_token).int()\n",
    "            subsequent_mask = torch.tril(torch.ones((self.seq_len, self.seq_len), dtype=torch.int))\n",
    "            padding_mask = (tgt_tensor != self.pad_token).int()\n",
    "            decoder_mask = subsequent_mask & padding_mask.unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "            return {\n",
    "                \"src\": src_tensor, # Seq_len\n",
    "                \"tgt\": tgt_tensor, # seq_len\n",
    "                \"output\": output_tensor, # seq_len\n",
    "                \"encoder_mask\" : encoder_mask.unsqueeze(0).unsqueeze(0), # 1 x 1 x seq_len\n",
    "                \"decoder_mask\" : decoder_mask.unsqueeze(0), # 1 x seq_len x seq_len\n",
    "            }\n",
    "    def __len__(self): \n",
    "            return len(self.paired_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(model, batch, max_len, device, sos_token, eos_token, pad_token):\n",
    "    encoder_input = batch['src'].to(device) # B x seq_len\n",
    "    encoder_mask = batch['encoder_mask'].to(device) # B  x 1 x 1 x seq_len\n",
    "    encoder_output = model.encode(encoder_input, encoder_mask)\n",
    "    B = encoder_input.size(0)\n",
    "    decoder_input = torch.full((B, max_len), pad_token).to(device)\n",
    "    decoder_input[: , 0] = sos_token\n",
    "    finished = torch.zeros(B, dtype=torch.bool, device=device)\n",
    "\n",
    "    for t in range(max_len - 1):\n",
    "        subsequent_mask = torch.tril(torch.ones((max_len, max_len), dtype=torch.int)).expand(B, -1, -1).to(device) # shape: (B, max_len, max_len)\n",
    "        other_mask =(decoder_input != pad_token).int().unsqueeze(1) # (B, 1, max_len)\n",
    "        decoder_mask = (subsequent_mask & other_mask).unsqueeze(1).to(device)\n",
    "        out = model.decode(decoder_input, encoder_output, encoder_mask, decoder_mask)\n",
    "        prediction = model.proj(out) # Expected shape: (B, max_len, vocab_size)\n",
    "        next_tokens = torch.argmax(prediction[:, t, :], dim=-1) # shape: (B, )\n",
    "        next_tokens = torch.where(finished, pad_token, next_tokens)\n",
    "\n",
    "        decoder_input[:, t + 1] = next_tokens\n",
    "        finished |= (next_tokens == eos_token)\n",
    "\n",
    "        if finished.all():\n",
    "          break\n",
    "\n",
    "    return decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"../papers/attention_is_all_you_need/Models/multi_hindi_small/Model_100\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "checkpoint['model_state_dict'] = OrderedDict(\n",
    "    (key[7:] if key.startswith(\"module.\") else key, value)\n",
    "    for key, value in checkpoint['model_state_dict'].items()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_english = pd.read_table(\"../data/en-hi/train.en\", header=None, skiprows=200_000, nrows=250000)\n",
    "train_hindi = pd.read_table(\"../data/en-hi/train.hi\", header=None, skiprows=200_000, nrows=250000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "sp = spm.SentencePieceProcessor(model_file='../papers/attention_is_all_you_need/BPE/en-hi.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "indices = np.random.randint(low=0, high=250_000, size=20)\n",
    "inference_dataset = LanguageTranslationDataset(140,sp.encode_as_ids(train_english.iloc[indices, 0].to_list()), \n",
    "                                               sp.encode_as_ids(train_hindi.iloc[indices, 0].to_list()), sp.bos_id(), sp.eos_id(), sp.pad_id())\n",
    "inference_data = DataLoader(inference_dataset, batch_size=len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(inference_data))\n",
    "preds = model_prediction(model, batch, 140, \"cpu\", sp.bos_id(), sp.eos_id(), sp.pad_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = sp.decode(preds.detach().cpu().tolist())\n",
    "actual_decoded = sp.decode(batch['tgt'][:, :].detach().cpu().tolist())\n",
    "source_sentence = sp.decode(batch['src'][:, :].detach().cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english sentence: Six of ...\n",
      "hindi sentence: छठे दौ .\n",
      "model sentence: छह में .\n",
      "-----------------------------------\n",
      "english sentence: Most wanted criminal arrested\n",
      "hindi sentence: मोस्ट वांटेड बदमाश गिरफ्तार\n",
      "model sentence: सबसे अधिक आरोपी गिरफ्तार\n",
      "-----------------------------------\n",
      "english sentence: But it was of no avail.\n",
      "hindi sentence: मगर फायदा नहीं हुआ।\n",
      "model sentence: लेकिन इसका कोई फायदा नहीं हुआ।\n",
      "-----------------------------------\n",
      "english sentence: He has benefitted from that.\n",
      "hindi sentence: उसने लाभ कमाया है।\n",
      "model sentence: इससे उन्हें फायदा हुआ है।\n",
      "-----------------------------------\n",
      "english sentence: Just one wrinkle.\n",
      "hindi sentence: सिर्फएकशिकन .\n",
      "model sentence: सिर्फ एक ही लकड़ी है।\n",
      "-----------------------------------\n",
      "english sentence: Failed to list objects:% s\n",
      "hindi sentence: वस्तु सूचीबद्ध करने में विफलः% s\n",
      "model sentence: वस्तु सूचीबद्ध करने में विफलः% s\n",
      "-----------------------------------\n",
      "english sentence: Rs 64 crore were released during 2000 - 01.\n",
      "hindi sentence: वर्ष 2000-2001 के दौरान इस कार्यक्रम मे तहत 64 करोड़ जारी किए गए।\n",
      "model sentence: 2000-01 के दौरान 64 करोड़ रुपये जारी किए गए।\n",
      "-----------------------------------\n",
      "english sentence: The boars are gathering in the forest.\n",
      "hindi sentence: सुअरों जंगल में जमा हो रहे हैं.\n",
      "model sentence: जंगल में बारीकियां जंगल में इकट्ठा हो रही हैं।\n",
      "-----------------------------------\n",
      "english sentence: These reports, however, have not been confirmed by the board.\n",
      "hindi sentence: हालांकि परिषद की ओर से इन आंकड़ों की पुष्टि ⁇  नहीं हो पाई।\n",
      "model sentence: हालांकि, इन रिपोर्टों की पुष्टि नहीं हुई है।\n",
      "-----------------------------------\n",
      "english sentence: Kumar secretly records this information and blackmails him.\n",
      "hindi sentence: कुमार चुपके से इस जानकारी को रिकॉर्ड कर लेता है और उसे ब्लैकमेल करता है।\n",
      "model sentence: कुमार ने कहा कि यह जानकारी और कालेमेल उसे रिकॉर्ड करता है।\n",
      "-----------------------------------\n",
      "english sentence: There are a lot more men, and not just in India, but everywhere else.\n",
      "hindi sentence: ऐसे बहुत सारे पुरुष हैं और ना केवल भारत में बल्कि हर जगह हैं।\n",
      "model sentence: भारत में बहुत से और अधिक लोग हैं, न केवल भारत में बल्कि हर जगह।\n",
      "-----------------------------------\n",
      "english sentence: In ancient times, all the people used to fast on the day of Ekadashi in the area ruled by a king.\n",
      "hindi sentence: प्रचीन काल में एक राजा के राज्य में एकादशी के दिन सभी लोग व्रत रखते थे।\n",
      "model sentence: प्राचीन काल में, सभी लोग एकादशी के दिन में, एकादशी के दिन में प्रचार करते थे।\n",
      "-----------------------------------\n",
      "english sentence: Out of a total of about 230 items in the 28 per cent slab, about 200 items have been shifted to lower slabs.\n",
      "hindi sentence: 28 प्रतिशत की कर श्रेणी की कुल दो सौ तीस वस्तुओं में से करीब दो सौ वस्तुओं को कम दर वाली श्रेणी में लाया गया है।\n",
      "model sentence: 28 प्रतिशत स्लाब में कुल 230 वस्तुओं में से लगभग 200 वस्तुओं को ढाल दिया गया है।\n",
      "-----------------------------------\n",
      "english sentence: If this judgment had come earlier, former Telecom Minister A. Raja would have cited it and moved an appellate court asking for the media to keep out of the 2G spectrum trial.\n",
      "hindi sentence: यदि यह निर्णय पहले आ गया होता तो पूर्व संचार मंत्री ए. राजा ने इसी का हवाला देकर 2जी स्पैक्ट्रम मुकदमे से मीडिया को दूर रखने के लिए पौनर्वादिक न्यायालय की शरण ले ली होती।\n",
      "model sentence: अगर यह फैसला पहले आया था, तो पूर्व दूरसंचार मंत्री ए. राजा ने इसे एक अपील में ले लिया था और 2जी स्पेक्ट्रम परीक्षण को लेकर अपील की थी कि वह अपील की थी।\n",
      "-----------------------------------\n",
      "english sentence: In the cities of Hyderabad, Bhubaneshwar, Ranchi, Raipur, Amravati and Shimla, one or more samples did not comply with the requirements of the Indian Standard.\n",
      "hindi sentence: हैदराबाद, भुवनेश्वर, रांची, रायपुर, अमरावती और शिमला, इन शहरों से लिए गए एक या उस से अधिक नमूने भारतीय मानक के अनुरूप नहीं पाए गए.\n",
      "model sentence: हैदराबाद के शहरों में भारतीय मानक के आवश्यकताओं के अनुरूप नहीं थे।\n",
      "-----------------------------------\n",
      "english sentence: The Gujarat Chief Minister Smt Anandiben Patel met the Minister of state (Independent charge) for Petroleum and Natural Gas Shri Dharmendra Pradhan here today, and discussed the issues between the state and the Centre regarding oil and gas.\n",
      "hindi sentence: गुजरात की मुख्यमंत्री श्रीमती आनंदीबेन पटेल ने आज यहां पेट्रोलियम और प्राकृतिक गैस राज्य मंत्री (स्वतंत्र प्रभार) श्री धर्मेन्द्र प्रधान से मुलाकात की और तेल तथा गैस के संबंध में राज्य एवं केंद्र के बीच मुद्दों पर चर्चा की।\n",
      "model sentence: गुजरात के मुख्यमंत्री श्रीमती आनंदीबेन पटेल ने आज यहां पेट्रोलियम और प्राकृतिक गैस राज्य मंत्री (स्वतंत्र प्रभार) श्री धर्मेंद्र प्रधान के साथ बैठक की और सरकार और केंद्र के बीच मुद्दों पर चर्चा की।\n",
      "-----------------------------------\n",
      "english sentence: Open Basic Education (OBE) Programme for 14  ⁇  years age group, adolescents and adults at A, B and C levels that are equivalent to classes III, V and VIII of the formal school system.\n",
      "hindi sentence: 14  ⁇  आयु समूह के बच्चों किशोरों और प्रौढ़ों के लिए मुक्त बेसिक शिक्षा (ओबीई) कार्यक्रम जिसके, बी और सी स्तर औपचारिक स्कूली शिक्षा को तीसरी पांचवी और आठवीं के समकक्ष हैं।\n",
      "model sentence: 14 से वर्ष की आयु वर्ग के लिए ओपन मूल शिक्षा (ओबीई) कार्यक्रम, ए, बी और सी स्तर पर वयस्क शामिल हैं जो क्लास III, वी और वीआईआईआई के समतुल्य हैं।\n",
      "-----------------------------------\n",
      "english sentence: As per Indian law, except Sikkim, online sports betting is illegal in all territories, said sport and gaming lawyer Vidushpat Singhania, who was the secretary to the Justice Mudgal-led IPL match-fixing probe committee.\n",
      "hindi sentence: खेल और गेमिंग वकील विदुषपत सिंघानिया ने कहा, भारतीय कानून के अनुसार, सिक्किम को छोड़कर, हर जगह ऑनलाइन खेल सट्टेबाजी अवैध है।\n",
      "model sentence: सिक्किम के अलावा, सभी क्षेत्रों में ऑनलाइन खेल सट्टाधना के अलावा खेल और वकील विदुषपत सिंघानिया ने कहा कि न्यायमूर्ति मुडल के नेतृत्व वाली आईपीएल-फिक्सिंग समिति में से सचिव थे।\n",
      "-----------------------------------\n",
      "english sentence: Before the start of each of the four races at the Jawaharlal Nehru Stadium, Tendulkar did 10 push-ups as part of the  ⁇ KeepMoving Push-up Challenge and urged the runners to join him in the exercise.\n",
      "hindi sentence: जवाहरलाल नेहरू स्टेडियम में चार रेस में प्रत्येक के शुरू होने से पहले तेंदुलकर ने ‘कीप मूविंग पुश-अप चैलेंज’ के अंतर्गत 10 पुश-अप किए और धावकों से इसमें उनके साथ जुड़ने का आग्रह किया।\n",
      "model sentence: जवाहरलाल नेहरू स्टेडियम में से प्रत्येक चार रेस की शुरुआत से पहले तेंदुलकर ने कंधा मोविंग पुशपोरिंग पुश-अप के भाग के रूप में 10 रन बना लिए थे और उन्होंने उनसे आग्रह किया कि वे अपने अभ्यास में शामिल हों।\n",
      "-----------------------------------\n",
      "english sentence: Puritan minister Thomas Brooks (1608 - 80) observed: God looks not at the oratory of your prayers, how elegant they may be. nor at the geometry of your prayers, how long they may be. nor at the arithmetic of your prayers, how many they may be. not at logic of your prayers, how methodical they may be. but the sincerity of them he looks at.\n",
      "hindi sentence: प्यूरिटन पादरी थॉमस ब्रुक्स ( ⁇  -  ⁇ ) ने कहा: “परमेश्‍वर आपकी प्रार्थनाओं की वाक्पटुता नहीं देखते, कि ये कितने सुरुचिपूर्ण हैं. न आपकी प्रार्थनाओं की ज्यामिति को देखते, कि ये कितने लम्बे हैं. न आपकी प्रार्थनाओं के अंकगणित को देखते, कि ये कितने ज़्यादा हैं. न आपकी प्रार्थनाओं की तर्कसंगति को देखते, कि ये कितने सिलसिलेवार हैं. पर वह उनकी निष्कपटता को देखते हैं । ”\n",
      "model sentence: पुरीत की मंत्री थॉमस ब्रुक ने कहा: “जो कुछ भी हो, वे प्रार्थनाओं के विषय में नहीं देख पाते, वे कितने ही हो सकते हैं, और अपनी प्रार्थनाओं की जीन में कितने ही हो सकते हैं, वे अपने प्रार्थनाओं की उपासना करते हैं, कितने समय तक वे आपसे हो सकते हैं । ”\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(decoded)):\n",
    "    print(f\"english sentence: {source_sentence[i]}\")\n",
    "    print(f\"hindi sentence: {actual_decoded[i]}\")\n",
    "    print(f\"model sentence: {decoded[i]}\")\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Following his retirement from international cricket, his future in the T20 leagues was uncertain.', 'अंतरराष्ट्रीय क्रिकेट से संन्यास के बाद, टी 20 लीग में उनका भविष्य अनिश्चित था।', 'अंतरराष्ट्रीय क्रिकेट से संन्यास लेने के बाद, टी20 लीग में भविष्य का पता नहीं चल पाया है।'), \n",
    "(\"In Bihar, the Rashtriya Janata Dal won the Simri-Bakhtiarpur and Belhar seats, the AIMIM's  ⁇ amrul Hoda won in Kishanganj and the ruling Janata Dal-United in the Nathnagar constituency.\", 'बिहार की किशनगंज में एआईएमआईएम, सिमरी बख्तिायारपुर और बेलहर में राष्ट्रीय जनता दल, नाथनगर में जनता दल (यूनाइटेड) और दरौंदा में निर्दलीय उम्मीदवार को जीत मिली।', 'बिहार में राष्ट्रीय जनता दल ने सिमर-बख्तियारपुर और बेल्हर सीट पर जीत हासिल की और एआईएमआईएमआईएम के क्वारुल होडा और नाथनगर सीट पर जनता दल यूनाइटेड में जीत हासिल की।'), \n",
    "(\"India has approved two vaccines Bharat Biotech's Covaxin and Serum Institute of India's Covishield for emergency use in the country.\", 'देश में दो टीकों-कोवैक्सीन और सीरम इंस्टीट्यूट के कोविशील्ड को आपात उपयोग की मंजूरी मिली है।', 'भारत ने देश में आपातकालीन उपयोग के लिए भारत बायोटेक और सेरम इंस्टीट्यूट ऑफ इंडिया के कोविशील्डड को दो टीके को मंजूरी दी है।'), ('Police arrested two kidnappers in the case.', 'मामले में पुलिस ने दो फैक्ट्रियों पर छापा मारते हुए दो मिलावटखोरों को गिरफ्तार कर लिया।', 'पुलिस ने इस मामले में दो बदमाशों को गिरफ्तार कर लिया है।'), ('Or is it because you feel that the other person deliberately attempted to hurt you?', 'या क्या आपको लगता है कि किसी ने जानबूझकर आपको चोट पहुँचायी है?', 'या क्या आपने महसूस किया कि दूसरे व्यक्ति ने आपको चोट पहुंचाने का प्रयास किया?'), ('A note regarding transfer of indent.', 'मांग पत्र को हस्तांतरित करने वाला नोट (ज्ञापन)।', 'अनंतकालीन के बारे में कोई जानकारी।'), \n",
    "('On the India-US call for maritime freedom in the Indo-Pacific region Hua said, About the security navigation in the sea, we uphold the legal rights entitled in the international law and we also hope parties can do real things to ensure freedom of navigation.', 'भारत-प्रशांत क्षेत्र में समुद्री स्वतंत्रता के लिए भारत-अमेरिका के आह्वान के संदर्भ में हुआ ने कहा कि समुद्र में सुरक्षा नौवहन के बारे में हम अंतरराष्ट्रीय कानून में उल्लेखित कानूनी अधिकारों को कायम रखेंगे और हम यह उम्मीद भी करते हैं कि नौवहन स्वतंत्रता के लिए पक्ष वास्तविक काम करें।’’', 'भारत-अमेरिका के भारत-अमेरिका के लिए समुद्री स्वतंत्रता की अपील पर हुवा ने कहा, समुद्र में सुरक्षा नौवहन के बारे में हम अंतरराष्ट्रीय कानून में दायर कानूनी अधिकारों को बनाए रखते हैं और हम उम्मीद कर सकते हैं कि पक्ष ने भी सिंचाई की स्वतंत्रता सुनिश्चित करने के लिए वास्तविक चीजें कर सकते हैं।'), ('On receiving the information, the police reached the spot and shifted the body to the hospital for post-mortem.', 'सूचना मिलते ही पुलिस घटना स्थल पर पहुंच गई और शव को पोस्टमार्टम के लिए अस्पताल भेज दिया।', 'सूचना मिलते ही मौके पर पहुंची पुलिस ने शव को कब्जे में लेकर पोस्टमार्टम के लिए अस्पताल पहुंचाया।'), ('In response to a question about democratic socialism ultimately calling for an end to capitalism during a Firing Line interview on PBS, she answered: \"Ultimately, we are marching towards progress on this issue.', 'लोकतांत्रिक समाजवाद के बारे में एक सवाल के जवाब में अंततः पीबीएस पर एक फायरिंग लाइन साक्षात्कार के दौरान पूंजीवाद को समाप्त करने का आह्वान किया, उसने जवाब दिया: \"आखिरकार, हम इस मुद्दे पर प्रगति की ओर अग्रसर हैं।', 'पीबीएस पर फायरिंग लाइन साक्षात्कार के दौरान लोकतांत्रिक सामाजिकता के बारे में एक सवाल के जवाब में उन्होंने कहा, \"पिछले ही हम इस मुद्दे पर प्रगति की ओर बढ़ रहे हैं।'), ('Organic manure covers manure made from cattle dung, excreta of other animals, rural and urban composts, other animal wastes, crop residues and green manures.', 'जैविक खाद में मवेशी के गोबर, जानवरों के अपशिष्ट, ग्रामीण और शहरी कम्पोस्ट, अन्य पशु अवशिष्ट, फसलों के अपशिष्ट और हरे खाद शामिल हैं।', 'जैविक मानवता के सहकर्मी, पशु धुँध, ग्रामीण और शहरी पदार्थों, अन्य जानवरों, फसलों और हरे हुए लोगों से भरी हुई।'), ('New Delhi: The Honourable Supreme Court has given its verdict on the Ayodhya issue.', 'नई दिल्ली: अयोध्या मामले को लेकर सुप्रीम कोर्ट से बड़ी खबर आई है.', 'नई दिल्ली: सुप्रीम कोर्ट ने अयोध्या मुद्दे पर अपना फैसला सुनाया है।'), (\"India will be 5 trillion dollar economy by 2024: PM Modi at NITI Aayog's meet\", 'BRICS: बिजनेस फोरम में PM मोदी बोले- 2024 तक 5 ट्रिलियन डॉलर होगी इकोनॉमी', 'नीति आयोग की बैठक में भारत 5 ट्रिलियन डॉलर की अर्थव्यवस्था होगी : पीएम मोदी'), \n",
    "('Thereafter, a ruckus ensued.', 'इसके बाद हडकम्प मच गया।', 'इसके बाद एक रुक गया।')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention_visualisation import get_attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inference_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43minference_data\u001b[49m))\n\u001b[1;32m      2\u001b[0m attention_dicts \u001b[38;5;241m=\u001b[39m get_attention(model, batch)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inference_data' is not defined"
     ]
    }
   ],
   "source": [
    "batch = next(iter(inference_data))\n",
    "attention_dicts = get_attention(model, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4, 140, 140])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attention_dict --> (batch x n_heads x seq_len x seq_len)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def process_and_visualise_attention(attentions, pixel_values, patch_size, threshold=0.6, raw_attn=False):    \n",
    "    # Extract the CLS token attention (first token attending to all patches)    \n",
    "    nh = attentions.shape[0]  # Number of attention heads\n",
    "    attentions = attentions[:, 0, 1:].reshape(nh, -1)\n",
    "    \n",
    "    w_featmap = pixel_values.shape[-2] // patch_size\n",
    "    h_featmap = pixel_values.shape[-1] // patch_size\n",
    "    \n",
    "    val, idx = torch.sort(attentions)  # Sort values per query\n",
    "    val /= torch.sum(val, dim=1, keepdim=True)  # Normalize each col to sum to 1\n",
    "    cumval = torch.cumsum(val, dim=1)  # Compute cumulative sum\n",
    "    th_attn = cumval > (1 - threshold)  # Mask for top 'threshold' percentage\n",
    "    idx2 = torch.argsort(idx)\n",
    "    \n",
    "    for head in range(nh):\n",
    "        th_attn[head] = th_attn[head][idx2[head]]\n",
    "\n",
    "    th_attn = th_attn.reshape(nh, w_featmap, h_featmap).float()\n",
    "    th_attn = nn.functional.interpolate(\n",
    "        th_attn.unsqueeze(0), scale_factor=patch_size, mode=\"bicubic\"\n",
    "    )[0].cpu().detach().numpy()\n",
    "\n",
    "    attentions = attentions.reshape(nh, w_featmap, h_featmap)\n",
    "    attentions = nn.functional.interpolate(\n",
    "        attentions.unsqueeze(0), scale_factor=patch_size, mode=\"bicubic\"\n",
    "    )[0].cpu().detach().numpy()\n",
    "\n",
    "    image_np = pixel_values.permute(1, 2, 0).cpu().numpy()  # Shape: (H, W, C)\n",
    "    image_np = (image_np - image_np.min()) / (image_np.max() - image_np.min())  # Normalize to [0,1]\n",
    "    \n",
    "    num_rows = 6 if raw_attn else 3  # Adjust number of rows based on raw_attn\n",
    "    num_cols = 4  # Fixed number of columns\n",
    "    figsize = (num_cols * 4, num_rows * 3)  # Adjust figure size dynamically\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=figsize)\n",
    "    \n",
    "    for head in range(12):  # Iterate over all heads\n",
    "        row = head // num_cols  # Calculate row index\n",
    "        col = head % num_cols   # Calculate column index\n",
    "        \n",
    "        ax = axes[row, col]\n",
    "        ax.imshow(image_np)\n",
    "        ax.imshow(th_attn[head], cmap=\"jet\", alpha=0.4)\n",
    "        ax.set_title(f\"Head {head}\")\n",
    "        ax.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import corpus_bleu, sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated 1 more sentences\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3967088290836577"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_sentence_1 = \"प्रचीन काल में एक राजा के राज्य में एकादशी के दिन सभी लोग व्रत रखते थे।\"\n",
    "model_sentence_1 = \"प्राचीन काल में, सभी लोग एकादशी के दिन में, एकादशी के दिन में प्रचार करते थे।\"\n",
    "sentence_bleu([original_sentence_1], model_sentence_1, generate_more=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated 1 more sentences\n"
     ]
    }
   ],
   "source": [
    "original_sentence = 'भारत-प्रशांत क्षेत्र में समुद्री स्वतंत्रता के लिए भारत-अमेरिका के आह्वान के संदर्भ में हुआ ने कहा कि समुद्र में सुरक्षा नौवहन के बारे में हम अंतरराष्ट्रीय कानून में उल्लेखित कानूनी अधिकारों को कायम रखेंगे और हम यह उम्मीद भी करते हैं कि नौवहन स्वतंत्रता के लिए पक्ष वास्तविक काम करें।' \n",
    "original_sentence_mod = \"उन्होंने कहा कि भारत-ऑस्ट्रेलिया के बीच समुद्री सुरक्षा के संबंध में भारत और अमेरिका के बीच सहमति बनी है।\"\n",
    "model_sentence = 'भारत-अमेरिका के भारत-अमेरिका के लिए समुद्री स्वतंत्रता की अपील पर हुवा ने कहा, समुद्र में सुरक्षा नौवहन के बारे में हम अंतरराष्ट्रीय कानून में दायर कानूनी अधिकारों को बनाए रखते हैं और हम उम्मीद कर सकते हैं कि पक्ष ने भी सिंचाई की स्वतंत्रता सुनिश्चित करने के लिए वास्तविक चीजें कर सकते हैं।'\n",
    "a = sentence_bleu([original_sentence, original_sentence_mod], model_sentence, generate_more=False)\n",
    "b = corpus_bleu([[original_sentence, original_sentence_mod]], [model_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = corpus_bleu([[original_sentence, original_sentence_mod]], [model_sentence], raw_values=True)\n",
    "t2 = corpus_bleu([[original_sentence_1]], [model_sentence_1], raw_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_num = t1[0] + t2[0]\n",
    "new_denom = t1[1] + t2[1]\n",
    "new_ref = t1[3] + t2[3]\n",
    "new_cand = t1[2] + t2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import brevity_penality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.264586891307893"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "bp = brevity_penality(new_cand, new_ref)\n",
    "pn = [new_num[i] / new_denom[i] if new_denom[i] > 0 else 0 for i in range(1, 5)]\n",
    "log_sum = sum([w * np.log(p) if p > 0 else 0 for w,p in zip((0.25, 0.25, 0.25, 0.25), pn)])\n",
    "bp * np.exp(log_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "combined_data = []\n",
    "\n",
    "# Construct a file pattern to search for JSON files in the input folder\n",
    "json_files = glob.glob(os.path.join(\"../data/en-hi/\", '*.json'))\n",
    "\n",
    "for file in json_files:\n",
    "    try:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            combined_data.extend(data)\n",
    "            # print(data)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON from {file}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred reading {file}: {e}\")\n",
    "\n",
    "# Write the combined data to the output file\n",
    "\n",
    "with open(\"../data/en-hi/test.json\", 'w') as f:\n",
    "    json.dump(combined_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.264586891307893"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bleu([[original_sentence, original_sentence_mod], [original_sentence_1]], [model_sentence, model_sentence_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pipeline\n",
    "\n",
    "# read data from the relevant file and only enough rows as specified\n",
    "# get the corresponding hindi ref sentences as well using the json \n",
    "# batch process them and generate model sentence for the whole batch\n",
    "# pass the rel ref sentences and translated hindi sentences to corpus_bleu and get the raw values\n",
    "# add the raw values to existing values and then return the summed total raw values write this to some file?\n",
    "# get a master file thats whole purpose is to read a dir and update its master values with the file values, and then delete that file \n",
    "# print or write the file value to some implementation. \n",
    "\n",
    "\n",
    "## Future Thoughts\n",
    "# Build that visualiser for attention heads\n",
    "# build some abalation pipeline ? \n",
    "# be able to run experiments keeping the number of total parameters constant but changing number of heads etc or should I keep\n",
    "# change the variable while keeping the rest of the config params constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated 1 more sentences\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.43759047241829613"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_sentence =  'देश में दो टीकों-कोवैक्सीन और सीरम इंस्टीट्यूट के कोविशील्ड को आपात उपयोग की मंजूरी मिली है।'\n",
    "model_sentence = 'भारत ने देश में आपातकालीन उपयोग के लिए भारत बायोटेक और सेरम इंस्टीट्यूट ऑफ इंडिया के कोविशील्डड को दो टीके को मंजूरी दी है।'\n",
    "sentence_bleu([original_sentence], model_sentence, generate_more=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "checkpoint = torch.load(\"../papers/attention_is_all_you_need/Models/hindi_model_small_full_5/Model_230\", map_location=torch.device(\"cpu\"))\n",
    "checkpoint['model_state_dict'] = OrderedDict((k.replace(\"module.\", \"\"), v) for k, v in checkpoint['model_state_dict'].items())\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "sp = spm.SentencePieceProcessor(model_file=\"../papers/attention_is_all_you_need/BPE/en-hi.model\")\n",
    "# model_prediction(model, None, config['SEQ_LEN'], device, sp.bos_id(), sp.eos_id(), sp.pad_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageTranslationDataset(Dataset):\n",
    "    def __init__(self, seq_length, src_encodings, tgt_encodings, sos_token, eos_token, pad_token):\n",
    "        super().__init__()\n",
    "        self.paired_encodings = LanguageTranslationDataset.augment_encodings(src_encodings, tgt_encodings, sos_token, eos_token)\n",
    "        self.seq_len = seq_length\n",
    "        self.pad_token = pad_token\n",
    "\n",
    "    @staticmethod\n",
    "    def augment_encodings(src_encodings, tgt_encodings, sos_token, eos_token):\n",
    "        src_encodings_app = [[sos_token] + sublist + [eos_token] for sublist in src_encodings]\n",
    "        tgt_encodings_app = [[sos_token] + sublist for sublist in tgt_encodings]\n",
    "        output_encodings = [sublist + [eos_token] for sublist in tgt_encodings] \n",
    "        full_encoding = list(zip(src_encodings_app, tgt_encodings_app, output_encodings))\n",
    "        # full_encoding.sort(key=lambda x: len(x[0])) # sort sequence lengths\n",
    "        return full_encoding\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "            src_seq, tgt_seq, output_seq = self.paired_encodings[idx]\n",
    "            # print(src_seq)\n",
    "            \n",
    "            # Convert to tensors\n",
    "            src_tensor = torch.tensor(src_seq, dtype=torch.long)\n",
    "            tgt_tensor = torch.tensor(tgt_seq, dtype=torch.long)\n",
    "            output_tensor = torch.tensor(output_seq, dtype=torch.long)\n",
    "\n",
    "            # **Ensure the sequence length does not exceed `seq_len`**\n",
    "            if src_tensor.size(0) > self.seq_len:\n",
    "                src_tensor = src_tensor[:self.seq_len]  # Crop excess tokens\n",
    "            if tgt_tensor.size(0) > self.seq_len:\n",
    "                tgt_tensor = tgt_tensor[:self.seq_len]  # Crop excess tokens\n",
    "            if output_tensor.size(0) > self.seq_len:\n",
    "                output_tensor = output_tensor[:self.seq_len]  # Crop excess tokens\n",
    "\n",
    "            # **Pad sequences to `seq_len` if they are shorter**\n",
    "            src_tensor = F.pad(src_tensor, (0, max(0, self.seq_len - src_tensor.size(0))), value=self.pad_token)\n",
    "            tgt_tensor = F.pad(tgt_tensor, (0, max(0, self.seq_len - tgt_tensor.size(0))), value=self.pad_token)\n",
    "            output_tensor = F.pad(output_tensor, (0, max(0, self.seq_len - output_tensor.size(0))), value=self.pad_token)\n",
    "            encoder_mask = (src_tensor != self.pad_token).int()\n",
    "            subsequent_mask = torch.tril(torch.ones((self.seq_len, self.seq_len), dtype=torch.int))\n",
    "            padding_mask = (tgt_tensor != self.pad_token).int()\n",
    "            decoder_mask = subsequent_mask & padding_mask.unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "            return {\n",
    "                \"src\": src_tensor, # Seq_len\n",
    "                \"tgt\": tgt_tensor, # seq_len\n",
    "                \"output\": output_tensor, # seq_len\n",
    "                \"encoder_mask\" : encoder_mask.unsqueeze(0).unsqueeze(0), # 1 x 1 x seq_len\n",
    "                \"decoder_mask\" : decoder_mask.unsqueeze(0), # 1 x seq_len x seq_len\n",
    "            }\n",
    "    def __len__(self): \n",
    "            return len(self.paired_encodings)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def get_data(datapath, ref_datapath, skiprows, amount, sp):\n",
    "    english_sentences = pd.read_table(Path(datapath) /  \"english_small.txt\",  header=None, skiprows=skiprows, nrows=amount)\n",
    "    english_encoded = sp.encode_as_ids(english_sentences.iloc[:, 0].to_list())\n",
    "    with open(ref_datapath / \"test.json\", 'r') as f:\n",
    "        ref_sentences = json.load(f)\n",
    "    ref_sentences = ref_sentences[ : amount]\n",
    "    encoding_hindi = list(itertools.chain.from_iterable(ref_sentences))\n",
    "    # assert len(english_encoded) == len(ref_sentences)\n",
    "    hindi_encoded = sp.encode_as_ids(encoding_hindi)[:amount]\n",
    "    return english_sentences, english_encoded, hindi_encoded, ref_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(sp, english_encoded, tgt_encoded, amount):\n",
    "    full_data = LanguageTranslationDataset(seq_length=config['SEQ_LEN'], src_encodings=english_encoded, tgt_encodings=tgt_encoded, sos_token=sp.bos_id(), eos_token=sp.eos_id(),\n",
    "                                        pad_token=sp.pad_id())\n",
    "    dataloader = DataLoader(full_data, batch_size=amount, pin_memory=True, shuffle=False)\n",
    "    return full_data, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(model, batch, max_len, device, sos_token, eos_token, pad_token):\n",
    "    underlying_model = model.module if hasattr(model, 'module') else model\n",
    "\n",
    "    encoder_input = batch['src'].to(device)  # B x seq_len\n",
    "    encoder_mask = batch['encoder_mask'].to(device)  # B x 1 x 1 x seq_len\n",
    "    encoder_output = underlying_model.encode(encoder_input, encoder_mask)\n",
    "\n",
    "    B = encoder_input.size(0)\n",
    "    decoder_input = torch.full((B, max_len), pad_token).to(device)\n",
    "    decoder_input[:, 0] = sos_token\n",
    "    finished = torch.zeros(B, dtype=torch.bool, device=device)\n",
    "\n",
    "    for t in range(max_len - 1):\n",
    "        subsequent_mask = torch.tril(torch.ones((max_len, max_len), dtype=torch.int)).expand(B, -1, -1).to(device)\n",
    "        other_mask = (decoder_input != pad_token).int().unsqueeze(1)\n",
    "        decoder_mask = (subsequent_mask & other_mask).unsqueeze(1).to(device)\n",
    "        out = underlying_model.decode(decoder_input, encoder_output, encoder_mask, decoder_mask)\n",
    "        prediction = underlying_model.proj(out)  # shape: (B, max_len, vocab_size)\n",
    "        next_tokens = torch.argmax(prediction[:, t, :], dim=-1)\n",
    "        next_tokens = torch.where(finished, pad_token, next_tokens)\n",
    "        decoder_input[:, t + 1] = next_tokens\n",
    "        finished |= (next_tokens == eos_token)\n",
    "        if finished.all():\n",
    "            break\n",
    "\n",
    "    return decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "english_sentences, english_encoded, hindi_encoded, ref_sentences = get_data(Path(\"../data/en-hi/\"), Path(\"../data/en-hi/\"), skiprows=1_000, amount=1024, sp=sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, dataloader = get_dataloaders(sp, english_encoded, hindi_encoded, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 172, 1965, 54, 44, 3462, 7937, 258, 598, 794, 5071, 50, 14, 3521, 2823, 7959, 2]\n",
      "[1, 1898, 114, 5978, 61, 544, 1092, 1375, 6837, 7899, 2]\n",
      "[1, 97, 445, 442, 151, 1565, 661, 3278, 5414, 254, 26, 3050, 118, 7872, 235, 7870, 1962, 7942, 2682, 3098, 44, 14, 1009, 65, 2]\n",
      "[1, 104, 5032, 302, 328, 7897, 254, 365, 228, 7, 1699, 44, 645, 2797, 5600, 7899, 2]\n",
      "[1, 97, 954, 136, 7861, 210, 3023, 241, 1790, 7825, 37, 228, 5727, 1062, 7, 2797, 2042, 642, 1684, 7864, 342, 44, 733, 1325, 276, 3262, 86, 7975, 7978, 329, 304, 221, 16, 61, 733, 5503, 7935, 1237, 5414, 97, 4859, 116, 3452, 3533, 1079, 7846, 642, 61, 3539, 503, 4613, 40, 6467, 44, 14, 5975, 4381, 5778, 7899, 2]\n",
      "[1, 104, 5786, 5947, 441, 7906, 7935, 7893, 538, 228, 383, 4611, 148, 14, 6014, 44, 14, 1665, 118, 338, 7862, 7893, 7959, 7986, 7986, 7890, 1387, 7864, 7899, 7865, 69, 7899, 8, 7986, 7974, 250, 7935, 7860, 1745, 69, 7935, 7884, 826, 169, 7942, 61, 7771, 239, 654, 7870, 311, 2611, 44, 2438, 148, 2207, 222, 7283, 44, 5309, 44, 975, 250, 350, 7937, 1887, 2]\n",
      "[1, 448, 5087, 261, 7, 4150, 3330, 7899, 2]\n",
      "[1, 380, 536, 14, 4867, 1328, 4086, 7897, 43, 90, 7955, 3692, 6557, 1699, 44, 3310, 406, 1132, 57, 465, 5, 140, 865, 1654, 103, 4076, 61, 2844, 7899, 2]\n",
      "[1, 6723, 981, 240, 5673, 61, 103, 129, 280, 2258, 302, 1078, 7899, 2]\n",
      "[1, 172, 116, 7978, 7937, 502, 1248, 2971, 14, 7402, 61, 729, 357, 6360, 7870, 50, 261, 5043, 1774, 2338, 687, 44, 14, 6985, 187, 254, 502, 1332, 1006, 50, 3564, 2]\n",
      "[1, 86, 1806, 54, 14, 49, 3773, 148, 845, 6261, 185, 490, 3540, 187, 1127, 432, 44, 1158, 129, 7864, 342, 257, 133, 414, 7607, 3354, 3953, 5190, 254, 231, 7, 876, 7906, 335, 369, 7899, 2]\n",
      "[1, 1311, 444, 979, 100, 1238, 329, 109, 7865, 522, 25, 7897, 4873, 164, 22, 2124, 330, 1613, 102, 768, 795, 1790, 7897, 2508, 141, 36, 3902, 3163, 5448, 6976, 57, 645, 5617, 883, 275, 365, 72, 274, 2657, 14, 1653, 1023, 44, 4707, 145, 7900, 124, 7899, 2]\n",
      "[1, 97, 826, 779, 1325, 1811, 625, 1265, 337, 57, 1254, 864, 14, 2017, 7899, 2]\n",
      "[1, 380, 7954, 3265, 2925, 2186, 636, 164, 4543, 2475, 14, 149, 7943, 7937, 187, 1375, 887, 298, 3984, 90, 687, 134, 3032, 4372, 4847, 61, 2607, 254, 269, 2139, 7899, 2]\n",
      "[1, 1317, 544, 298, 1538, 44, 43, 7561, 5799, 1216, 16, 848, 269, 869, 5, 353, 1674, 7897, 859, 114, 2139, 1293, 7897, 57, 328, 114, 622, 7877, 889, 1293, 7897, 50, 2489, 61, 895, 77, 123, 310, 57, 892, 1178, 1867, 519, 61, 1078, 7899, 541, 690, 512, 895, 77, 123, 310, 57, 892, 1178, 1867, 519, 61, 1078, 258, 298, 333, 7884, 5350, 7899, 2]\n",
      "[1, 849, 3355, 4287, 60, 5463, 50, 2175, 4490, 280, 7892, 2]\n",
      "[1, 1317, 14, 2907, 60, 739, 448, 5895, 134, 118, 7946, 25, 7942, 6039, 1361, 7897, 2]\n",
      "[1, 5882, 858, 228, 897, 2621, 5678, 61, 2438, 228, 14, 2363, 342, 538, 2]\n",
      "[1, 1630, 258, 103, 261, 7890, 1387, 1101, 44, 123, 2937, 141, 57, 546, 954, 50, 1707, 7899, 2]\n",
      "[1, 2241, 324, 2668, 7959, 5723, 4068, 444, 5680, 3608, 38, 4002, 117, 812, 40, 104, 1306, 2]\n",
      "[1, 7289, 1410, 5262, 44, 4168, 1378, 55, 3692, 1386, 7897, 179, 710, 176, 228, 383, 4168, 1328, 7899, 2]\n",
      "[1, 172, 6806, 240, 3308, 465, 2682, 4460, 3998, 61, 6426, 1061, 6023, 109, 69, 239, 14, 7463, 2928, 755, 50, 14, 819, 7899, 2]\n",
      "[1, 1317, 14, 43, 280, 250, 2065, 7866, 739, 258, 103, 7997, 187, 14, 1748, 359, 44, 1350, 103, 3061, 784, 1235, 185, 1024, 103, 1829, 14, 123, 7864, 1424, 7899, 2]\n",
      "[1, 50, 2426, 111, 2602, 2]\n",
      "[1, 1635, 254, 34, 955, 7870, 354, 2073, 7976, 99, 7952, 597, 2957, 354, 7899, 2]\n",
      "[1, 172, 992, 228, 383, 2123, 2912, 2213, 6151, 302, 1316, 707, 44, 733, 5080, 7899, 2]\n",
      "[1, 7092, 7962, 7962, 7937, 7946, 149, 7985, 97, 7946, 7962, 117, 7944, 6848, 2391, 7962, 7948, 7925, 442, 7964, 5755, 4044, 7930, 7897, 86, 7946, 7944, 7926, 117, 7944, 4258, 7930, 7943, 102, 7975, 7954, 7946, 5534, 7957, 7962, 7962, 104, 7925, 97, 7946, 7962, 186, 7926, 5781, 7968, 7948, 7945, 289, 7975, 2203, 7966, 7962, 7962, 6795, 7966, 7962, 7943, 7944, 7930, 3797, 7968, 7948, 7922, 442, 7964, 350, 7948, 7950, 6139, 7962, 5534, 6139, 7950, 350, 0, 7934, 7968, 7944, 7925, 117, 6964, 7932, 7968, 3797, 7968, 7948, 2949, 7975, 7948, 7937, 7926, 7966, 442, 7964, 5755, 4044, 7930, 2065, 7962, 7962, 7934, 7937, 5755, 4044, 7930, 7997, 2]\n",
      "[1, 26, 1753, 258, 6092, 7884, 7047, 14, 3229, 44, 14, 6215, 1876, 297, 442, 5188, 7897, 512, 4436, 7, 6627, 7915, 559, 44, 14, 1702, 4000, 864, 14, 86, 340, 4701, 4331, 873, 875, 1313, 63, 57, 4192, 7893, 4348, 44, 2241, 7862, 4704, 279, 2510, 57, 7522, 207, 102, 537, 2948, 123, 1326, 7864, 134, 14, 3229, 44, 14, 6215, 3521, 3978, 7870, 269, 209, 7937, 102, 7877, 1698, 512, 1823, 5299, 2821, 51, 90, 7877, 72, 2441, 234, 5350, 865, 50, 14, 1465, 7899, 2]\n",
      "[1, 1532, 240, 123, 2459, 218, 7899, 2]\n",
      "[1, 1303, 1615, 365, 3156, 14, 2138, 7899, 2]\n",
      "[1, 172, 1595, 36, 3490, 34, 3812, 224, 375, 7344, 439, 2850, 57, 5152, 1244, 14, 29, 865, 44, 7, 2992, 49, 2739, 5696, 7, 2213, 123, 3049, 44, 20, 810, 50, 14, 2613, 141, 759, 465, 43, 135, 217, 2115, 544, 298, 148, 187, 2646, 410, 7869, 1550, 372, 29, 3682, 7897, 362, 1596, 526, 2921, 43, 194, 249, 57, 2863, 134, 7870, 655, 465, 3066, 30, 711, 60, 656, 7899, 2]\n",
      "[1, 933, 99, 2475, 354, 7899, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:03, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m cand_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(dataloader)):\n\u001b[0;32m----> 7\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m140\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbos_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mdecode(pred\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m      9\u001b[0m     val1, val2, val3, val4 \u001b[38;5;241m=\u001b[39m corpus_bleu(ref_sentences[(idx) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m: (idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m], decoded, raw_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[103], line 17\u001b[0m, in \u001b[0;36mmodel_prediction\u001b[0;34m(model, batch, max_len, device, sos_token, eos_token, pad_token)\u001b[0m\n\u001b[1;32m     15\u001b[0m other_mask \u001b[38;5;241m=\u001b[39m (decoder_input \u001b[38;5;241m!=\u001b[39m pad_token)\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m decoder_mask \u001b[38;5;241m=\u001b[39m (subsequent_mask \u001b[38;5;241m&\u001b[39m other_mask)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 17\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43munderlying_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m prediction \u001b[38;5;241m=\u001b[39m underlying_model\u001b[38;5;241m.\u001b[39mproj(out)  \u001b[38;5;66;03m# shape: (B, max_len, vocab_size)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m next_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(prediction[:, t, :], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Documents - Utkarsh’s MacBook Air/AI grind/dl_from_scratch/dl-from-scratch/papers/Attention Is All You Need/TransformerComponents/Transformer.py:24\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(self, x, encoder_output, encoder_mask, decoder_mask)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Documents - Utkarsh’s MacBook Air/AI grind/dl_from_scratch/dl-from-scratch/papers/Attention Is All You Need/TransformerComponents/Decoder.py:28\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, encoder_output, encoder_mask, decoder_mask)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Documents - Utkarsh’s MacBook Air/AI grind/dl_from_scratch/dl-from-scratch/papers/Attention Is All You Need/TransformerComponents/Decoder.py:16\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, encoder_output, encoder_mask, decoder_mask)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Documents - Utkarsh’s MacBook Air/AI grind/dl_from_scratch/dl-from-scratch/papers/Attention Is All You Need/TransformerComponents/UtilsLayers.py:26\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, sublayer)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl_scratch/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Documents - Utkarsh’s MacBook Air/AI grind/dl_from_scratch/dl-from-scratch/papers/Attention Is All You Need/TransformerComponents/UtilsLayers.py:15\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "num_c = Counter({1: 0, 2: 0, 3: 0, 4:0})\n",
    "denom_c = Counter({1: 0, 2: 0, 3: 0, 4:0})\n",
    "ref_len = 0\n",
    "cand_len = 0\n",
    "for idx, batch in tqdm(enumerate(dataloader)):\n",
    "    pred = model_prediction(model, batch, 140, \"cpu\", sp.bos_id(), sp.eos_id(), sp.pad_id())\n",
    "    decoded = sp.decode(pred.detach().cpu().tolist())\n",
    "    val1, val2, val3, val4 = corpus_bleu(ref_sentences[(idx) * 32: (idx + 1) * 32], decoded, raw_values=True)\n",
    "    # break\n",
    "    num_c += val1\n",
    "    denom_c += val2\n",
    "    cand_len += val3\n",
    "    ref_len += val4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_metrics_script import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02846159391986035"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metrics import brevity_penality\n",
    "import numpy as np\n",
    "bp = brevity_penality(cand_len, ref_len)\n",
    "pn = [num_c[i] / denom_c[i] if denom_c[i] > 0 else 0 for i in range(1, 5)]\n",
    "log_sum = sum([w * np.log(p) if p > 0 else 0 for w,p in zip((0.25, 0.25, 0.25, 0.25), pn)])\n",
    "bp * np.exp(log_sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
